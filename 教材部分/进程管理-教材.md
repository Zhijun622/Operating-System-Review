# 进程管理

第2章
在传统的OS中，为了提高资源利用率和系统吞吐量，通常会采用多道程序技术将多个
程序同时装入内存，并使它们并发执行，即传统意义上的程序不再独立运行。此时，资源
分配和独立运行的基本单位都是进程，OS所具有的四大特征也都是基于进程而形成的。由
此可见，在OS中，进程是一个极其重要的概念。因此，本章将专门对进程进行详细阐述。
本章知识导图如图2-1所示。
进程的描述与控制
前趋图和程序执行
进程
前趋图
程序顺序执行
程序并发执行
进程的定义
进程的特征
进程的基本状态与转换
内核支持线程
用户级线程
两种线程的组合方式
多对一模型
一 对一模型
多对多模型
共享存储器系统
管理通信系统
消息传递系统
客户机-服务器系统
进程的描述
进程控制
进程通信
线程的概念
线程的实现
线程
图2-1  第2章知识导图
进程的描述与控制
第2 章导读


--- Page 61 ---
40
计算机操作系统 （慕课版）
2.1 前趋图和程序执行
在单道批处理系统和早期未配置OS 的计算机系统中，程序的执行方式是顺序执行，即在内
存中仅装入一道程序，由它独占系统的所有资源；只有在一个程序执行完成后，才允许装入另
一个程序并执行（即顺序执行）。可见，这种方式存在浪费资源、系统运行效率低等缺点。而
在多道程序系统中，由于内存中可以同时装入多个程序，它们可以共享系统资源、并发执行，
这显然可以克服上述缺点。程序的这两种执行方式之间存在着显著的不同，尤其是程序并发执
行时的特征，使得在OS中引入进程的概念非常必要。
在此基础上，本节将先后介绍程序的顺序执行和并发执行方式。为了更好地描述程序的这
两种执行方式，本节将首先介绍用于描述程序执行先后顺序的前趋图。
2.1.1 前趋图
所谓前趋图（precedence graph），是指一个有向无环图（directed acyclic graph， DAG），
它用于描述进程之间执行的先后顺序。图中的每个节点均可用于表示一个进程或一段程序，甚
至是一条语句，节点间的有向边则表示两个节点之间所存在的偏序（partial order）或前趋关系
（precedence relation）。
程序之间的前趋关系可用“→”来表示。如果Pi和Pj间存在着前趋关系，则可将它们写成（Pi，
Pj）∈→，也可写成Pi→Pj，表示在Pj开始执行之前Pi必须执行完成。此时称P i是Pj的直接前趋，
而称Pj是Pi的直接后继。在前趋图中，把没有前趋的节点称为初始节点（initial node），把没有
后继的节点称为终止节点（ﬁnal node）。此外，每个节点还具有一个权重（weight），用于表示
该节点所含有的程序量或程序的执行时间。在图2-2（a）所示的无循环的前趋图中，存在着如下
前趋关系：
P1 →P 2，P1 →P 3，P1 →P 4，P2 →P 5，P3 →P 5，P4 →P 6，P4 →P 7，P5 →P 8，P6 →P 8，P7 →P 9，
P8 →P 9。
上述关系还可表示为：
P={P1，P2，P3，P4，P5，P6，P7，P8，P9}
→ ={(P1，P2)， (P1，P3)， (P1，P4)， (P2，P5)， (P3，P5)， (P4，P6)， (P4，P7)， (P5，P8)， (P6，P8)， (P7，P9)，
(P8，P9)}。
（a）无循环的前趋图 （b）有循环的前趋图
P1
P2
P3
P4
P6
P8
P7
P9
S1
S2
S3
P5
图2-2  前趋图
应当注意，前趋图中是不允许有循环的，否则必然会产生无法实现的前趋关系。例如，在图2-2
（b）所示的有循环的前趋图中，就存在着循环。它一方面要求在S3开始执行之前S2必须完成，另一
方面又要求在S2开始执行之前S3必须完成，显然，这种关系（即S2→S3，S3→S2）是不可能实现的。

--- Page 62 ---
41
第
2章 
进程的描述与控制
2.1.2 程序顺序执行
1．程序的顺序执行
通常，一个程序由若干个程序段组成，每个程序段负责完成特定的功能，且它们都需要
按照某种先后次序被顺序运行，仅当前一程序段运行完成后，才会运行后一程序段。例如，在
进行计算时，应先运行输入程序，用于输入用户的程序和数据；然后运行计算程序，对所输入
的数据进行计算；最后才会运行打印程序，打印计算结果。我们用节点来代表各程序段的操作
（在图2-3中用圆圈表示不同节点），其中 I代表输入操作， C代表计算操作，P 代表打印操作，
箭头指示操作的先后次序。这样，上述的3 个程序段的操作间所存在的前趋关系即可表示为：
Ii→Ci→Pi，其执行的先后顺序可用图2-3（a）所示的前趋图来描述。
S1 S2 S3I1 C1 P1 I2 C2 P2
（a）程序的顺序执行 （b）3条语句的顺序执行
图2-3  程序顺序执行的前趋图
需要说明的是，即使是一个程序段，也可能存在执行顺序问题。例如，下面给出了一个包
含3条语句的程序段。
S1: a ∶ =x+y ；
S2: b ∶ =a-5 ；
S3: c ∶ =b+1 ；
其中，语句S2必须在语句S1（即a被赋值）后才能执行，语句S3也只能在语句S2（即b被赋值）后才
能执行，因此，3条语句存在着前趋关系：S1→S2→S3，应按图2-3（b）所示的前趋关系顺序执行。
2．程序顺序执行时的特征
由上述描写可知，程序在顺序执行时具有3个特征。①顺序性：处理机会严格按照程序所规
定的顺序执行语句，即每个操作都必须在下个操作开始之前结束； ②封闭性：程序在封闭的环
境下运行，即程序运行时独占全机资源，只有本程序才能改变资源的状态（除初始状态外），
程序一旦开始执行，其执行结果便不会再受外界因素影响； ③可再现性：只要程序执行时的环
境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“停停走走”
地执行，都可获得相同的结果。程序顺序执行时的这种特性，为程序员检测和校正程序的错误
带来了很大的方便。
2.1.3 程序并发执行
程序顺序执行时，虽然可以给程序员带来方便，但是系统资源的利用率却是极其低下的。
为此，在系统中引入了多道程序技术，使程序或程序段间能并发执行。然而，并非所有的程序
都能并发执行。事实上，只有不存在前趋关系的程序才有可能并发执行，否则无法并发执行。
1．程序的并发执行
首先，我们通过一个最常见的例子，来说明程序顺序执行和并发执行的不同。
在图2-3中的输入程序、计算程序和打印程序三者之间，存在着I i→Ci→Pi这样的前趋关系，
以至对于一个作业而言，输入、计算和打印这三个程序段必须顺序执行。但是当需要处理一批

--- Page 63 ---
42
计算机操作系统 （慕课版）
作业（而非一个）时，每个作业的输入、计算和打印程序段的执行情况如图 2-4所示。输入程序 
（I1）输入第一次数据后，在由计算程序（C 1）对该数据进行计算的同时，输入程序（ I2）可
再输入第二次数据，从而使第一个计算程序（C 1）可与第二个输入程序（I 2）并发执行。事实
上，正是由于C1和I2之间并不存在前趋关系，因此它们之间可以并发执行。一般来说，输入程序
（Ii+1）在输入第i+1次数据时，计算程序（ Ci）可能正在对输入程序（I i）的第i次输入的数据进
行计算，而打印程序（Pi-1）可能正在打印计算程序Ci-1的计算结果。
I1 I2
I3 I4
C1
C2 C3 C4
P1
P2 P3 P4
图2-4  程序并发执行时的前趋图
从图2-4中可以看出，存在前趋关系I i→Ci，Ii→Ii+1，Ci→Pi，Ci→Ci+1，Pi→Pi+1，而在Ii+1和Ci
以及Pi-1之间，不存在前趋关系，它们可以并发执行。
对于具有下述4条语句的程序段：
S1: a ∶ =x+2;
S2: b ∶ =y+4;
S3: c ∶ =a+b;
S4: d ∶ =c+b;
可画出图2-5所示的前趋关系。从图2-5中可以看出：S 3必须在a和b被赋值后方能执行；S4必须在
S3之后方能执行；但S1和S2则可以并发执行，因为它们彼此互不依赖。
S1
S2
S3
S4
图2-5  4条语句的前趋关系
2．程序并发执行时的特征
在引入程序间的并发执行功能后，虽然提高了系统吞吐量和资源利用率，但是由于它们共
享系统资源，以及为完成同一任务而相互合作，这些并发执行的程序之间必将形成相互制约关
系，这会给程序并发执行带来新的特征，介绍如下。
（1）间断性 。程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相
互合作，这些并发执行的程序之间形成了相互制约关系。例如，图2-4中的I 、C和P是三个相互
合作的程序，当计算程序C i-1完成计算后，如果输入程序I i尚未完成数据输入，则计算程序C i就
无法进行数据处理，此时必须暂停执行。只有当致使程序暂停的因素消失后（如I i已完成数据输 
入），计算程序C i才可恢复执行。由此可见，相互制约关系将导致并发程序具有“执行—暂
停—执行”这种间断性的活动规律。
（2）失去封闭性 。当系统中存在多个可以并发执行的程序时，系统中的各种资源将为它
们所共享，而这些资源的状态也会由这些程序来改变，致使其中任一程序在执行时，其执行环

--- Page 64 ---
43
第
2章 
进程的描述与控制
境必然会受到其他程序的影响。例如，当处理机已被分配给某个进程执行时，其他程序必须等
待。显然，程序的执行失去了封闭性。
（3）不可再现性 。程序在并发执行时，失去封闭性会导致其失去可再现性。例如，有两
个循环程序A 和B，它们共享一个变量 N。程序A 每执行一次时，都要执行 N =  N + 1操作；程
序B每执行一次时，都要执行Print( N)操作，然后再将 N置成“0”。程序A 和B以不同的速度运
行。这样，可能出现下述3种情况（假定某一时刻变量N的值为n）。①若N = N + 1在Print(N)和 
N = 0之前执行，则各次操作对应的 N值分别为n+1、n+1、0。②若N = N + 1在 Print(N)和N = 0  
之后执行，则各次操作对应的N值分别为n、0、1。③若N = N + 1在Print(N)和N = 0之间执行，则
各次操作对应的N值分别为n、n+1、0。
上述情况说明，程序在并发执行时，由于失去了封闭性，其计算结果必将与并发程序的执
行速度有关，这使程序的执行失去了可再现性。换言之，程序经过多次执行后，虽然多次执行
时的环境和初始条件相同，但得到的结果却各不相同。
2.2 进程的描述
2.2.1 进程的定义与特征
1．进程的定义
在多道程序环境下，程序的执行属于并发执行，因此它们会失去封闭性，并具有间断性和
运行结果不可再现性。通常，程序是不能参与并发执行的，否则，程序的执行就失去了意义。
为了使程序可以并发执行，并且可以对并发执行的程序加以描述和控制，人们在OS 中引入了
“进程”这一概念。
为了使参与并发执行的每个程序（含数据）都能独立地运行，在OS中必须为之配置一个
专门的数据结构，称之为进程控制块（process control block， PCB）。系统利用PCB来描述进
程的基本情况和活动过程，进而控制和管理进程。这样，由程序段、相关的数据段和PCB这 3
部分便构成了进程实体（又称为进程映像）。一般情况下，我们把进程实体简称为进程，例
如，所谓创建进程，实质上是指创建进程的PCB；而撤销进程，实质上是指撤销进程的PCB，
本书中也是如此。
对于进程，从不同的角度可以给出不同的定义，其中较典型的定义有以下3种。
（1）进程是程序的一次执行。
（2）进程是一个程序及其数据在处理机上顺序执行时所发生的活动。
（3）进程是具有独立功能的程序在一个数据集上执行的过程，它是系统进行资源分配和调
度的一个独立单位。
在引入进程的概念后，我们可以把传统OS 中的进程定义为：“进程是程序的执行过程，是
系统进行资源分配和调度的一个独立单位”。
2．进程的特征
进程和程序是两个截然不同的概念，进程除了具有程序所没有的PCB外，还具有以下特征。
（1）动态性 。进程的实质是程序的执行过程，因此，动态性就是进程最基本的特征。动
态性还表现在：进程由创建而产生，由调度而执行，由撤销而消亡。由此可见，进程有一定的
生命期，而程序则只是一组有序指令的集合，并存放于某种介质上，其本身并不具有活动的含

--- Page 65 ---
44
计算机操作系统 （慕课版）
义，因而是静态的。
（2）并发性，是指多个进程共存于内存中，且能在一段时间内同时执行。引入进程也正是
为了使进程能和其他进程并发执行。因此，并发性是进程的另一个重要特征，同时也成为了OS
的重要特征；而程序（未建立PCB）是不能参与并发执行的。
（3）独立性。在传统OS中，独立性是指进程是一个能够独立运行、独立获得资源、独立
接受调度的基本单位。凡未建立PCB的程序都不能作为一个独立的单位参与并发执行。
（4）异步性 ，是指进程是按异步方式运行的，即按各自独立的、不可预知的速度向前推
进。正是这一特征才导致传统意义上的程序若参与并发执行，则会使其结果不可再现。为了使
进程在并发执行时虽具有异步性，但仍能保证进程并发执行的结果是可再现的，在OS中引入了
进程的概念，并且配置了相应的进程同步机制。
为什么程序一定要被创建成为进程后，才能在 OS 中运行？
思考题
2.2.2 进程的基本状态与转换
1．进程的 3 种基本状态
由于多个进程在并发执行时共享系统资源，它们会在执行过程中呈现间
断性规律，因此，进程在其生命周期内可能具有多种状态。一般而言，每个进
程至少应处于以下3种基本状态之一。
（1）就绪（ready）状态，是指进程已处于准备好执行的状态，即进程已
分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行。如果系统中有许多处
于就绪状态的进程，则通常会将它们按一定的策略（如优先级策略）排成一个队列，称该队列
为就绪队列。
（2）执行（running）状态 ，是指进程获得CPU后其程序“正在执行”这一状态。对任何
一个时刻而言，在单处理机系统中，只有一个进程处于执行状态，而在多处理机系统中，则可
能会有多个进程处于执行状态。
（3）阻塞（block）状态。正在执行的进程由于发生某事件（如I/O请求、申请缓冲区失败
等）而暂时无法继续执行，即指进程的执行受到了阻塞。此时会引发进程调度，OS会把处理机
分配给另一个就绪进程，而让受阻进程处于暂停状态，一般将这种暂停状态称为阻塞状态，有
时也称为等待状态或封锁状态。通常系统会将处于阻塞状态的进程排成一个队列，称该队列为
阻塞队列。实际上，在较大的系统中，为了减少阻塞队列操作开销，提高系统效率，根据阻塞
原因的不同，会设置多个阻塞队列。
2．进程 3 种基本状态间的转换
进程在运行过程中，会经常发生状态的转换。例如，处于就绪状态的进程，在调度程序为
之分配处理机之后便可执行，相应地，其状态就会由就绪转变为执行；正在执行的进程（当前
进程），如果因分配给它的时间片已完而被剥夺处理机暂停执行时，其状态便会由执行转变为
就绪；如果因发生某事件而致使当前进程的执行受阻（例如进程访问某临界资源而该资源又正
在被其他进程访问），使之无法继续执行，则该进程状态将由执行转变为阻塞。图 2-6给出了进
程的3种基本状态以及各状态之间的转换关系。
进程的基本 
状态与转换


--- Page 66 ---
45
第
2章 
进程的描述与控制
I/O完成
时间片完
进程调度
I/O请求
就绪
阻塞
执行
图2-6  进程的3种基本状态及其转换关系
3．创建状态和终止状态
为了满足进程控制块对数据与操作的完整性要求以及增强管理的灵活性，通常会在系统中
为进程引入另外两种常见的状态：创建状态和终止状态。
（1）创建状态。
如前所述，进程是由创建或新建产生的。创建一个进程是一个很复杂的过程，一般要通过
多个步骤才能完成，具体而言：首先，由进程申请一个空白PCB，并向PCB中填写用于控制和
管理进程的信息；然后，为该进程分配运行时所必需的资源；最后，把该进程的状态转换为就
绪状态并将其插入就绪队列之中。但如果进程所必需的资源尚不能得到满足，如系统尚无足够
的内存来存储进程，此时创建工作尚未完成，进程不能被调度运行，于是我们把此时进程所处
的状态称为创建状态（或新建状态）。
引入创建状态，是为了保证进程的调度必须在创建工作完成后进行，以确保对PCB操作的
完整性。同时，创建状态的引入也增加了管理的灵活性，OS可以根据系统性能或内存容量的限
制，推迟新进程的提交（使进程处于创建状态）。对于处于创建状态的进程，当其获得了所必
需的资源，并完成了对PCB的初始化工作后，便可由创建状态转入就绪状态。
（2）终止状态。
进程的终止也要通过两个步骤：首先，等待OS进行善后处理；然后，将进程的PCB清零，
并将PCB空间返还OS。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被OS
所终止，或是被其他有终止权的进程所终止时，它就会进入终止状态。进入终止状态的进程不
能再被执行，但在OS中依然会保留一个记录，其中会保存状态码和一些计时统计数据以供其
他进程收集。一旦其他进程完成了对其信息的提取，系统就会删除该进程，即将其 PCB清零，
并将该空白PCB返还OS。图2-7 所示为增加了创建状态和终止状态后，进程的 5种状态及其转换 
关系。
I/O完成
时间片完
进程调度
I/O请求
许可
释放
就绪创建
阻塞 执行 终止
图2-7  进程的5种基本状态及其转换关系

--- Page 67 ---
46
计算机操作系统 （慕课版）
2.2.3 挂起操作和进程状态的转换
在许多系统中，为了满足系统和用户观察与分析进程的需要，除了就绪、执行和阻塞这3种最
基本的状态外，还引入了一个面向进程的重要操作——挂起。当该操作作用于某个进程时，该进程
将被挂起，这意味着此时该进程处于静止状态。例如，如果进程正在执行，则其此时会暂停执行；
如果进程原本处于就绪状态，则其此时暂不接受调度。与挂起操作对应的操作是激活操作。
1．挂起操作的引入
引入挂起操作主要是为了满足下列需要。
（1）终端用户的需要。终端用户自己的程序在运行期间发现有可疑问题，希望暂停程序运  
行，以便用户研究其执行情况或对其进行修改。
（2）父进程的需要。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，
或者协调各子进程间的活动。
（3）负荷调节的需要 。当实时系统中的工作负荷较重，可能会影响到对实时任务的控制
时，系统可把一些不重要的进程挂起，以保证自身能正常运行。
（4）OS的需要。OS有时希望挂起某些进程，以便检查在进程运行过程中资源的使用情况
或进行记账。所记录的信息包括CPU时间、实际使用时间、作业或进程数量等。
2．引入挂起操作后进程 3 个基本状态间的转换
引入挂起原语Suspend和激活原语Active（二者须成对使用）后，在二者的共同作用下，进
程可能会发生以下几种状态转换。
（1）活动就绪→静止就绪 。进程处于未被挂起的就绪状态，称为活动就绪状态，表示为
Readya，此时进程可以接受调度。当用挂起原语Suspend将该进程挂起后，该进程的状态便转换
成了静止就绪状态，表示为Readys。处于Readys状态的进程不会再被调度执行。
（2）活动阻塞→静止阻塞 。进程处于未被挂起的阻塞状态，称为活动阻塞状态，表示为
Blockeda。当用挂起原语Suspend将该进程挂起后，进程的状态便转换成了静止阻塞状态，表示为
Blockeds。处于该状态的进程在其所期待的事件发生后，它将从静止阻塞状态变为静止就绪状态。 
（3）静止就绪→活动就绪。处于Readys状态的进程，若用激活原语Active将其激活，则该
进程的状态将会转换为Readya状态。
（4）静止阻塞→活动阻塞 。处于Blockeds状态的进程，若用激活原语Active将其激活，则
该进程的状态将会转换为Blockeda状态。图2-8所示为具有挂起状态的进程状态图。
执行
活动
就绪
静止
就绪
静止
阻塞
活动
阻塞
激活
挂起
激活
释放
释放
时间片完
调度
请求I/O
挂起
挂起
图2-8  具有挂起状态的进程状态图

--- Page 68 ---
47
第
2章 
进程的描述与控制
3．引入挂起操作后进程 5 个基本状态间的转换
图2-9所示为增加了创建状态和终止状态后，具有挂起状态的进程状态图。
执行
创建
终止
活动
就绪
静止
就绪
静止
阻塞
活动
阻塞
激活
挂起
激活
释放
释放
释放
时间片完调度
请求I/O
许可
许可
挂起
挂起
图2-9  具有创建、 终止和挂起状态的进程状态图
如图2-9所示，引入创建和终止状态后，进程在进行状态转换时，与图2-8所示的进程5 个状
态转换相比较，要额外考虑下面的几种情况。
（1）NULL→创建：一个新进程产生时，该进程处于创建状态。
（2）创建→活动就绪：在当前系统的性能和内存容量均允许的情况下，当完成进程创建的
必要操作后，相应地系统会将进程状态转换为活动就绪状态。
（3）创建→静止就绪：在当前的系统资源状况和性能要求不允许的情况下，系统不会分配
给新建进程所需资源（主要是内存），相应地系统会将进程状态转换为静止就绪状态。进程被
安置在外存，不参与调度，此时进程创建工作尚未完成。
（4）执行→终止 ：当一个进程已完成任务，或是出现了无法克服的错误，或是被OS或其
他进程所终止时，将进程状态转换为终止状态。
2.2.4 进程管理中的数据结构
如1.1.2小节所述，一方面，为了便于使用和管理计算机中的各类资源（包括硬件和信
息），OS将它们抽象为相应的各种数据结构，并提供了一组对资源进行操作的命令；用户可利
用这些数据结构及操作命令来执行相关的操作，而无须关心其实现的具体细节。另一方面，OS
作为计算机资源的管理者，为了协调诸多用户对系统中共享资源的使用，它还必须记录和查询
各种资源的使用情况及各类进程的运行情况等信息；OS对于这些信息的组织和维护，也是通过
建立和维护各种数据结构的方式来实现的。
1．OS 中用于管理资源和控制进程的数据结构
在计算机系统中，对于每个资源和每个进程都设置了一个数据结构，用于表征其实体，我
们称之为资源信息表和进程信息表，其中包含了资源和进程的标志、描述、状态等信息以及一
批指针。通过这些指针，可以将同类资源和进程的信息表，或者同一进程所占用的资源信息表
分类链接成不同的队列，以便OS进行查找。如图2-10所示，OS管理的这些控制表一般可分为以
下4类：内存表、设备表、文件表和用于进程管理的进程表，通常进程表又被称为PCB。本小节
着重介绍PCB，其他的表将在后面的章节中陆续介绍。

--- Page 69 ---
48
计算机操作系统 （慕课版）
内存
设备
文件
进程
内存表
设备表
文件表
进程1
进程2
进程3 进程1
进程实体及所用资源列表
进程实体及所用资源列表
…
…
进程n
进程n
图2-10  OS控制表的一般结构
2．PCB 的作用
为了便于系统描述和管理进程，OS为每个进程专门定义了一个数据结构——PCB。 PCB作
为进程的一部分，记录了OS所需的、用于描述进程当前情况以及管理进程运行状态的全部信
息，是OS中最重要的记录型数据结构。
PCB的作用是使一个在多道程序环境下不能独立运行的程序（含数据），成为一个能独立
运行的基本单位，即一个能与其他进程并发执行的进程。下面将对PCB的具体作用做进一步的  
阐述。
（1）作为独立运行基本单位的标志。当一个程序（含数据）配置了PCB后，就表示它已是
一个能在多道程序环境下独立运行的、合法的基本单位了，即具有了取得OS服务的权利，如打
开文件系统中的文件，请求使用系统中的 I/O设备，以及与其他相关进程进行通信等。因此，当
系统创建一个新进程的同时，就会为它建立一个PCB。进程结束时系统又会回收其PCB，进程
也随之消亡。系统是通过PCB来感知进程的存在的。事实上，PCB已成为进程存在于系统中的
唯一标志。
（2）实现间断性运行方式。在多道程序环境下，程序是采用“停停走走”这种间断性的方
式运行的。当进程因阻塞而暂停运行时，它必须保留自己运行时的CPU现场信息，因为其再次
被调度运行时，还需要恢复CPU现场信息。在有了PCB后，系统就可以将CPU现场信息保存在
被中断进程的PCB中，供该进程再次被调度运行而须恢复CPU现场信息时使用。由此可再次明
确，在多道程序环境下，作为传统意义上的静态程序，其因并不具有保护或保存自己运行现场
的手段，故无法保证运行结果的可再现性，从而失去了运行的意义。
（3）提供进程管理所需要的信息。当调度程序调度到某进程时，只能根据该进程PCB中记
录的程序和数据在内存或外存起始地址（又称为“始址”或“基址”）中找到相应的程序和数
据；在进程运行过程中，当进程需要访问文件系统中的文件或I/O设备时，也都需要借助PCB中
的信息。另外，还可根据 PCB中的资源清单了解到该进程所需的全部资源等信息。由此可见，
在进程的整个生命期中，OS总是根据PCB来实施对进程的控制和管理的。
（4）提供进程调度所需要的信息。只有处于就绪状态的进程才能被调度运行，而在PCB中
就提供了进程所处状态等信息。如果进程处于就绪状态，系统便会把它插入进程就绪队列中，
等待调度程序的调度；另外，在进行进程调度时，往往还需要了解进程的其他信息，如在优先

--- Page 70 ---
49
第
2章 
进程的描述与控制
级调度算法中，就需要知道进程的优先级；在有些较为公平的调度算法中，还需要知道进程的
等待时间和已执行时间等信息。
（5）实现与其他进程的同步与通信。进程同步机制是用于实现各进程的协调运行的，在采
用信号量机制时，它要求在每个进程中都要设置相应的用于同步的信号量。在 PCB中还具有用
于实现进程通信的区域或通信队列指针等。
3．PCB 中的信息
在PCB中，主要包括下述4方面的信息。
（1）进程标识符。
进程标识符用于唯一地标志一个进程。一个进程通常有两种标识符。
① 外部标识符 。为了方便用户（进程）对进程的访问，须为每个进程设置一个外部标识
符。它是由创建者提供的，通常由字母和数字组成。为了描述进程的家族关系，还应设置父进
程标识符和子进程标识符。此外，还可设置用户标识符，以指示拥有该进程的用户。
② 内部标识符。为了方便系统对进程的使用，在OS中又为进程设置了内部标识符，即赋予
每个进程唯一的一个数字标识符，它通常是一个进程的序号。
（2）处理机状态。
处理机状态信息，也称为处理机的上下文，主要是由处理机的各种寄存器中的内容组成
的。这些寄存器包括：①通用寄存器，又称为用户可视寄存器，它们可被用户程序访问，用于
暂存信息，在大多数处理机中，有8 ～32个通用寄存器，在RISC中可超过100个；②指令计数
器，其中存放了要访问的下一条指令的地址；③程序状态字寄存器，其中含有状态信息，如条
件码、执行方式、中断屏蔽标志等；④用户栈指针寄存器，指每个用户进程都有一个或若干个
与之相关的系统栈，用于存放进程和系统的调用参数及调用地址。栈指针指向该栈的栈顶。处
理机处于执行状态时，正在处理的许多信息都是放在寄存器中的。当进程被切换时，处理机状
态信息都必须保存在相应的PCB中，以便在该进程被重新调度时，能再从断点处继续执行。
（3）进程调度信息。
OS在进行进程调度时，必须了解进程的状态以及有关进程调度的信息，这些信息包括：  
①进程状态，指明进程的当前状态，作为进程调度和对换时的依据；②进程优先级，描述进程使
用处理机的优先级别（用一个整数表示），优先级高的进程应优先获得处理机；③进程调度所需
要的其他信息，如进程已等待CPU的时间总和、进程已执行时间总和等，它们与所采用的进程调
度算法有关；④事件，指进程由执行状态转换为阻塞状态所等待发生的事件，即阻塞原因。
（4）进程控制信息。
进程控制信息是指用于进程控制所必需的信息，包括：①程序和数据的地址，即进程中程
序和数据的内存或外存起始地址，便于再调度到该进程执行时，能从 PCB中快速找到其程序和
数据；②进程同步和通信机制，这是实现进程同步和进程通信时所必需的机制，如消息队列指
针、信号量等，它们可能会全部或部分放在 PCB中；③资源清单，在该清单中列出了进程在运
行期间所需的全部资源（除CPU外）；④链接指针，它给出了本进程所在队列中的下一个进程
的PCB的始址。
4．PCB 的组织方式
在一个系统中，通常可拥有数十个、数百个乃至数千个PCB。为了能对它们加以有效的管
理，应该用适当的方式将这些PCB组织起来。目前常用的组织方式有以下3种。

--- Page 71 ---
50
计算机操作系统 （慕课版）
（1）线性方式。将系统中所有的PCB都组织在一张线性表中，将该表的起始地址存放在内
存的一个专用区域中。该方式实现简单且开销小，但每次查找时都需要扫描整张表，因此适合
进程数目不多的系统。图2-11所示为PCB线性表示意。
（2）链接方式 。通过PCB中的链接字，将具有相同状态的进程的PCB分别链接成一个队
列。这样即可形成就绪队列、若干个阻塞队列和空闲队列等。对就绪队列而言，其往往会按进
程的优先级将PCB从高到低进行排列，即将优先级高的进程的PCB排在队列的前面。同样，也
可根据阻塞原因的不同，把处于阻塞状态的进程的PCB排成多个阻塞队列，如等待I/O操作完成
的队列和等待分配内存的队列等。图2-12所示为PCB链接队列示意。
（3）索引方式。系统根据所有进程状态的不同，建立几张索引表，如就绪索引表、阻塞索
引表等，并把各索引表在内存中的起始地址记录在内存的一些专用单元中。在每个索引表的表
目中，记录具有相应状态的某个PCB在PCB表中的地址。图2-13所示为PCB索引方式示意。
PCB1
PCB2
PCB3
PCBn
…
                              
执行指针 
PCB1
PCB2
PCB3
PCB4
PCB5
PCB6
PCB7
PCB8
PCB9
4
3
0
8
7
9
0
1
…
就绪队列指针
阻塞队列指针
空闲队列指针
                图2-11  PCB线性表示意                                   图2-12  PCB链接队列示意
执行指针
就绪索引表指针
阻塞索引表指针
就绪索引表
阻塞索引表
PCB1
PCB2
PCB3
PCB4
PCB5
PCB6
PCB7
…
图2-13  PCB索引方式示意
2.3 进程控制
进程控制是进程管理中最基本的功能，其负责创建新进程、终止已完成的进程、将因发生
异常情况而无法继续运行的进程置于阻塞状态、转换运行中进程的状态等。例如，当一个正在
运行的进程因等待某事件而暂时不能继续运行时，将其置于阻塞状态，而在该进程所期待的事
件出现后，又将其置于就绪状态。进程控制一般是由OS内核中的原语来实现的。
2.3.1 进程的创建
1．进程的层次结构
在OS中，允许一个进程创建另一个进程，通常把创建进程的进程称为 父进程 （parent 
进程控制


--- Page 72 ---
51
第
2章 
进程的描述与控制
process），而把被创建的进程称为子进程（progeny process）。子进程可以继续创建其自己的子
进程（即父进程的孙进程），由此便形成了进程的层次结构。如在UNIX系统中，进程与其子孙
进程可以共同组成一个进程家族（进程组）。
了解进程间的这种关系是十分重要的，因为子进程可以继承父进程所拥有的资源，例如，
继承父进程所打开的文件和分配到的缓冲区等。当子进程被撤销时，应将其从父进程那里获得
的资源归还给父进程。此外，在撤销父进程时，也必须同时撤销其所有的子进程。为了标志进
程间的家族关系，在 PCB中设置了家族关系表项，以标明自己的父进程及所有的子进程。进程
不能拒绝其子进程的继承权。
值得注意的是，在Windows系统中不存在任何进程层次结构的概念，所有的进程都具有相
同的地位。在一个进程创建了另外一个进程后，创建进程获得一个句柄，其作用相当于一个令
牌，可以用来控制被创建的进程。但是这个句柄是可以进行传递的，也就是说，获得了句柄的
进程拥有控制被创建进程的权力，因此，进程之间的关系不再是层次关系了，而是获得句柄与
否、控制与被控制的简单关系。
2．进程图
为了形象地描述一个进程的家族关系，引入了进程图（process graph）。所谓 进程图，就是
用于描述进程间关系的一棵有向树，如图2-14所示。图中的节点代表进程。若进程B 创建了进程
D，则称B是D的父进程，D是B的子进程。
A
B
D
I J K L M
E F G H
C
图2-14  进程图
这里可用一条由进程B指向进程D的有向边来描述它们之间的父子关系。创建父进程的进程
称为祖先进程，这样便形成了一棵进程树，树的根节点作为进程家族的祖先（ancestor）。
3．引起进程创建的事件
为使程序之间能并发执行，应先为它们分别创建进程。导致一个进程去创建另一个进程的
典型事件有4类。①用户登录：在分时系统中，用户在终端键入登录命令后，若登录成功，则系
统将会为该用户创建一个进程，并把它插入就绪队列中。 ②作业调度：在多道批处理系统中，
当作业调度程序按一定的算法调度到某个（或某些）作业时，便会将它（们）装入内存、为它  
（们）创建进程，并把它（们）插入就绪队列中。 ③提供服务：当运行中的用户程序提出某种
请求后，系统将专门创建一个进程来为用户提供其所需要的服务，例如，用户进程要求打印文
件，系统将为它创建一个打印进程，这样，不仅可使打印进程与该用户进程并发执行，还便于
计算出完成打印任务所须花费的时间。④应用请求：在上述3种情况下，都是由系统内核为用户
创建一个新进程；而针对“应用请求”这类事件，则需要由用户进程自己创建新进程，以使新
进程以同创建进程并发执行的方式完成特定任务。例如，某用户进程需要不断地先从键盘终端

--- Page 73 ---
52
计算机操作系统 （慕课版）
读入数据，再对读入的数据进行相应的处理，最后将处理结果以表格的形式显示在屏幕上。该
用户进程为使这几个操作能并发执行以加速完成任务，可以分别建立键盘输入进程、数据处理
进程以及表格输出进程。
4．进程的创建
在系统中每当出现创建新进程的请求时，OS 便会调用进程创建原语，并按下述步骤创建一
个新进程。
（1）申请空白PCB。为新进程申请一个唯一的数字标识符，并从PCB集合中索取一个空白
PCB。
（2）为新进程分配其运行所需的资源，包括各种物理和逻辑资源，如内存、文件、I/O设
备和CPU时间等。这些资源从OS或其父进程获得。新进程对这些资源的需求详情，一般也要
提前告知OS或其父进程。例如，为新进程的程序和数据以及用户栈分配必要的内存空间时，
OS必须知道新进程所需内存的大小：①对于批处理作业，其大小可在用户提出创建进程要求时
提供；②对于为应用进程创建子进程，也应在该进程提出创建进程的请求中给出所需内存的大
小；③对于交互型作业，用户可以不给出内存要求而由系统分配一定的内存空间，如果新进程
要共享内存中的某个地址空间（即已装入内存的共享段），则必须建立相应的链接。
（3）初始化PCB。PCB的初始化工作包括：①初始化标志信息，将系统分配的标识符和父
进程标识符填入新PCB中；②初始化处理机状态信息，使程序计数器指向程序的入口地址，使
栈指针指向栈顶；③初始化处理机控制信息，将进程的状态设置为就绪状态或静止就绪状态，
此外，通常还须将其设置为最低优先级，除非用户以显式方式提出高优先级要求。
（4）如果进程就绪队列能够接纳新进程，就将新进程插入就绪队列。
当进程创建新进程时，有两种执行的可能：
 父进程与子进程并发执行； 
 父进程等待，直到其某个或全部子进程执行完毕。
新进程的地址空间也有两种可能：
 子进程是父进程的复制品（即子进程具有与父进程相同的程序和数据）；
 子进程加载另一个新程序。
上述不同功能的实现，能以UNIX系统中创建新进程的系统调用fork()为例。使用fork()后创建的
新进程是通过复制原进程的地址空间而形成的，这种机制支持父进程与子进程方便地进行通信。这
两个进程（父进程和子进程）都会继续执行位于系统调用fork()之后的指令。但不同的是，对于子进
程，系统调用fork()的返回值为0；而对于父进程，返回值为子进程的进程标识符（非0）。
通常，在系统调用fork()后，进程会使用另一个系统调用，即exec()，用新程序来取代进程
的内存空间。系统调用exec() 会将二进制文件装入内存（取代了原来包含系统调用exec()程序的
内存映射），并开始执行。采用这种方式，两个进程能够相互通信，并能按各自的方法执行。
父进程能创建更多的子进程，或者如果在子进程运行时父进程没有事情可做，那么它可以使用
系统调用wait()把自己移出就绪队列以等待子进程的终止。
2.3.2 进程的终止
1．引起进程终止的事件
（1）正常结束，表示进程的任务已经完成，准备退出运行。在任何系统中，都应有一个用

--- Page 74 ---
53
第
2章 
进程的描述与控制
于表示进程已经运行完成的指示。在批处理系统中，通常会在程序的最后安排一条Holt指令，用
于向OS表示运行已结束。当程序运行到Holt指令时，将产生一个中断以通知OS本进程已运行完
毕；在分时系统中，用户可利用Logs off来表示进程运行完毕，此时同样可产生一个中断以通知
OS本进程已运行完毕。
（2）异常结束，是指进程在运行时，发生了某种异常事件，使程序无法继续运行。常见的
异常事件有：①越界错，程序所访问的存储区已越出该进程所占存储区域的范围；②保护错，
进程试图去访问一个不允许访问的资源或文件，或者以不适当的方式进行访问，例如，进程试
图去写一个只读文件；③指令错，程序试图去执行一条不存在的指令（非法指令），出现该错
误的原因可能是程序错误地转移到了数据区，把数据当成了指令；④特权指令错，进程试图去
执行一条只允许OS执行的指令；⑤运行超时，进程的运行时间超过了设定的最大值；⑥等待超
时，进程等待某事件的时间超过了指定的最大值；⑦算术运算错，进程试图去执行一个被禁止
的运算，例如，被0除；⑧I/O错，这是指在I/O过程中发生了错误等。
（3）外界干预，是指进程应外界的请求而终止运行。这些干预有：①操作员或OS干预，
如果系统中发生了某事件，例如，发生了系统死锁，则由操作员或OS 采取终止某些进程的方
式，把系统从死锁状态中解救出来；②父进程请求，当子进程已完成父进程所要求的任务时，
父进程可以提出请求以结束该子进程；③父进程终止，即当父进程终止时，它的所有子孙进程
都应当结束，因此，OS在终止父进程的同时，也会将它的所有子孙进程终止。
2．进程的终止过程
当系统中发生了要求终止进程的某事件后，OS便会调用进程终止原语，按下述步骤终止指
定的进程：①根据被终止进程的标识符，从PCB集合中检索出该进程的PCB，并从该进程的PCB
中读出该进程的状态；②若被终止进程正处于执行状态，则立即终止该进程的执行，并置调度
标志为真，以指示该进程被终止后应重新进行调度；③若该进程还有子孙进程，则还应终止其
所有子孙进程，以防止它们成为不可控的进程；④将被终止的进程所拥有的全部资源，或归还
给其父进程，或归还给系统；⑤将被终止进程的 PCB从所在队列（或链表）中移出，等待其他
程序来搜集信息。
2.3.3 进程的阻塞与唤醒
1．引起进程阻塞与唤醒的事件
有下述几类事件会引起进程阻塞或进程唤醒。
（1）向系统请求共享资源失败。进程在向系统请求共享资源时，由于系统已无足够的资源
分配给它，此时进程会因不能继续运行而将自身状态转变为阻塞状态。例如，一个进程请求使
用打印机，由于系统已将打印机分配给了其他进程，已无可再分配的打印机，这时，请求进程
只能被阻塞，仅在其他进程释放出打印机后，请求进程才会被唤醒。
（2）等待某种操作的完成。当进程启动某种操作后，如果该进程必须在该操作完成之后才
能继续执行，则应先将该进程阻塞起来，以等待该操作完成。例如，进程启动了某 I/O设备，如
果只有在I/O设备完成了指定I/O操作任务后进程才能继续执行，则该进程在启动了I/O设备后，
便应自动进入阻塞状态去等待。在I/O操作完成后，再由中断处理程序将该进程唤醒。
（3）新数据尚未到达。对于相互合作的进程，如果一个进程需要先获得另一进程提供的数
据后，才能对该数据进行处理，则只要其所需数据尚未到达，进程便会阻塞。例如，有两个进

--- Page 75 ---
54
计算机操作系统 （慕课版）
程，进程A用于输入数据，进程B用于对输入的数据进行加工。假如A尚未将数据输入完毕，则B
将会因没有所需处理的数据而阻塞；A一旦把数据输入完毕，便可去唤醒B。
（4）等待新任务的到达 。在某些（特别是在网络环境下的）OS中，往往会设置一些特定
的系统进程，每当这种进程完成任务后，便会把自己阻塞起来，以等待新任务的到来。例如，
在网络环境中的发送进程，其主要任务是发送数据包，若已有的数据包已全部发送完成，而又
无新的数据包需要发送，这时发送进程就会把自己阻塞起来；仅当有新的数据包到达时，系统
才会将发送进程唤醒。
2．进程阻塞过程
正在执行的进程，如果发生了上述某事件，进程便会通过调用阻塞原语block将自己阻塞。
由此可见，阻塞是进程自身的一种主动行为。进入block阶段后，由于该进程还处于执行状态，
因此系统应首先立即停止执行该进程，把PCB中的现行状态由执行改为阻塞，并将PCB插入阻
塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将该进程插入具有相同事
件的阻塞队列。最后，转至调度程序进行重新调度操作，将处理机分配给另一就绪进程并进行
切换，即保留被阻塞进程的处理机状态，并按新进程的PCB中的处理机状态设置CPU的环境。
3．进程唤醒过程
当被阻塞进程所期待的事件发生时，例如它所启动的I/O操作已完成，或其所期待的数据已
到达，有关进程（如提供数据的进程）就会调用唤醒原语wakeup以将等待该事件的进程唤醒。
wakeup的执行过程是：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其PCB中的现
行状态由阻塞改为就绪；然后再将该PCB插入就绪队列中。
应当指出，block原语和wakeup原语是一对作用刚好相反的原语。在使用它们时，必须成对
使用，即如果在某进程中调用了阻塞原语，则必须在与之相合作的或其他相关进程中调用一条
相应的唤醒原语，以便能唤醒被阻塞的进程；否则，阻塞进程将会因不能被唤醒而永久地处于
阻塞状态，再无机会继续运行。
2.3.4 进程的挂起与激活
1．进程的挂起
当系统中出现引发进程挂起的事件时，OS就会利用挂起原语suspend将指定进程或处于阻塞
状态的进程挂起。suspend的执行过程是：首先，检查被挂起进程的状态，若为活动就绪状态，
则将其改为静止就绪状态；其次，针对处于活动阻塞状态的进程，将其状态改为静止阻塞状
态；再次，为了方便用户或父进程考查该进程的运行情况，把该进程的PCB复制到某指定的内
存区域；最后，若被挂起的进程正在执行，则转向调度程序重新调度。
2．进程的激活
当系统中出现激活进程的事件时，OS就会利用激活原语active将指定进程激活。active 的执
行过程是：首先将进程从外存调入内存，然后检查该进程的现行状态，若是静止就绪，则将其
改为活动就绪；若是静止阻塞，则将其改为活动阻塞。假如采用的是抢占调度策略，则每当有
静止就绪进程被激活而插入就绪队列时，便应检查是否要进行重新调度，即由调度程序将被激
活进程与当前进程两者的优先级进行比较，如果被激活进程的优先级较低，就不必重新调度；
否则，立即终止当前进程的运行，并把处理机分配给刚被激活的进程。

--- Page 76 ---
55
第
2章 
进程的描述与控制
2.4 进程通信
进程通信 ，是指进程之间的信息交换，通常有低级和高级之分。低级进程通信之所以低
级，是因为：①效率低，生产者每次只能向缓冲区中投放一个产品（消息），消费者每次只能
从缓冲区中取得一个消息；②通信对用户不透明，OS只为进程之间的通信提供了共享存储器，
而关于进程之间通信所需要的共享数据结构的设置、数据的传送、进程的互斥与同步等，都必
须由程序员去实现，这对于用户而言显然是非常不方便的。本书第4 章中将会介绍进程的互斥与
同步，由于它们的实现需要在进程间交换少量的信息，不少学者也将它们归为低级进程通信。
当需要在进程之间传送大量数据时，应当利用OS 提供的高级通信工具，该工具最主要的特
点是：①使用方便，OS隐藏了实现进程通信的具体细节，向用户提供了一组高级通信命令（原
语），用户可以方便地直接利用它来实现进程之间的通信，或者说通信过程对用户是透明的，
这样就大大减少了通信程序编制上的复杂性；②高效地传送大量数据，用户可以直接利用高级
通信命令（原语）来高效地传送大量数据。
2.4.1 进程通信的类型
随着OS的发展，用于进程之间实现通信的机制也在发展，并已由早期的低级通信机制发展
为能传送大量数据的高级通信机制。目前，高级通信机制可归结为4 类：共享存储器系统、管道
通信系统、消息传递系统以及客户机-服务器系统。
1．共享存储器系统
在共享存储器系统（shared-memory system）中，相互通信的进程共享某些数据结构或存储
区，进程之间能够通过这些空间进行通信。据此，又可把它们分成以下两种类型。
（1）基于共享数据结构的通信方式。在这种通信方式中，要求各进程共享某些数据结构，
以实现各进程间的信息交换，如在生产者 -消费者问题中的有界缓冲区。OS仅提供共享存储
器，由程序员负责对共享数据结构进行设置和对进程间同步进行处理。这种通信方式仅适用于
传送相对较少量的数据，通信效率低下，属于低级进程通信。
（2）基于共享存储区的通信方式。为了传送大量数据，在内存中划出了一块共享存储区，
各进程可通过对该共享存储区的读/ 写来交换信息、实现通信，数据的形式和位置（甚至访问）
均由进程负责控制，而非OS。这种通信方式属于高级进程通信。需要通信的进程在通信前，先
向系统申请获得共享存储区中的一个分区，并将其附加到自己的地址空间中，进而便可对其中
的数据进行正常的读/写，读/写完成或不再需要时，将分区归还给共享存储区即可。
2．管道通信系统
所谓“管道”（pipe），是指用于连接一个读进程和一个写进程以实现它们之间通信的一
个共享文件，又名pipe文件。向管道（共享文件）提供输入的发送进程（即写进程），会以字节
流形式将大量的数据送入管道；而接收管道输出的接收进程（即读进程），则会从管道中接收
（读）数据。由于发送进程和接收进程是利用管道进行通信的，故称之为管道通信。这种方式
首创于UNIX系统，由于它能有效地传送大量数据，因而又被应用于许多其他OS中。
为了协调双方的通信，管道机制必须提供以下3方面的协调能力。①互斥，即当一个进程正
在对管道执行读/写操作时，其他（另一）进程必须等待。 ②同步，即当写（输入）进程把一定
数量（如4KB）的数据写入管道后，便去睡眠（等待），直到读（输出）进程取走数据后，再

--- Page 77 ---
56
计算机操作系统 （慕课版）
把它唤醒。当读进程读一空管道时，也应睡眠（等待），直至写进程将数据写入管道后，再把
它唤醒。③确定对方是否存在，只有确定了对方已存在时，才能进行通信。
3．消息传递系统
在该机制中，进程不必借助任何共享数据结构或存储区，而是会以格式化的消息
（message）为单位，将通信的数据封装在消息中，并利用OS提供的一组通信命令（原语），在
进程间进行消息传递，完成进程间的数据交换。
该方式隐藏了通信实现细节，使通信过程对用户透明，降低了通信程序设计的复杂性和错
误率，成为当前应用得最为广泛的一类进程通信机制。例如：在计算机网络中，消息又称为报
文；在微内核OS中，微内核与服务器之间的通信无一例外地都采用了消息传递机制；由于该机
制能很好地支持多处理机系统、分布式系统和计算机网络系统，因此也成为这些系统中最主要
的通信机制。
基于消息传递系统（message passing system）的通信方式属于高级通信方式，其因实现方式
的不同又可进一步分成两类： ①直接通信方式，是指发送进程利用OS所提供的发送原语，直接
把消息发送给目标进程； ②间接通信方式，是指发送进程和接收进程都通过共享中间实体（称
为信箱）的方式进行消息的发送和接收，进而完成进程间的通信。
4．客户机 - 服务器系统
前面所述的共享内存、消息传递等技术，虽然可以用于实现不同计算机间进程的双向通信，
但客户机-服务器系统（client-server system）的通信机制，在网络环境的各种应用领域，已成为当
前主流的通信机制，其主要的实现方法分为3类：套接字、远程过程调用和远程方法调用。
（1）套接字。
套接字（socket）起源于20世纪70年代加州大学伯克利分校开发的伯克利软件套件（berkeley 
software distribution，BSD），其是UNIX系统下的网络通信接口。最初，套接字被设计用于同一
台主机上多个应用程序之间的通信（即进程间的通信），主要是为了解决多对进程同时通信时
端口和物理线路的多路复用问题。随着计算机网络技术的发展以及 UNIX系统的广泛使用，套接
字逐渐成为了非常流行的网络通信接口之一。
一个套接字就是一个通信标志类型的数据结构，包含通信目标地址、通信使用的端口号、
通信网络的传输层协议、进程所在的网络地址以及针对客户或服务器程序所提供的不同系统调
用或API等，是进程通信和网络通信的基本构件。套接字是针对客户机 -服务器模型而设计的。
通常，套接字可分为以下两类。
① 基于文件型。通信进程都运行在同一主机的网路环境下，而套接字是基于本地文件系统
支持的。一个套接字会关联一个特殊的文件，通信双方通过对这个特殊文件进行读/ 写而实现通
信，其原理类似于前面所讲的管道通信。
② 基于网络型。该类型通常采用非对称方式通信，即发送者需要提供接收者的名称。通信
双方的进程运行在不同主机的网络环境下。通信被分配了一对套接字，其中一个属于接收进程
（或服务器端），另一个属于发送进程（或客户端）。一般地，发送进程发出连接请求时，会
随机申请一个套接字，与此同时主机会为之分配一个端口，并使其与该套接字绑定，而不再分
配给其他进程。接收进程拥有全局公认的套接字和指定的端口（如文件传输协议（file transfer 
protocol，FTP）服务器的监听端口号为21，Web或超文本传输协议（hypertext transfer protocol，
HTTP）服务器的监听端口号为80），并通过监听端口来等待客户请求。因此，任何进程都可以

--- Page 78 ---
57
第
2章 
进程的描述与控制
向它发出连接请求和信息请求，以方便进程之间通信连接的建立。接收进程一旦收到请求，就
会接受来自发送进程的连接，并完成连接，这表示在主机间传输的数据可以准确地分送到通信
进程，实现进程间的通信；当通信结束时，系统通过关闭接收进程的套接字来撤销连接。
套接字的优势在于，它不仅适用于同一台计算机内部的进程通信，也适用于网络环境中不
同计算机间的进程通信。由于每个套接字都拥有唯一的套接字号（也称为套接字标识符），即
系统中所有的连接都持有唯一的一对套接字及端口，对于来自不同应用程序进程或网络连接的
通信能够被方便地加以区分，这确保了通信双方之间逻辑链路的唯一性，便于实现数据传输的
并发功能，而且隐藏了通信设施与实现细节，支持采用统一的端口进行通信。
（2）远程过程调用和远程方法调用。
远程过程调用（remote procedure call，RPC）是一个通信协议，用于通过网络连接的系统。
该协议允许运行于一台主机（本地）系统上的进程调用另一台主机（远程）系统上的进程，而
对程序员则表现为常规的过程调用，无须额外为此编程。 需要特别说明的是，如果涉及的软件
采用面向对象编程，那么远程过程调用亦可称作远程方法调用。
负责处理远程过程调用的进程有两个，一个是本地客户进程，另一个是远程服务器进程。
这两个进程通常也被称为网络守护进程，主要负责在网络间传递消息。一般情况下，这两个进
程都处于阻塞状态，等待消息。
为了使远程过程调用看上去与本地过程调用一样，使得调用者感觉不到此次调用的过程是
在其他主机上（远程）执行的，RPC引入了存根（stub）的概念：在本地客户端，每个能够独立
运行的远程过程都拥有一个客户存根（client stubborn），本地进程调用远程过程，实际是调用
该过程关联的存根；与此类似，在每个远程进程所在的服务器端上，其所对应的实际可执行进
程也存在一个服务器存根与其关联。本地客户存根与对应的远程服务器存根一般也处于阻塞状
态，等待消息。
远程过程调用的主要步骤是：①本地过程调用者以一般方式调用远程过程在本地关联的客
户存根，传递相应的参数，然后将控制权转移给客户存根；②执行客户存根，完成包括过程名
和调用参数等信息的消息建立，将控制权转移给本地客户进程；③本地客户进程完成与服务器
的消息传递，并将消息发送到远程服务器进程；④远程服务器进程接收消息后，转入执行，并
根据其中的远程过程名找到对应的服务器存根，然后将消息发送给该服务器存根；⑤该服务器
存根接收到消息后，由阻塞状态转入执行状态，拆开消息并从中取出过程调用的参数，然后以
一般方式调用服务器端关联的远程过程；⑥在服务器端的远程过程运行完毕后，将结果返回给
与之关联的服务器存根；⑦该服务器存根获得控制权后运行，将结果打包为消息，并将控制权
转移给远程服务器进程；⑧远程服务器进程将消息发送回客户端；⑨本地客户进程接收到消息
后，根据其中的过程名将消息存入关联的客户存根，并再次将控制权转移给客户存根；⑩客户
存根从消息中取出结果，返回给本地过程调用者进程，并完成控制权的转移。这样，本地过程
调用者再次获得控制权，并且得到了所需的数据，能够继续运行。
显然，上述步骤的主要作用在于，将客户端的本地过程调用转化为客户存根，再转化为服
务器端的本地过程调用。对客户与服务器来说，这一过程的中间步骤是不可见的。因此，调用
者在整个过程中并不知道该过程的执行是在远程（而非本地）。
请思考计算机本地进程通信和远程进程通信的差异。
思考题

--- Page 79 ---
58
计算机操作系统 （慕课版）
2.4.2 消息传递通信的实现方式
当进程之间进行通信时，源进程可以直接或间接地将消息发送给目标进程，因此可将进程通
信分为直接和间接两种。常见的直接消息传递系统和信箱通信就分别采用了这两种通信方式。
1．直接通信（直接消息传递系统）
直接消息传递系统采用直接通信方式，即发送进程利用OS 所提供的发送命令（原语），直
接把消息发送给目标进程。
（1）直接通信原语。
① 对称寻址方式。
该方式要求发送进程和接收进程都必须以显式方式提供对方的标识符。通常，系统会提供
下列两条通信命令（原语）。
send(receiver, message)：发送一个消息给接收进程。
receive(sender, message)：接收发送进程发来的消息。
例如，原语send(P 2, m1)表示将消息m1发送给接收进程P2；而原语receive(P 1, m1)则表示接收
由P1发来的消息m1。
对称寻址方式的不足在于，一旦改变进程的名称，就可能需要检查所有其他进程的定义，
有关对该进程旧名称的所有引用都必须查找到，以便将它们修改为新名称。显然，这样的方式
不利于实现进程定义的模块化。
② 非对称寻址方式。
在某些情况下，接收进程可能需要与多个发送进程进行通信，因此无法事先指定发送进程。
例如，用于提供打印服务的进程，可以接收来自任何一个进程的“打印请求”消息。对于这样的
应用，在接收进程的原语中不需要命名发送进程，而只需要填写表示源进程的参数，即完成通信
后的返回值；发送进程则仍需要命名接收进程。该方式的发送和接收原语可表示为如下。
send(P, message)：发送一个消息给进程P。
receive(id, message)：接收来自任何进程的消息，id变量可设置为进行通信的发送方进程id
或其名字。
（2）消息的格式。
在消息传递系统中所传递的消息，必须具有一定的消息格式。在单处理机系统中，由于发
送进程和接收进程处于同一台机器中，有着相同的环境，因此消息的格式比较简单，可采用比
较短的定长消息格式，以减少对消息的处理和存储开销。该方式可用于办公自动化系统中，为
用户提供快速的便笺式通信。但这种方式对于需要发送较长消息的用户是不方便的。为此，可
采用变长消息格式，即进程所发送消息的长度是可变的。对于变长消息，系统无论在处理方面
还是存储方面，都可能会付出更多的开销，但其优点在于方便了用户。
（3）进程的同步方式。
当进程之间进行通信时，同样需要有进程同步机制，以使各进程间能协调通信。不论是发
送进程，还是接收进程，在完成消息的发送或接收后，都存在两种可能性，即进程继续发送/ 接
收，或者阻塞。由此，我们可得到3种情况。①发送进程阻塞，接收进程阻塞。这种情况主要用
于进程之间紧密同步，发送进程和接收进程之间无缓冲。 ②发送进程不阻塞，接收进程阻塞 。
这是一种应用最广的进程同步方式。平时，发送进程不阻塞，因而它可以尽快地把一个或多个
消息发送给多个目标；而接收进程平时则处于阻塞状态，直到发送进程发来消息时才会被唤

--- Page 80 ---
59
第
2章 
进程的描述与控制
醒。③发送进程和接收进程均不阻塞 。这也是一种较常见的进程同步方式。平时，发送进程和
接收进程都在忙于自己的事情，仅当发生某事件而使它们无法继续运行时，它们才会把自己阻
塞起来进行等待。
（4）通信链路。
为了使在发送进程和接收进程之间能进行通信，必须在两者之间建立一条通信链路。有两
种方式建立通信链路。第一种方式是：由发送进程在通信之前用显式的“建立连接”命令（原
语），请求系统为之建立一条通信链路，在链路使用完后拆除链路。这种方式主要用于计算机网
络中。第二种方式是：发送进程无须明确提出建立链路的请求，只须使用系统提供的发送命令
（原语），系统就会自动为之建立一条链路。这种方式主要用于单处理机系统中。根据通信方式
的不同，又可把链路分成两种：①单向通信链路，只允许发送进程向接收进程发送消息，或者反
向进行；②双向通信链路，允许进程A在向进程B发送消息的同时，进程B向进程A发送消息。
2．间接通信（信箱通信）
信箱通信采用间接通信方式，即进程之间的通信需要通过某种中间实体（如共享数据结构
等）实现。该实体建立在随机存储器的共享缓冲区上，用来暂存发送进程发送给目标进程的消  
息；接收进程可以从该实体中取出发送进程发送给自己的消息，通常把这种中间实体称为信箱
（或邮箱），每个信箱都有一个唯一的标识符。消息在信箱中可以被安全保存，只允许核准的目
标用户对其进行随时读取。因此，利用信箱通信方式既可实现实时通信，又可实现非实时通信。
（1）信箱的结构。
信箱被定义为一种数据结构。在逻辑上，其可以分为两个部分： ①信箱头 ，用于存放信
箱的描述信息，如信箱标识符、信箱的拥有者标识符、信箱口令、信箱的空格数等； ②信箱
体，由若干个可以存放消息（或消息头）的信箱格组成，信箱格的数目以及每格的大小是在创
建信箱时确定的。在消息传递方式上，最简单的方式是单向传递，当然消息也可以双向传递。  
图2-15所示为双向通信链路（双向信箱）示意。
进程A 进程B
…
信箱头
信箱格    1
信箱格    2
信箱格    3
信箱格    
接收
发送 接收
发送
图2-15  双向信箱示意
（2）信箱通信原语。
系统为信箱通信提供了若干条原语，分别用于下列情况。
①信箱的创建和撤销。进程可利用信箱创建原语来建立一个新信箱，创建者进程应给出信
箱名字、信箱属性（公用、私用或共享）；对于共享信箱，还应给出共享者的名字。当进程不
再需要读信箱时，可用信箱撤销原语将之撤销。
②消息的发送和接收。当进程之间要利用信箱进行通信时，必须使用共享信箱，并利用系
统提供的下列通信原语进行通信。
send(mailbox, message)：将一个消息发送到指定信箱。
receive(mailbox, message)：从指定信箱中接收一个消息。

--- Page 81 ---
60
计算机操作系统 （慕课版）
（3）信箱的类型。
信箱可由OS创建，也可由用户进程创建，创建者是信箱的拥有者。据此，可把信箱分为
以下3类。①私用信箱，用户进程可为自己建立一个新信箱，并将其作为该进程的一部分。信
箱的拥有者有权从信箱中读取消息，其他用户则只能将自己构成的消息发送到该信箱。这种私
用信箱可采用单向通信链路的信箱来实现。当拥有该信箱的进程结束时，信箱也会随之消失。  
②公用信箱 ，由OS 创建，并提供给系统中的所有核准进程使用。核准进程既可把消息发送到
该信箱，也可获得该信箱发送给自己的消息。显然，公用信箱应采用双向通信链路的信箱来实
现。通常，公用信箱在系统运行期间始终存在。 ③共享信箱，由某进程创建，在创建时或创建
后，须指明它是可共享的，同时须指出共享进程（用户）的名字。信箱的拥有者和共享者，都
有权获得信箱发送给自己的消息。
利用信箱通信时，在发送进程和接收进程之间，存在以下4 种关系：①一对一关系，发送
进程和接收进程可以建立一条两者专用的通信链路，使两者之间的交互不受其他进程的干扰。  
②多对一关系，允许提供服务的进程与多个用户进程进行交互，也称为客户/ 服务器交互
（client/server interaction）。③一对多关系，允许一个发送进程与多个接收进程进行交互，使发
送进程可用广播方式向接收者（多个）发送消息。④多对多关系，允许建立一个公用信箱，使
得多个进程既能向信箱中投递消息，又能从信箱中取走属于自己的消息。
2.4.3 实例 ： Linux 进程通信
UNIX系统中进行进程间通信（interprocess communication， IPC）的方法有很多，但极少有
方法能在所有的UNIX系统中进行移植。而Linux作为一种新兴的OS，几乎支持所有的UNIX系统
下常用的进程通信方法，包括管道、信号、消息队列、共享内存、信号量、套接字等。
1．管道
管道是进程间通信中最古老的一种方式，它分为无名管道和有名管道两种，前者用于父进
程和子进程间的通信，后者用于运行在同一台机器上的任意两个进程间的通信。
（1）无名管道由pipe()函数创建：
1   #include <unistd.h>
2   int pipe(int filedis[2]);
其中，参数filedis返回两个文件描述符：filedes[0]为读而打开，filedes[1]为写而打开。
filedes[1]的输出是filedes[0]的输入。下面的例子示范了如何在父进程和子进程之间实现通信。
1   #define INPUT 0
2   #define OUTPUT 1
3   void main( ) {
4       int file_descriptors[2];
5       pid_t pid;       /* 定义子进程号 */
6       char buf [256];
7       int returned_count;
8       pipe(file_descriptors);   /* 创建无名管道 */
9       if((pid = fork()) == -1) {  /* 创建子进程 */
10               printf("Error in fork/n");
11               exit(1);

--- Page 82 ---
61
第
2章 
进程的描述与控制
12       }
13       if(pid == 0) {        /* 执行子进程 */
14              printf("in the spawned (child) process…/n");
15              /* 子进程向父进程写数据， 关闭管道的读端 */
16              close(file_descriptors[INPUT]);
17              write(file_descriptors[OUTPUT], "test data", strlen("test data"));
18              exit(0);
19       } 
20       else {            /* 执行父进程 */
21              printf("in the spawning (parent) process…/n");
22              /* 父进程从管道读取子进程写的数据， 关闭管道的写端 */
23              close(file_descriptors[OUTPUT]);
24              returned_count = read(file_descriptors[INPUT], buf, sizeof(buf));
25              printf("%d bytes of data received from spawned process: %s/n",returned_count, buf);
26       }
27   }
（2）有名管道可由两种命令行方式创建：函数mkfifo和系统调用mknod。下面的两种方式
都在当前目录下生成了一个名为myfifo的有名管道。
方式一：mkfifo("myfifo","rw");
方式二：mknod myfifo p;
生成了有名管道后，就可以使用一般的文件I/O函数（如open、 close、read、write等）来对
它进行操作。下面给出了一个简单的例子，假设我们已经创建了一个名为myfifo的有名管道。
1   #include <stdio.h>
2   #include <unistd.h>
3   void main( ) {
4       FILE * in_file, *out_file;
5       int count = 1;
6       char buf[80];
7       in_file = fopen("mypipe", "r");   /* 读有名管道 */
8       if (in_file == NULL) {
9           printf("Error in fdopen./n");
10           exit(1);
11       }
12       while ((count = fread(buf, 1, 80, in_file)) > 0) printf("received from pipe: %s/n", buf );
13       fclose(in_file);
14       out_file = fopen("mypipe", "w");   /* 写有名管道 */
15       if (out_file == NULL) {
16           printf("Error in fdopen./n");
17           exit(1);
18       }
19       sprintf(buf,"this is test data for the named pipe example./n");

--- Page 83 ---
62
计算机操作系统 （慕课版）
20       fwrite(buf, 1, 80, out_file);
21       fclose(out_file);
22   }
2．信号
使用信号进行通信是一种比较复杂的通信方式，用于通知接收进程有某种事件发生。信号
除了可以用于进程间通信外，还可以被进程发送给其自身。Linux除了支持UNIX系统早期信号
语义函数signal()外，还支持语义符合可移植操作系统接口（portable operating system interface，
POSIX）标准的信号函数sigaction。
3．消息队列
Linux消息队列支持POSIX消息队列和System V消息队列。消息队列用在运行于同一台机器
上的进程间通信中，它和管道很相似，是一个在系统内核中用来保存消息的队列，它在系统内
核中以消息链表的形式出现。消息链表中节点的结构用msg声明。有足够权限的进程可以向队
列中添加消息，被赋予读权限的进程可以读取队列中的消息。消息队列克服了信号承载信息量
少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4．共享内存
共享内存可以使运行在同一台机器上的进程间通信最快，因为数据无须在不同的进程间进
行复制。通常由一个进程在内存中创建一块共享存储区，其余进程对这块存储区进行读/ 写。
得到共享存储区的方式有两种：映射/dev/mem 设备和内存映像文件。前一种方式不会给系统带
来额外的开销，但在现实中并不常用，因为它控制的将会是实际的物理内存，而在Linux系统
下，这只有通过限制Linux系统存取的内存才可以实现，这当然不太实际。常用的方式是通过
shmXXX函数族来实现利用共享存储区进行存储。
首先使用shmget()函数获得一个共享存储标识符：
1   #include <sys/types.h>
2   #include <sys/ipc.h>
3   #include <sys/shm.h>
4   int shmget(key_t key, int size, int flag);
shmget()函数类似于大家所熟悉的malloc()函数，系统会将其请求分配size大小的内存用作共享
存储区。当共享存储区被创建后，其余进程即可通过调用shmat()将其连接到自身的地址空间中：
void *shmat(int shmid, void *addr, int flag);
shmid 为 shmget() 函数返回的共享存储标识符，addr 和 ﬂag 参数决定了以什么方式来确定连
接的地址， 函数的返回值就是该进程数据段所连接的实际地址， 进程可以对此地址所对应的内存
进行读 / 写操作。
使用共享存储区来实现进程间通信的注意点是对数据存取的同步，必须确保当一个进程去
读取数据时，它所想要的数据已经写好了。通常，信号量会被用于实现对共享存储数据存取的
同步，另外，也可通过使用shmctl()函数设置共享存储区的某些标志位（如SHM_LOCK、 SHM_
UNLOCK等）来实现。
5．信号量
信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常会被作为一种锁机

--- Page 84 ---
63
第
2章 
进程的描述与控制
制，用于防止某进程正在访问共享资源（如共享内存）时，其他进程也来访问该资源。因此，
信号量主要作为进程间以及同一进程内不同线程间的同步手段。
6．套接字
套接字编程是实现Linux系统和其他大多数OS中进程间通信的主要方式之一。我们熟知的
WWW服务、FTP服务、Telnet服务等都是基于套接字编程来实现的。除了适用于异地计算机进
程间通信之外，套接字同样适用于本地同一台计算机内部的进程间通信。
2.5 线程的概念
20世纪60年代中期，人们在设计多道程序OS时，引入了进程的概念，从而解决了在单处理
机环境下的程序并发执行问题。此后在长达20年的时间里，在多道程序OS中一直以进程为能够
拥有资源并独立调度（运行）的基本单位。直到20世纪80年代中期，人们才提出了比进程更小
的基本单位——线程（thread）的概念，并试图用它来提高程序并发执行的程度，以进一步改善
系统的服务质量。特别是在进入20世纪90年代后，多处理机系统得到了迅速发展，由于线程能
更好地提高程序的并发执行程度，近些年推出的多处理机OS无一例外地都引入了线程，用于改
善OS的性能。
2.5.1 线程的引入
如果说在OS中引入进程的目的是使多个程序能并发执行，以提高资源利用率和系统吞吐
量，那么，在OS中再引入线程，则是为了减少程序在并发执行时所付出的时空（时间和空间）
开销，以使OS具有更好的并发性。
1．进程的两个基本属性
首先让我们来回顾进程的两个基本属性。①进程是一个可拥有资源的独立单位。一个进
程要能独立运行，就必须拥有一定的资源，包括用于存放程序正文和数据的磁盘，内存地址空
间，以及它在运行时所需要的 I/O设备、已打开的文件、信号量等。②进程同时又是一个可独立
调度和分派的基本单位。一个进程要能独立运行，它还必须是一个可独立调度和分派的基本单
位。每个进程在系统中均有唯一的PCB，系统可以根据PCB来感知进程的存在，也可以根据PCB
中的信息对进程进行调度，还可将断点信息保存在进程的PCB中。反之，可利用进程PCB中的
信息来恢复进程运行的现场。正是由于具有这两个基本属性，进程才成为了一个能独立运行的
基本单位，从而也就构成了进程并发执行的基础。
2．程序并发执行所须付出的时空开销
为使程序能并发执行，系统必须进行以下这一系列的操作：①创建进程，系统在创建一个
进程时，必须为它分配其所必需的、除处理机以外的所有资源（如内存空间、I/O设备等），
并建立相应的PCB；②撤销进程，系统在撤销进程时，又必须先对其所占有的资源执行回收
操作，然后再撤销PCB；③进程切换，对进程进行上下文切换时，需要保留当前进程的CPU环
境，并设置新选中进程的CPU环境，这一过程须花费不少的处理机时间。
据此可知，由于进程是一个资源的拥有者，因而在创建、撤销和切换中，系统必须为之付
出较大的时空开销。这就限制了系统中所设置进程的数目，而且进程切换也不宜过于频繁，从

--- Page 85 ---
64
计算机操作系统 （慕课版）
而限制了程序并发执行程度的进一步提高。
3．线程——作为调度和分派的基本单位
如何能使多个程序更好地并发执行，同时又能尽量减少系统的开销，已成为近年来设计OS
时所追求的重要目标。有不少研究OS的学者们想到，可以将进程的两个基本属性分开，由OS分
开处理，即并不把“作为调度和分派的基本单位”同时作为拥有资源的基本单位，以实现“轻
装上阵”；而对于拥有资源的基本单位，又不对之施以频繁的切换。正是在这种思想的指导
下，形成了线程的概念。
随着VLSI技术和计算机体系结构的发展，出现了对称多处理机（symmetrical multi-
processing，SMP）系统。它为提高计算机的运行速度和系统吞吐量提供了良好的硬件基础。但
要使多个CPU很好地协调运行，充分发挥它们的并行处理能力以提高系统性能，则还必须配置
性能良好的多处理机OS。但利用传统的进程概念和设计方法，已难以设计出适用于SMP系统的
OS，最根本的原因是进程“太重”，这致使为实现多处理机环境下的进程创建、调度与分派，
均须花费较大的时空开销。如果在OS中引入线程，以线程为调度和分派的基本单位，则可以有
效改善多处理机系统的性能。因此，一些主要的OS（如UNIX 、Windows等）厂家，又进一步对
线程技术做了开发，使之适用于SMP系统。
2.5.2 线程与进程的比较
线程具有传统进程所具有的很多特征，因此又称为 轻型进程 （light-weight process，
LWP）或进程元；相应地把传统进程称为 重型进程 （heavy-weight process， HWP），它相
当于只有一个线程的任务。下面将从调度的基本单位、并发性、拥有资源等方面对线程和进
程进行比较。
1．调度的基本单位
在传统OS中，进程作为独立调度和分派的基本单位，能够独立运行。其在每次被调度时，
都需要进行上下文切换，开销较大。而在引入线程的OS中，已把线程作为调度和分派的基本单
位，因而线程是能独立运行的基本单位。当进行线程切换时，仅须保存和设置少量寄存器的内  
容，切换代价远低于进程。在同一进程中，线程的切换不会引起进程的切换，但从一个进程中
的线程切换到另一个进程中的线程时，必然会引起进程的切换。
2．并发性
在引入线程的OS中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可
并发执行，甚至还允许一个进程中的所有线程都能并发执行。同样，不同进程中的线程也能并
发执行。这使得OS具有了更好的并发性，从而能更加有效地提高资源利用率和系统吞吐量。例
如，在文字处理机中可设置三个线程：第一个线程用于显示文字和图形，第二个线程通过键盘
读入数据，第三个线程在后台检查拼写和语法。再如，在网页浏览器中可设置两个线程：第一
个线程用于显示图像或文本，第二个线程用于从网络中接收数据。
此外，有的应用程序需要执行多个相似的任务。例如，一个网络服务器经常会接收到许多
客户的请求，如果仍采用传统单线程的进程来执行该任务，则每次只能为一个客户提供服务。
但如果在一个进程中可以设置多个线程，并使其中的一个线程专用于监听客户的请求，则每当
有一个客户提出请求时，系统便会立即创建一个线程来处理该客户的请求。

--- Page 86 ---
65
第
2章 
进程的描述与控制
3．拥有资源
进程可以拥有资源，并可作为系统中拥有资源的一个基本单位。然而，线程可以说是几乎不
拥有资源，其仅有的一点儿必不可少的资源也是为了确保自身能够独立运行。例如，在每个线程
中都应具有用于控制线程运行的线程控制块（thread control block，TCB），用于指示被执行指令
序列的程序计数器，用于保留局部变量、少数状态参数和返回地址等的一组寄存器，以及堆栈。
线程除了拥有自己的少量资源外，还允许多个线程共享它们共属的进程所拥有的资源，这
一点首先表现在：属于同一进程的所有线程都具有相同的地址空间，这意味着线程可以访问该
地址空间中的每一个虚地址；此外，线程还可以访问其所属进程所拥有的资源，如已打开的文  
件、定时器、信号量机构等的内存空间，以及线程所申请到的I/O设备等。
4．独立性
在同一进程中的不同线程之间的独立性，要比不同进程之间的独立性低得多。这是因为，
为防止进程之间彼此干扰和破坏，每个进程都拥有独立的地址空间和其他资源，它们除了共享
全局变量外，不允许自身以外的进程访问自己地址空间中的地址。但是同一进程中的不同线
程，往往是为了提高并发性以及满足进程间的合作需求而创建的，它们可以共享进程的内存地
址空间和资源，如每个线程都可以访问它们所属进程地址空间中的所有地址，一个线程的堆栈
可以被其他线程读/写，甚至完全清除。由一个线程打开的文件，可以供其他线程读/写。
5．系统开销
在创建（撤销）进程时，系统要为它分配（向它回收）TCB和其他资源（如内存空间和I/O
设备等）。OS为此所付出的开销，明显大于线程创建/ 撤销时所付出的开销。类似地，在进行进
程切换时，涉及进程上下文的切换，而线程的切换代价则远低于进程的。例如，在Solaris 2 OS
中，进程的创建耗时约为线程的30倍，而进程上下文切换的耗时约为线程的5倍。此外，由于一
个进程中的多个线程具有相同的地址空间，线程之间的同步和通信也比进程简单。因此，在一
些OS中，线程的切换、同步以及通信都无须OS内核的干预。
6．支持多处理机系统
在多处理机系统中，对于传统的进程，即单线程进程，不管有多少处理机，该进程只能
运行在一个处理机上。但对于多线程进程，其可以将一个进程中的多个线程分配到多个处理
机上，并行运行，这无疑能够加速进程的完成。因此，现代多处理机系统都无一例外地引入
了多线程。
2.5.3 线程状态和线程控制块
1．线程执行的 3 个状态
与传统的进程一样，各线程之间也存在着共享资源和相互合作的制约关系，这致使线程在
执行时也具有间断性。相应地，线程在执行时，也具有下述3 种基本状态：①执行状态，指线程
已获得处理机而正在执行； ②就绪状态，指线程已具备各种执行条件，只须再获得CPU便可立
即执行；③阻塞状态，指线程在执行中因某事件而受阻，进而处于暂停状态，例如，当一个线
程执行从键盘读入数据的系统调用时，该线程就会被阻塞。线程状态之间的转换和进程状态之
间的转换是一样的，如图2-6所示。

--- Page 87 ---
66
计算机操作系统 （慕课版）
2．线程控制块
如同每个进程有一个PCB一样，系统也为每个线程配置了一个TCB，将所有用于控制和管
理线程的信息均记录在TCB中。TCB中通常含有：①线程标识符，为每个线程赋予一个唯一的
线程标识符；②一组寄存器（包括程序计数器、状态寄存器和通用寄存器等）的内容；③线程
执行状态，描述线程正处于何种执行状态；④优先级，描述线程执行的优先程度；⑤线程专有
存储区，用于在线程切换时存放现场保护信息和与该线程相关的统计信息等；⑥信号屏蔽，即
对某些信号加以屏蔽；⑦堆栈指针，线程在执行时，经常会进行过程调用，而过程调用时通常
会出现多重嵌套的情况，这样，就必须把每次过程调用中所使用的局部变量以及返回地址保存
起来。为此，应为每个线程设置一个堆栈，用它来保存局部变量和返回地址。相应地，在TCB
中，也须设置两个指向堆栈的指针：指向用户自己堆栈的指针和指向核心栈的指针。前者是指
当线程运行在用户态时，使用用户自己的用户栈来保存局部变量和返回地址；后者是指当线程
运行在内核态时，使用系统的核心栈来保存局部变量和返回地址。
3．多线程 OS 中的进程属性
多线程OS中的进程通常都包含多个线程，并会为它们提供资源。OS支持一个进程中的多个
线程并发执行，但此时的进程已不再是一个执行的实体。多线程OS中的进程具有以下属性。
（1）进程是一个可拥有资源的基本单位 。在多线程OS中，进程仍作为系统资源分配的基
本单位，任一进程所拥有的资源包括：用户的地址空间、实现进程（线程）间同步和通信的机
制、已打开的文件和已申请到的 I/O设备以及一张由核心进程维护的地址映射表，该表用于实现
用户程序的逻辑地址到其内存物理地址的映射。
（2）多个线程可并发执行。通常一个进程含有若干个相对独立的线程，其数目可多可少，
但至少要有一个线程。由进程为这些（个）线程提供资源和运行环境，以使它们能并发执行。
在OS中的所有线程都只能属于某一个特定进程。实际上，现在把传统进程的执行方法称为单
线程方法，如传统的UNIX系统能支持多用户进程，但只能支持单线程方法。将每个进程支持
多个线程执行的方法，称为多线程方法，例如，Java的运行环境是单进程多线程的，Windows 
2000、Solaris、Mach等的运行环境则是多进程多线程的。
（3）进程已不是可执行的实体 。在多线程OS中，把线程作为独立运行（或称调度）的基
本单位。此时的进程已不再是一个基本的可执行实体。虽然如此，进程仍具有与“执行”相关
的状态。例如，进程处于“执行”状态，实际上是指该进程中的某线程正在执行。此外，对进
程所施加的、与进程状态有关的操作，也会对其线程起作用。例如，在把某个进程挂起时，该
进程中的所有线程也都将被挂起；再如，在把某个进程激活时，属于该进程的所有线程也都将
被激活。
2.6 线程的实现
2.6.1 线程的实现方式
线程已在许多系统中实现，但各系统中实现的方式并不完全相同。在有的系统中，特别
是在一些数据库管理系统（如infomix）中，所实现的是用户级线程；而在另一些系统中，如
Windows XP、 Linux、Mac OS X 和OS/2等，所实现的是内核支持线程；此外，在Solaris等系统
中，所实现的则是这两种线程的组合。
多线程模型


--- Page 88 ---
67
第
2章 
进程的描述与控制
1．内核支持线程
在OS中的所有进程，无论是系统进程还是用户进程，都是在OS内核的支持下运行的，是与
内核紧密相关的。而内核支持线程（kernel supported thread， KST），同样也是在内核的支持下
运行的，它们的创建、阻塞、撤销和切换等也都是在内核空间实现的。为了对内核支持线程进
行控制和管理，在内核空间也为每个内核支持线程设置了一个TCB，内核根据该TCB来感知某
线程的存在，并对其加以控制。当前大多数OS都支持KST。
KST的实现方式有4个主要优点：①在多处理机系统中，内核能够同时调度同一进程中的多
个线程并行运行；②如果进程中的一个线程被阻塞，则内核可以调度该进程中的其他线程来占
有处理机并运行，也可运行其他进程中的线程；③内核支持线程具有很小的数据结构和堆栈，
线程的切换比较快，切换开销小；④内核本身也可以采用多线程技术，可以提高系统的执行速
度和效率。
内核支持线程的主要缺点是：对于用户的线程切换而言，其模式切换的开销较大；在同一
个进程中，从一个线程切换到另一个线程时需要从用户态转到内核态进行，这是因为用户进程
的线程在用户态运行，而线程调度和管理是在内核中实现的，系统开销较大。
2．用户级线程
用户级线程（user level thread， ULT）是在用户空间中实现的，其对线程的创建、撤销、同
步与通信等功能都无须内核支持，即ULT与内核无关。一个系统中的ULT数目可以达到数百个甚
至数千个。由于这些线程的TCB都设置在用户空间，而线程所执行的操作又无须内核支持，因
而内核完全不知道ULT的存在。
值得说明的是，对于设置了ULT 的系统，其调度仍是以进程为单位进行的。在采用时间片
轮转调度算法时，各个进程轮流执行一个时间片，这对于各进程而言貌似是公平的，但假如
在进程A中包含了1个ULT，而在进程B 中包含了100个 ULT，那么，进程A 中线程的运行时间将
会是进程B 中各线程运行时间的100倍；相应地，进程A 的运行速度也要快上100倍，因此说实
质上并不公平。
假如系统中设置的是KST，则调度便会以线程为单位进行。在采用时间片轮转调度算法
时，各个线程轮流执行一个时间片。同样假定进程 A中只有1个KST，而进程B中有100个KST。
此时，进程B可以获得的CPU时间是进程A的100倍，且进程B可使100个系统调用并发执行。
使用ULT方式有许多优点，介绍如下。①线程切换不需要转换到内核空间。对一个进程而
言，其所有线程的管理数据结构均在该进程的用户空间中，管理线程切换的线程库也在用户空
间运行，因此进程不用切换到内核方式来做线程管理，从而节省了模式切换的开销。②调度算
法可以是进程专用的。在不干扰OS调度的情况下，不同的进程可以根据自身需要选择不同的调
度算法，以对自己的线程进行管理和调度，而与OS的低级调度算法无关。③用户级线程的实现
与OS平台无关，因为面向线程管理的代码属于用户程序的一部分，所有的应用程序都可以共享
这段代码。因此，ULT甚至可以在不支持线程机制的OS平台上实现。
使用ULT方式的主要 缺点介绍如下。①系统调用的阻塞问题。在基于进程机制的OS中，
大多数系统调用都会使进程阻塞，因此，当线程执行一个系统调用时，不仅该线程会被阻塞，
而且进程内的所有线程均会被阻塞。而在KST 方式下，进程中的其他线程仍然可以运行。②在
单纯的ULT实现方式中，多线程应用不能利用多处理机可以进行多重处理的这一优点。内核每
次分配给一个进程的仅有一个CPU，因此，进程中仅有一个线程能执行，在该线程放弃CPU之
前，其他线程只能等待。

--- Page 89 ---
68
计算机操作系统 （慕课版）
3．两种线程的组合方式
有些OS把ULT和KST这两种线程进行组合，提供了组合方式的ULT/KST线程。在组合方式
线程系统中，内核支持多个KST 的建立、调度和管理，同时也允许用户应用程序建立、调度和
管理ULT。一些KST对应多个ULT，这是ULT通过时分多路复用KST来实现的，即将ULT对部分
或全部KST进行多路复用，并且程序员可按应用需要和机器配置对KST的数目进行调整，以达到
较好的效果。在组合方式线程中，同一个进程内的多个线程可以同时在多处理机上并行执行，
而且在阻塞一个线程时，并不需要将整个进程阻塞。因此，组合方式多线程模型能够结合 ULT
和KST两者的优点，并克服它们各自的不足。由于ULT 和KST的连接方式不同，从而形成了3 种
不同的多线程模型：多对一模型、一对一模型和多对多模型。
（1）多对一模型，将多个ULT映射到一个KST上。如图2-16（a）所示，这些ULT一般属于
一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完
成的。仅当 ULT需要访问内核时，才会将其映射到一个KST 上，但每次只允许一个线程进行映
射。该模型的主要优点是：线程管理的开销小，效率高。其主要缺点是：如果一个线程在访问
内核时发生阻塞，则整个进程都会被阻塞；此外，在任一时刻，只有一个线程能够访问内核，
多个线程不能同时在多个处理机上运行。
（2）一对一模型，将每个ULT映射到一个KST上。如图2-16（b）所示，为每个ULT都设置
了一个KST 与之连接。该模型的主要优点是：当一个线程阻塞时，允许调度另一个线程运行，
所以它提供了比多对一模型更好的并发性能。此外，在多处理机系统中，它允许多个线程并
行地运行在多处理机系统上。该模型的唯一缺点是：每创建一个 ULT，相应地就需要创建一个
KST，开销较大，因此需要限制整个系统的线程数。Windows 2000 、Windows NT、OS/2等系统
上都实现了该模型。
（3）多对多模型，将许多ULT映射到同样数量或较少数量的KST上。如图2-16（c）所示，
KST的数目可以根据应用进程和系统的不同而变化，其可以比ULT数少，也可以与之相等。该模
型结合了上述两种模型的优点，它可以像一对一模型那样使一个进程的多个线程并行地运行在
多处理机系统上，也可以像多对一模型那样减少线程管理开销并提高效率。
用户空间
ULT ULT ULT
KST KST KST
核心空间
用户空间
核心空间
用户空间
核心空间
（a）多对一模型 （b）一对一模型 （c）多对多模型
图2-16  组合方式多线程模型
什么时候多线程进程比单线程进程性能好？什么时候多线程进程比单线程进程性能差？
思考题

--- Page 90 ---
69
第
2章 
进程的描述与控制
2.6.2 线程的具体实现
不论是进程还是线程，都必须直接或间接地取得内核的支持。由于KST可以直接利用系统
调用为它服务，故其对应的线程控制相当简单；而 ULT则必须借助于某种形式的中间系统的帮
助方能取得内核的服务，故其对应的线程控制要较复杂。
1．KST 的实现
在仅设置了KST的OS中，一种可能的线程控制方法是，系统在创建一个新进程时，便为它
分配一个任务数据区（per task data area， PTDA），其中包括若干个TCB空间，如图2-17所示。
在每个TCB中可保存线程标识符、优先级、线程运行的CPU状态等信息。虽然这些信息与ULT的
TCB中的信息相同，但它们被保存在了内核空间中。
PTDA
TCB　#1
TCB　#2
TCB　#3
进程资源
图2-17  一个任务数据区
每当进程要创建一个线程时，便会为新线程分配一个TCB，同时将有关信息填入该TCB
中，并为之分配必要的资源，如为线程分配数百至数千个字节的栈空间和局部存储区，于是新
创建的线程便有条件立即执行。当PTDA中的所有TCB空间已用完而进程又要创建新的线程时，
只要其所创建的线程数目未超过系统的允许值（通常为数十至数百个），系统即可再为之分配
新的TCB空间；在撤销一个线程时，也应回收该线程的所有资源和TCB。由此可见，KST的创建
和撤销均与进程的相似。在有的系统中，为了减少在创建和撤销一个线程时的开销，在撤销一
个线程时，并不会立即回收该线程的资源和TCB，这样，当以后再要创建一个新线程时，便可
直接将已被撤销但仍持有资源的TCB作为新线程的TCB。
KST的调度和切换与进程的调度和切换十分相似，也分抢占式和非抢占式两种。线程的调
度同样可采用时间片轮转调度算法、优先级调度算法等。当线程调度选中一个线程后，便会将
处理机分配给它。当然，线程在调度和切换上所花费的开销要比进程的小得多。
2．ULT 的实现
ULT是在用户空间实现的。所有ULT 都具有相同的结构，它们都运行在一个中间系统上。
当前有两种方式实现的中间系统，即运行时系统与核心线程。
（1）运行时系统。
所谓运行时系统（ runtime system ），实质上是用于管理和控制线程的函数（过程）的集
合，其中包括用于创建和撤销线程的函数、用于控制线程同步和通信的函数以及用于实现线程
调度的函数等。正因为有这些函数，才能使 ULT与内核无关。运行时系统中的所有函数都驻留
在用户空间，并作为ULT与内核之间的接口。
在传统OS中，进程在切换时必须先由用户态转为内核态，再由核心线程来执行切换任务；  
而ULT在切换时则无须转入内核态，而是由运行时系统中的线程切换过程来执行切换任务，该
过程将线程的CPU状态保存在该线程的堆栈中，然后按照一定的算法选择一个处于就绪状态的
新线程运行，并将新线程堆栈中的CPU状态装入CPU相应的寄存器中，一旦将栈指针和程序计

--- Page 91 ---
70
计算机操作系统 （慕课版）
数器切换后，便开始了新线程的运行。由于 ULT的切换无须进入内核，且切换操作简单，因而
其切换速度非常快。
不论是在传统OS中，还是在多线程OS中，系统资源都是由内核管理的。在传统OS中，进
程是利用OS提供的系统调用来请求系统资源的，系统调用通过软中断（如trap）机制进入OS内
核，由内核来完成相应资源的分配。 ULT是不能利用系统调用的。当线程需要系统资源时，其
须将该要求传送给运行时系统，由后者通过相应的系统调用来获得系统资源。
（2）核心线程。
核心线程又称为LWP。每一个进程都可拥有多个LWP 。同ULT一样，每个LWP都有自己的
数据结构（如TCB），其中包括线程标识符、优先级、CPU状态等信息，另外还有栈和局部存
储区等。LWP也可以共享进程所拥有的资源。LWP 可通过系统调用来获得内核提供的服务，这
样，当一个ULT运行时，只须将它连接到一个LWP上，它便能具有KST的所有属性。这种线程实
现方式就是组合方式。
一个系统中的ULT 数量可能很大，为了节省系统开销，不可能设置太多的LWP ，而是会
把这些LWP 做成一个缓冲区，称之为“线程池”。用户进程中的任一ULT 都可以连接到线程
池中的任一LWP 上。为使每一个ULT 都能利用LWP 与内核通信，可以使多个ULT 多路复用一
个LWP，但只有当前连接到LWP 上的ULT才能与内核通信，其余线程或阻塞、或等待LWP 。
而每个LWP 都要连接到一个KST上，这样，通过LWP 即可把ULT 与KST连接起来，ULT 可通
过LWP 来访问内核，但内核所看到的总是多个LWP 而非ULT 。亦即，由LWP 实现了内核与
ULT之间的隔离，从而使ULT 与内核无关。图2-18所示为将LWP 作为中间系统时ULT 的实现
方法。
任务1 任务2 任务3
ULT
LWP
CPU
内核
KST
图2-18  将LWP作为中间系统时ULT的实现方法
当ULT不需要与内核通信时，并不需要LWP ；而当其要通信时，便须借助 LWP，而且每个
要通信的ULT都需要一个LWP。例如，在一个任务中，如果同时有5个ULT发出了对文件的读/写
请求，这就需要有5个LWP来予以帮助，即由LWP将对文件的读/写请求发送给相应的KST，再由
后者执行具体的读/写操作。如果一个任务中只有4个LWP，则只能有4个ULT的读/写请求被传送
给KST，余下的1个ULT必须等待。
在KST执行操作时，如果其发生阻塞，则与之相连接的多个LWP 也将随之阻塞，进而使连
接到LWP上的ULT也被阻塞。如果进程中只包含一个LWP ，此时进程也会阻塞。这种情况与前
述的传统OS一样，在进程执行系统调用时，该进程实际上是阻塞的。但如果一个进程中含有多
个LWP，则当一个LWP阻塞时，进程中的另一个LWP 可以继续执行；即使进程中的所有LWP 全
部阻塞，进程中的线程也仍能继续执行，只是不能再去访问内核而已。

--- Page 92 ---
71
第
2章 
进程的描述与控制
2.6.3 线程的创建与终止
如同进程一样，线程也是有生命期的，它由创建而产生、由终止而消亡。相应地，在OS 中
也就有用于创建线程的函数（或系统调用）和用于终止线程的函数（或系统调用）。
1．线程的创建
应用程序在启动时，通常仅有一个线程在执行，我们把该线程称为“初始化线程”，它的
主要功能是创建新线程。在创建新线程时，需要利用一个线程创建函数（或系统调用），并提
供相应的参数，如指向线程主程序入口的指针、堆栈的大小以及用于调度的优先级等。在线程
的创建函数执行完后，将返回一个线程标识符供以后使用。
2．线程的终止
当一个线程完成了自己的任务（工作）后，或是线程在运行中出现异常情况而须被强行终
止时，由终止线程通过调用相应的函数（或系统调用）对它执行终止操作。但有些线程（主要
是系统线程）一旦被建立起来之后，便会一直运行下去而不被终止。在大多数OS中，线程被终
止后并不会立即释放它所占有的资源，只有当进程中的其他线程执行了分离函数后，被终止的
线程才会与资源分离，此时的资源才能被其他线程利用。
已被终止但尚未释放资源的线程，仍可被需要它的线程所调用，以使其重新恢复运行。为
此，调用线程须调用一条被称为“等待线程终止”的连接命令，以与该线程进行连接。当一个
调用线程调用“等待线程终止”的连接命令而试图与指定线程相连接时，若指定线程尚未被终
止，则调用连接命令的线程将会阻塞，直至指定线程被终止后，其才能与指定线程进行连接并
继续执行；若指定线程已被终止，则调用线程不会被阻塞，而是会继续执行。
2.7 本章小结
本章从程序的执行方式入手，先后引入了OS中的两个重要概念：进程和线程。程序的执
行方式有顺序执行和并发执行两种。在顺序执行方式下，单个程序独占内存运行，系统的运行
效率低；在并发执行方式下，多个程序占用内存并轮流在CPU上运行，系统的运行效率得到了  
提升。
进程就是指正在运行的程序，它在运行过程中会改变状态，这些状态是根据进程当前的活
动来定义的，包括创建、就绪、运行、阻塞和终止等。OS中的每个进程都是通过与之一一对应
的PCB来实现控制和管理的。进程控制包括：进程创建、进程终止、进程阻塞与唤醒、进程挂
起与激活等，这些控制操作需要用原语的方式来完成。进程间可以相互通信，通信方法多样，
常用的有管道、信号、消息队列、共享内存、信号量、套接字等。
为了提高程序并发执行的程度，引入了比进程更小的单位——线程。引入线程后，在资源
共享、用户响应、经济性和多处理机架构等方面有诸多好处，能够进一步改善系统的性能。引
入线程后，进程是资源分配的单位，线程是CPU调度的单位。线程可分为KST和ULT两种，不同
的系统会支持某一种线程，或者两种都支持。由于ULT 和KST的连接方式不同，形成了3 种不同
的多线程模型：多对一模型、一对一模型和多对多模型。

--- Page 93 ---
72
计算机操作系统 （慕课版）
习题2（含考研真题）
一、简答题
1．什么是前趋图？请画出下列4条语句的前趋图。
    S 1：a=x+y； S 2：b=z+1； S 3：c=a-b； S 4：w=c+1；
2．什么是进程？OS中为什么要引入进程？它会产生什么样的影响？
3．进程最基本的状态有哪些？哪些事件可能会引起不同状态间的转换？
4．为什么要引入进程的挂起状态？
5．叙述组成进程的基本要素，并说明它们的作用。
6．（考研真题）请给出PCB的主要内容。描述当进程状态发生转换（就绪→运行、运行→
阻塞）时，OS需要使用/修改PCB的哪些内容？
7．试说明引起进程创建的主要事件。
8．（考研真题）在创建一个进程时，OS需要完成的主要工作是什么？
9．试说明引起进程终止的主要事件。
10．在终止一个进程时，OS要完成的主要工作是什么？
11．试说明引起进程阻塞或被唤醒的主要事件。
12．试比较进程间的低级与高级通信工具。
13．当前有哪几种高级通信机制？
14．试说明使用管道文件（pipe文件）进行通信的优缺点。
15．试比较直接通信方式和间接通信方式。
16．为什么要在OS中引入线程？
17．试说明线程的属性。
18．何谓用户级线程和内核支持线程？
19．（考研真题）用户级线程和内核支持线程有何区别？
20．试说明用户级线程和内核支持线程的实现方法。
二、综合应用题
21．试从调度、并发、拥有资源和系统开销这4个方面对传统进程和线程进行比较。
22．（考研真题）现代OS一般都提供多进程（或称多任务）运行环境，回答以下问题。
（1）为支持多进程的并发执行，系统必须建立哪些关于进程的数据结构？
（2）为支持进程状态的变迁，系统至少应提供哪些进程控制原语？
（3）在执行每一个进程控制原语时，进程状态会发生什么变化？相应的数据结构会发生什
么变化？


--- Page 94 ---

第3章
在多道程序环境下，内存中存在着多个进程，其数目往往多于处理机数目。这就要求系统
能按某种算法动态地将处理机分配给处于就绪状态的进程，以使之执行。分配处理机的任务是
由处理机调度程序完成的。对于大型系统，其在运行时的性能，如系统吞吐量、资源利用率、
作业周转时间或响应的及时性等，在很大程度上都取决于处理机调度性能的好坏。因此，处理
机调度便成为了OS中至关重要的部分。同样，在多道程序环境中，可能会有多个进程同时竞
争有限数量的资源。当一个进程申请某个资源时，如果没有可用资源，那么该进程就会变为等
待状态；若所申请的资源被其他等待进程占有，那么该等待进程有可能再也无法改变状态。这
种情况称为死锁（deadlock）。如果系统处于死锁状态，进程将无法向前推进。本章将重点介
绍处理机调度与死锁的相关知识与实例。本章知识导图如图3-1所示。
处理机调度与死锁
处理机调度
死锁
处理机调度概述
调度算法
实时调度
调度实例
死锁概述
死锁预防
死锁避免
死锁的检测与解除
先来先服务调度算法
短作业优先调度算法
优先级调度算法
轮转调度算法
多级队列调度算法
多级反馈队列调度算法
基于公平原则的调度算法
银行家算法
图3-1  第3章知识导图
处理机调度与死锁
第3 章导读


--- Page 95 ---
74
计算机操作系统 （慕课版）
3.1 处理机调度概述
在多道程序系统中，调度的实质是一种资源分配，处理机调度是对处理
机进行分配。处理机调度算法是指根据处理机分配策略所规定的处理机分配算
法。在多道批处理系统中，一个作业从提交到获得处理机执行，直至作业运行
完毕，可能需要经历多级处理机调度。下面先来了解处理机调度的层次。
3.1.1 处理机调度的层次
1．高级调度
高级调度（high level scheduling）又称为长程调度或作业调度，它的调度对象是作业，主
要功能是根据某种算法，决定将外存上处于后备队列中的哪几个作业调入内存，为它们创建进
程、分配必要的资源，并将它们放入就绪队列。高级调度主要用于多道批处理系统中，而在分
时系统和实时系统中，不设置高级调度。
2．低级调度
低级调度（low level scheduling）又称为短程调度或进程调度，其所调度的对象是进程（或
LWP）。其主要功能是，根据某种算法，决定就绪队列中的哪个进程应获得处理机，并由分派
程序将处理机分配给被选中的进程。低级调度是最基本的一种调度，在多道批处理、分时和实
时这3种系统中，都必须配置这种调度。
3．中级调度
中级调度（intermediate scheduling）又称为内存调度。引入中级调度的主要目的是提高内存利用
率和系统吞吐量。为此，应把那些暂时不能运行的进程调至外存等待，此时进程的状态称为就绪驻
外存状态（或挂起状态）。当它们已具备运行条件且内存稍有空闲时，由中级调度来决定把外存上
的那些已具备运行条件的就绪进程再重新调入内存，并修改它们的状态为就绪状态，挂在就绪队列
上等待。中级调度实际上就是存储器管理中的对换功能，本书将在第5章中对其进行详细介绍。
在上述3种调度中，低级调度的运行频率最高，在分时系统中通常仅10ms ～100ms便进行一
次低级调度，因此把它称为短程调度。为避免低级调度占用太多的CPU时间，不宜使低级调度
算法太复杂。高级调度（作业调度）往往发生在一批作业已运行完毕退出系统，又需要重新调
入一批作业进入内存的时候。高级调度的周期较长，几分钟一次，因此把它称为长程调度。由
于其运行频率较低，故允许作业调度算法花费较长的时间。中级调度的运行频率基本上介于上
述两种调度之间，因此又把它称为中程调度。
3.1.2 作业和作业调度
在多道批处理系统中，作业是用户提交给系统的一项相对独立的工作。操作员把用户提交
的作业通过相应的输入设备输入磁盘存储器，并保存在一个后备作业队列中，再由作业调度程
序将其从外存调入内存。
1．作业
作业是一个比程序更为广泛的概念，它不仅包含了通常的程序和数据，而且配有一份作业
处理机调度


--- Page 96 ---
75
第
3章 
处理机调度与死锁
说明书，系统根据该说明书对程序的运行进行控制。在多道批处理系统中，会将作业作为基本
单位从外存调入内存。
2．作业控制块
为了管理和调度作业，在多道批处理系统中，为每个作业设置了一个作业控制块（job control 
block，JCB），它是作业在系统中存在的标志，其中保存了系统对作业进行管理和调度所需的全
部信息。JCB中包含的内容通常有：作业标志、用户名称、用户账号、作业类型（CPU繁忙型、
I/O繁忙型、批量型、终端型）、作业状态、调度信息（优先级、作业运行时间）、资源需求情
况（预计运行时间、要求内存大小）、资源使用情况等。
每当一个作业进入系统时，“作业注册”程序便会为该作业建立一个JCB，然后根据作业类
型将其放到相应的作业后备队列中等待调度。调度程序依据一定的调度算法来调度它们，被调度
到的作业将被装入内存。在作业运行期间，系统会按照JCB中的信息和作业说明书对作业进行控
制。当一个作业执行结束并进入完成状态时，系统便会回收已分配给它的资源，并撤销其JCB。
3．作业调度的主要任务
作业调度的主要任务是，根据JCB中的信息，检查系统中的资源能否满足作业的需求，以
及按照一定的调度算法从外存的作业后备队列中选取某些作业调入内存，并为它们创建进程和
分配必要的资源。然后，将新创建的进程排在就绪队列上等待调度。因此，也把作业调度称为
接纳调度（admission scheduling）。在每次执行作业调度时，都须做出以下两个决定。
（1）接纳多少个作业。
在每次进行作业调度时，应当从后备队列中选取多少作业调入内存，取决于多道程序度
（degree of multiprogramming），其表示允许多少个作业同时在内存中运行。对系统而言，其希望
装入内存较多的作业，因为这样有利于提高资源利用率和系统吞吐量。但如果内存中同时运行的
作业太多，那么进程在运行时因内存不足所发生的中断就会急剧增加，这将会使进程的平均周转
时间显著延长，进而影响系统的服务质量。因此，多道程序度的确定方法是：综合考虑计算机系
统规模、计算机运行速度、作业大小以及所能获得的系统性能好坏等情况后，做出适当的抉择。
（2）接纳哪些作业。
应选择后备队列中的哪些作业调入内存，取决于所采用的调度算法。最简单的调度算法是
先来先服务调度算法，它会将最早进入外存的作业优先调入内存。较常用的一种调度算法是短
作业优先调度算法，它会将外存上（执行时间）最短的作业优先调入内存。另一种较常用的调
度算法是基于作业优先级的调度算法，它会将外存上作业优先级最高的作业优先调入内存。调
度性能比较好的一类调度算法是“响应比高者优先”的调度算法。 3.2节中将会对上述几种算法
做较详细的介绍。
3.1.3 进程调度
进程调度是OS中必不可少的一种调度，因此在3 种类型的OS中都无一例外地配置了进程调
度。此外，它也是对系统性能影响最大的一种处理机调度，相应地，有关进程调度的算法也比
较多。
1．进程调度任务
进程调度的任务主要有三。 ①保存CPU现场信息。在进行进程调度时，首先需要保存当前

--- Page 97 ---
76
计算机操作系统 （慕课版）
进程的CPU现场信息，如程序计数器、多个通用寄存器等中的内容。 ②按某种算法选取进程 。
调度程序须按某种算法从就绪队列中选取一个进程，将其状态改为运行状态，并准备把CPU分
配给它。③把CPU分配给进程 。由分派程序把CPU分配给该进程，此时需要将选中进程的PCB
内有关CPU的现场信息装入CPU相应的各个寄存器中，并把CPU的控制权交给该进程，以使其
能够从上次的断点处恢复运行。
2．进程调度机制
为了实现进程调度，在进程调度机制（如图3-2所示）中，应具有以下3个基本部分。
来自其他状态
就绪进程
移出运行进程
PCB
排队器 就绪队列
调度程序
CPU分派器 上下文切换器
图3-2  进程调度机制
（1）排队器。为了提高进程调度的效率，应事先将系统中的所有就绪进程，按照一定的策
略排成一个或多个队列，以便调度程序能最快地找到它们。以后每当有一个进程转变为就绪状
态时，排队器便将它插入相应的就绪队列。
（2）分派器。分派器将进程调度程序所选定的进程从就绪队列中取出，然后进行从分派器
到新选进程间的上下文切换，以将CPU分配给新选进程。
（3）上下文切换器 。在对处理机进行切换时，会发生两对上下文的切换操作：①第一对
上下文切换时，OS将保存当前进程的上下文，即把当前进程的CPU寄存器内容保存到该进程的
PCB内的相应单元，而装入分派程序的上下文，则可以方便分派程序运行；②第二对上下文切
换是移出分派程序的上下文，把新选进程的CPU现场信息装入CPU的各个相应寄存器中，以便
新选进程运行。
在进行上下文切换时，需要执行大量的load和store等操作指令，以保存寄存器的内容。即使
是现代计算机，用每次上下文切换所花费的时间大约也可以执行上千条指令。为此，现在已有
通过硬件实现来减少上下文切换时间的方法了，一般采用两组（或多组）寄存器，其中一组寄
存器供处理机在内核态时使用，而另一组寄存器供应用程序使用。在这样的条件下的上下文切
换，只须改变指针以使其指向当前寄存器组即可。
3．进程调度方式
早期所采用的非抢占调度方式（non-preemptive mode）存在着很大的局限性，很难满足交互
性作业和实时任务的需求。为此，在进程调度中又引入了抢占调度方式（preemptive mode）。下
面分别对它们进行介绍。
（1）非抢占调度方式。
在采用非抢占调度方式时，一旦把处理机分配给某进程，就会一直让它运行下去，而决
不会因为时钟中断或其他原因去抢占该进程的处理机，直至该进程完成或发生某事件而被阻塞

--- Page 98 ---
77
第
3章 
处理机调度与死锁
时，才会把分配给该进程的处理机分配给其他进程。
在采用非抢占调度方式时，可能会引起进程调度的因素可归结为：①正在执行的进程运行
完毕，或因发生某事件而使其无法继续运行；②正在执行的进程因提出I/O请求而暂停执行；  
③在进程通信或同步过程中执行了某种原语操作，如Block原语。非抢占调度方式的优点是实现
简单、系统开销小，其适用于大多数批处理系统。但它不能用于分时系统和大多数实时系统。
（2）抢占调度方式。
抢占调度方式允许调度程序根据某种原则去暂停某个正在执行的进程，并将已分配给该进程
的处理机重新分配给另一进程。在现代OS中广泛采用抢占调度方式，这是因为：对于批处理机系
统，抢占调度方式可以防止一个长进程长时间地占用处理机，以确保处理机能为所有进程提供更
为公平的服务。在分时系统中，只有采用抢占调度方式才有可能实现人机交互。在实时系统中，
抢占调度方式能满足实时任务的需求。但抢占调度方式比较复杂，所须付出的开销也较大。
“抢占”不是一种任意性行为，必须遵循一定的原则，主要原则有： ①优先级原则 ，允
许优先级高的新到进程抢占当前进程的处理机，即当有新进程到达时，如果它的优先级比当前
进程的优先级高，则调度程序将剥夺当前进程的运行，并将处理机分配给新到进程； ②短进程
优先原则，允许新到的短进程抢占当前长进程的处理机，即当新到进程比当前进程（尚须运行
的时间）明显短时，将处理机分配给新到的短进程； ③时间片原则，各进程按时间片轮转运行
时，当正在执行的进程的一个时间片用完后，便停止该进程的执行而重新进行调度。
抢占调度方式和非抢占调度方式各适用于什么场景下？
思考题
3.1.4 处理机调度算法的目标
一般而言，在设计一个OS时应如何选择调度算法，这在很大程度上取决于OS的类型及其设
计目标，例如，在批处理系统、分时系统和实时系统中，通常会采用不同的调度算法。
1．处理机调度算法的共同目标
（1）资源利用率。为了提高系统的资源利用率，应使系统中的处理机和其他所有资源都尽
可能地保持忙碌状态，其中最重要的资源——CPU的利用率可用以下公式计算。
（2）公平性。公平性是指应使各进程都获得合理的CPU时间，以防止发生进程饥饿现象。
公平性是相对的，相同类型的进程应获得相同的服务；但对于不同类型的进程，由于它们的紧
急程度或重要性不同，为它们提供的服务也应不同。
（3）平衡性。系统中可能具有多种类型的作业，有的属于CPU繁忙型作业，有的属于I/O
繁忙型作业。为使系统中的 CPU和各种I/O设备都能经常处于忙碌状态，调度算法应尽可能保证
系统资源使用的平衡性。
（4）策略强制执行。对于所制定的策略（其中包括安全策略），只要有需要，就必须予以
准确的执行，即使会造成某些工作的延迟也要执行。
2．批处理系统中处理机调度算法的目标
（1）平均周转时间短。所谓周转时间（亦称为作业周转时间），是指从作业被提交给系统

--- Page 99 ---
78
计算机操作系统 （慕课版）
开始到作业完成为止的这段时间间隔。它包括4 部分时间：作业在外存后备队列上等待作业调度
的时间，进程在就绪队列上等待进程调度的时间，进程在CPU上执行所耗费的时间，以及进程
等待I/O操作完成的时间。其中，后3项在一个作业的整个处理过程中可能会发生多次。
对每个用户而言，他们都希望自己作业的周转时间最短。但作为计算机系统的管理者，则
总是希望作业的平均周转时间最短，因为这不仅可以有效提高系统资源的利用率，还可以使大
多数用户都感到满意。事实上，计算机系统的管理者应使作业的周转时间和作业的平均周转时
间都尽可能短，否则，许多用户的等待时间过长会引起他们（特别是短作业用户）的不满。可
把平均周转时间表示为：
。
为了进一步反映调度的性能，以更清晰地描述各进程在周转时间中“等待时间和执行时
间”的具体分配状况，引入了带权周转时间，即作业的周转时间 Ti与系统为它提供服务的时间
之比，表示为Wi=Ti/
 。因此，平均带权周转时间可表示为：
。
（2）系统吞吐量高 。系统吞吐量是指单位时间内系统所完成的作业数，因而它与批处理
作业的平均长度有关。事实上，如果仅为了获得高的系统吞吐量，则应尽量多地选择短作业  
运行。
（3）处理机利用率高。对于大、中型计算机，CPU价格十分昂贵，致使处理机的利用率成
为了衡量系统性能的重要指标；而调度算法又对处理机的利用率起着十分重要的作用。如果仅
为了使处理机的利用率高，则应尽量多地选择计算量大的作业运行。
综上所述可知，这些目标的实现之间存在着一定的矛盾。
3．分时系统中处理机调度算法的目标
（1）保证响应时间快 。响应时间快是选择分时系统中进程调度算法的重要准则。所谓响
应时间，是指从用户通过键盘提交一个请求开始，到屏幕上显示出处理结果为止的这段时间间
隔。它包括3部分时间：请求信息从键盘输入开始直至传送到处理机的时间，处理机对请求信息
进行处理的时间，以及将所形成的响应信息回送到终端显示器的时间。
（2）保证均衡性。用户对响应时间的要求并非完全相同。通常用户对较复杂任务的响应时
间允许较长，而对较简单任务的响应时间要求较短。所谓均衡性是指，系统响应时间的快慢应
与用户所请求服务的复杂性相适应。
4．实时系统中处理机调度算法的目标
（1）保证满足截止时间的要求。所谓截止时间，是指某任务必须开始执行的最迟时间，或
必须完成的最迟时间。对于严格的实时系统而言，其调度算法必须要保证这一点，否则将会造
成难以预料的后果。对于实时系统而言，调度算法的一个主要目标是保证实时任务满足截止时
间的要求。对于HRT 任务，其调度算法必须满足截止时间的要求，否则将会造成难以预料的后
果；而对于SRT任务，其调度算法也应基本上满足截止时间的要求。
（2）保证可预测性。在实时系统中，可预测性显得非常重要。例如，在多媒体系统中，无
论是电影还是电视剧，都应是连续播放的，这就保证了请求的可预测性。如果系统中采用了双
缓冲区，则因为可实现第i帧播放和第i+1帧读取的并行处理，所以可提高系统的实时性。

--- Page 100 ---
79
第
3章 
处理机调度与死锁
3.2 调度算法
3.2.1 先来先服务调度算法
先来先服务（first come first server，FCFS）调度算法是最简单的调度算法，
该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法
时，系统将按照作业到达的先后次序来进行调度，或者说它会优先考虑在系统中等待时间最长的
作业，而不管该作业执行时间的长短。FCFS调度算法会从后备作业队列中选择几个最先进入该队
列的作业，将它们调入内存，并为它们分配资源和创建进程；最后，把它们放入就绪队列。
当在进程调度中采用FCFS调度算法时，每次调度都是从就绪的进程队列中选择一个最先进
入该队列的进程，并为之分配处理机，使之投入运行。在该进程一直运行到完成或发生某事件
而阻塞后，进程调度程序才会将处理机分配给其他进程。
需要补充说明的是，FCFS调度算法在单处理机系统中已很少作为主调度算法了，但通常会将
它与其他调度算法结合使用，进而形成一种更为有效的调度算法。例如，可以在系统中按进程的
优先级设置多个队列，每个优先级对应一个队列，其中每个队列的调度都基于FCFS调度算法。
3.2.2 短作业优先调度算法
由于在实际情况中，短作业（进程）占有很大比例，为了使它们能比长作业优先执行，产
生了短作业优先（short job first，SJF）调度算法。
1．SJF 调度算法简介
SJF调度算法是以作业的长短来计算优先级的，作业越短，其优先级越高。作业的长短是以
作业所要求的运行时间来衡量的。SJF调度算法可以分别用于作业调度和进程调度。当把SJF调
度算法用于作业调度时，它将从外存的作业后备队列中选择估计运行时间最短的作业，并优先
将它调入内存运行。当SJF调度算法用于进程调度时，它将从就绪队列中选择估计运行时间最短
的进程，并为之分配CPU运行。
2．SJF 调度算法的缺点
SJF调度算法较FCFS调度算法有了明显的改进，但仍然存在不容忽视的缺点，介绍如下。
①必须预先知道作业的运行时间。当采用SJF调度算法时，要预先知道每个作业的运行时间，但
即便是程序员也很难对其进行准确估计；如果估计偏短，系统就可能会按估计的时间终止作业
的运行，但此时作业并未完成，故一般都会偏长估计。②对长作业非常不利，长作业的周转时
间会明显增长。更严重的是，SJF调度算法完全忽视作业的等待时间，这可能会使作业的等待时
间过长，进而出现饥饿现象。③当采用FCFS调度算法时，无法实现人机交互。④SJF调度算法
完全没有考虑作业的紧迫程度，故不能保证紧迫性作业能得到及时处理。
3.2.3 优先级调度算法
我们可以这样来看进程或作业的优先级。对于FCFS调度算法，进程的等待时间就是进程的
优先级，等待时间越长，其优先级越高。对于 SJF调度算法，进程的长短就是进程的优先级，进
程所须运行的时间越短，其优先级越高。但上述两种优先级，都不能反映进程的紧迫程度。而
优先级调度算法（priority-scheduling algorithm）是基于进程的紧迫程度，由外部赋予进程相应的
典型调度算法


--- Page 101 ---
80
计算机操作系统 （慕课版）
优先级的，其会根据该优先级进行调度。这样就可以保证紧迫性进程优先运行。优先级调度算
法可用于作业调度，也可用于进程调度。当把该算法用于作业调度时，系统将从后备队列中选
择优先级最高的作业装入内存。当把该算法用于进程调度时，系统将从就绪队列中选择具有最
高优先级的进程在CPU上运行。
1．优先级调度算法的类型
优先级调度算法，是把处理机分配给就绪队列中优先级最高的进程。因此，可进一步把该
算法分成以下两种。
（1）非抢占式优先级调度算法。该算法规定，一旦把处理机分配给就绪队列中优先级最高
的进程，该进程便会一直执行下去直至完成，或者当该进程因发生某事件而放弃处理机时，系
统方可将处理机重新分配给优先级次高的进程。
（2）抢占式优先级调度算法。该算法规定，在把处理机分配给优先级最高的进程并使之执
行时，只要出现了另一个优先级更高的进程，调度程序就会将处理机分配给新到的优先级更高
的进程。因此，在采用这种调度算法时，每当系统中出现一个新的就绪进程i时，系统就会将其优
先级Pi同正在执行的进程j的优先级Pj进行比较，如果Pi≤Pj，则原进程j继续执行；但如果Pi＞Pj，
则立即停止原进程j的执行并进行进程切换，使新进程i投入执行。抢占式优先级调度算法常用于
对实时性要求较高的系统中。
2．优先级的类型
优先级调度算法的关键在于如何确定进程的优先级，以及如何确定应当使用静态优先级，
还是动态优先级。
（1）静态优先级 。静态优先级是在创建进程时确定的，其在进程的整个运行期间保持不
变。优先级是利用某一范围内的一个整数（如0 ～255的某一整数）来表示的，我们把该整数称
为优先数。确定进程优先级大小的依据有3 个：①进程类型，通常系统进程（如接收进程、对换
进程等）的优先级要高于一般用户进程的优先级；②进程对资源的需求，对资源要求少的进程
应被赋予较高的优先级；③用户要求，根据进程的紧迫程度以及用户所付费用的多少，确定优
先级。静态优先级这一方法简单易行，系统开销小，但不够精确，可能会出现优先级低的进程
长期未被调度的情况。
（2）动态优先级 。动态优先级是指在创建进程之初，先赋予进程一个优先级，然后优先
级会随进程的推进或等待时间的增加而改变，以便获得更好的调度性能。例如，可以规定在就
绪队列中的进程，其优先级能随等待时间的增长而提高。若所有的进程都具有相同的优先级初
值，则最先进入就绪队列的进程会因优先级变得更高而优先获得处理机，这相当于FCFS 调度算
法。若所有的就绪进程均具有各不相同的优先级初值，那么对于优先级初值较低的进程，在等
待了足够长的时间后也可获得处理机。当采用抢占式优先级调度算法时，若再规定当前进程的
优先级随运行时间的推移而下降，则可防止一个长作业长期垄断处理机。
3．高响应比优先调度算法
高响应比优先（highest response ratio next ，HRRN）调度算法是优先级调度算法的一个特
例，通常用于作业调度。在批处理系统中，FCFS 调度算法所考虑的只是作业的等待时间，而忽
视了作业的运行时间。而SJF调度算法正好相反，其只考虑了作业的运行时间，而忽视了作业的
等待时间。HRRN调度算法则是既考虑了作业的等待时间，又考虑了作业的运行时间，因此其既
照顾了短作业，又不会致使长作业的等待时间过长，从而改善了处理机调度的性能。

--- Page 102 ---
81
第
3章 
处理机调度与死锁
HRRN调度算法是如何实现的呢？如果能为每个作业引入一个动态优先级，即优先级是可以
改变的，例如令它能够随等待时间的延长而增加，那么长作业的优先级就会在等待期间不断提
高，且在等待足够长的时间后，长作业其必然会获得处理机。该优先级的变化规律可表示为：
优先级 =
  。
由于等待时间与要求服务时间之和就是系统对该作业的响应时间，故该优先级又相当于响
应比RP，其可表示为：
RP=
 。
由上式可以看出：①如果作业的等待时间相同，则要求服务时间越短，优先级越高，此时
HRRN调度算法类似于 SJF调度算法，有利于短作业；②当作业的要求服务时间相同时，其优先
级又取决于等待时间，此时HRRN调度算法又类似于FCFS调度算法；③对于长作业的优先级，
其可随等待时间的增加而提高，当作业的等待时间足够长时，其也可获得处理机。因此HRRN调
度算法实现了较好的折中。当然在利用该算法时，每次调度之前都需要先计算响应比，这显然
会增加系统的开销。
3.2.4 轮转调度算法
在分时系统中，最简单也是较常用的进程调度算法是基于时间片的轮转（round robin，RR）
调度算法。该算法采取了非常公平的处理机分配方式，即让就绪队列上的每个进程每次仅运行一
个时间片。如果就绪队列上有n个进程，则每个进程每次大约可获得1/n的处理机时间。
1．RR 调度算法的基本原理
在RR调度算法中，系统会将所有的就绪进程按FCFS策略排成一个就绪队列。系统可设置每
隔一定时间（如30ms）便产生一次中断，去激活进程调度程序进行调度，把处理机分配给队首
进程，并令其执行一个时间片。当它运行完后，再把处理机分配给就绪队列中新的队首进程，
同样地让它也执行一个时间片。这样，就可以保证就绪队列中的所有进程，在确定的时间段
内，都能获得一个时间片的处理机时间。
2．进程切换时机
在RR调度算法中，应在何时进行进程切换，可分为两种情况。①若一个时间片尚未用完而正
在运行的进程便已经完成，则立即激活调度程序，将已经运行完成的进程从就绪队列中删除，再
调度就绪队列中新的队首进程运行，并启动一个新的时间片。②当一个时间片用完时，计时器中
断处理程序会被激活，此时，如果进程尚未运行完毕，调度程序就把它送往就绪队列的末尾。
3．时间片大小的确定
在RR调度算法中，时间片的大小对系统性能有很大的影响。若选择很小的时间片，则将有
利于短作业，因为它能在该时间片内完成。但是，若时间片选择得太小，则意味着系统会频繁
地执行进程调度和进程上下文的切换，这无疑会增加系统的开销；若时间片选择得太大，且为
使每个进程都能在一个时间片内完成，RR调度算法便会退化为FCFS调度算法，无法满足短作业
和交互式用户的需求。一个较为可取的时间片大小是略大于一次典型的交互所需要的时间，使
大多数交互式进程能在一个时间片内完成，从而可以获得很小的响应时间。图 3-3所示为时间片

--- Page 103 ---
82
计算机操作系统 （慕课版）
大小对响应时间的影响，图3-3（a）所示为时间片大于典型交互的时间，图3-3（b）所示为时间
片小于典型交互的时间。图3-4所示为时间片分别为q=1和q=4时进程的周转时间。
（b）时间片小于典型交互的时间
分配给进程的
时间片
分配给进程的
时间片
其他进程运行时间片q
响应时间sb
进程被抢占 交互完成
（a）时间片大于典型交互的时间
时间
分配给进程的
时间片
时间片q
响应时间sa
交互结束
q-sa
图3-3  时间片大小对响应时间的影响
作业情况
A
0
4
15
15
3.75
4
4
1
B
1
3
12
11
3.67
7
6
2
C
2
4
16
14

第4章
在OS中引入进程，可以使系统中的多道程序并发执行，这不仅能有效地改善资源的利
用率，还能显著地提高系统的吞吐量；但是，同时也会使系统变得更加复杂。如果不能采
取有效的措施，以对多个进程的运行进行妥善管理，则必然会由这些进程对系统资源的无
序争夺，给系统造成混乱。
为保证多个进程能有条不紊地运行，必须引入进程同步机制。本章将详细介绍单处理
机系统中的多种进程同步机制，如软件同步机制、硬件同步机制、信号量机制和管程机制
等，利用它们可以保证程序执行的可再现性。本章知识导图如图4-1所示。
进程同步
进程同步的基本概念
进程同步机制
互斥与同步
临界区问题
信号量机制介绍
信号量的应用
实现进程互斥
实现进程同步
生产者-消费者问题
哲学家进餐问题
读者-写者问题
软件同步机制
硬件同步机制
信号量机制
管程机制
经典的进程同步问题
图4-1  第4章知识导图
第4 章导读


--- Page 131 ---
110
计算机操作系统 （慕课版）
4.1 进程同步的基本概念
4.1.1 进程同步概念的引入
我们把异步环境下的一组并发进程因直接制约而互相发送消息、互相合
作、互相等待，使得各进程按一定的速度执行的过程，称为进程同步。具有同
步关系的一组并发进程称为协作进程。互相协作的进程或能直接共享逻辑地址空间（代码和数
据），或能通过文件或消息来共享数据。前者（即共享逻辑地址空间）可以通过轻量级进程或线
程来实现，具体参见本书第2章。后者（共享数据）的并发访问可能会产生数据的不一致问题。
进程同步机制的主要任务是：在执行次序上对多个协作进程进行协调，使并发执行的诸多
协作进程之间能按照一定的规则（或时序）共享系统资源，并能很好地相互合作，从而使程序
的执行具有可再现性。
1．两种形式的制约关系
在多道程序环境下，对于同处于一个系统中的多个进程，由于它们共享系统中的资源，或
为完成某一任务而相互合作，它们之间可能存在着以下两种形式的制约关系。
（1）间接相互制约关系（互斥关系）。
多个程序在并发执行时，由于共享系统资源，如CPU、 I/O设备等，这些并发执行的程序之
间会形成相互制约的关系。对于像打印机、磁带机这样的系统资源，必须保证多个进程对其只
能进行互斥访问，由此在这些进程间，形成了源于对该类资源共享的所谓间接相互制约关系，
也可称之为互斥关系。为了保证这些进程能有序地运行，对于系统中的这类资源，必须由系统
实施统一分配，即用户在要使用这类资源之前应先提出申请，而不能直接使用。
（2）直接相互制约关系（同步关系）。
某些应用程序为了完成某项任务，会建立两个或多个进程。这些进程会为了完成同一任
务而相互合作。进程间的直接制约关系就是源于它们之间的相互合作，该关系也可称为同步关
系。例如，有两个相互合作的进程——输入进程A 和计算进程B，它们共享一个缓冲区。输入进
程A通过缓冲区向计算进程 B提供数据。计算进程 B从缓冲区中读取数据，并对数据进行处理。
但在该缓冲区为空时，计算进程B 会因不能获得所需数据而被阻塞。一旦输入进程A 把数据输入
缓冲区，计算进程B便会被唤醒；反之，当缓冲区已满时，输入进程A 会因不能再向缓冲区投放
数据而被阻塞，当计算进程B将缓冲区中的数据读取走后便可唤醒输入进程A。
进程同步的概念是一个大的范畴，协作进程间的制约关系可以统称为进程同步。根据制约
形式的不同，其又可细分为同步关系和互斥关系，互斥是同步的一个特例。同步强调的是保证
进程之间操作的先后次序的约束，而互斥强调的是对共享资源的互斥访问。
在多道程序环境下，由于存在着上述两类相互制约关系，进程在运行过程中能否获得处理
机运行（即获得CPU控制权运行）以及以怎样的速度运行，这些都不能由进程自身所控制，此即
进程的异步性。进程的异步性会使进程对共享变量或数据结构等资源产生不正确的访问次序，从
而造成进程每次执行的结果均不一致。这种差错往往与时间有关，故称之为“与时间有关的错
误”。为了杜绝这种差错，必须对进程的执行次序进行协调，以保证各进程能按“序”执行。
2．临界资源
在第1章中曾介绍过，许多硬件资源如打印机、磁带机等，进程在使用它们时都需要采用互
进程同步


--- Page 132 ---
111
第
4章 
进程同步
斥方式，这样的资源被称为临界资源（critical resource ）。临界资源既可以是硬件资源，也可以
是软件资源，如共享变量、文件等。下面将通过一个简单的例子来对其进行说明。
生产者-消费者（producer-consumer）问题是一个著名的进程同步问题。它描述的是：有一组生
产者进程在生产产品，并将这些产品提供给一组消费者进程去消费。为使生产者进程与消费者进程
能够并发执行，在两者之间设置了一个具有n个缓冲区的缓冲池，生产者进程将它所生产的产品放
入一个缓冲区中；消费者进程可从一个缓冲区中取走产品并进行消费。尽管所有的生产者进程和消
费者进程都是以异步方式运行的，但它们之间必须保持同步，即不允许消费者进程到一个空缓冲区
中去取产品；也不允许生产者进程向一个已装满产品且产品尚未被取走的缓冲区投放产品。
我们可以利用一个数组buffer来表示上述具有 n个缓冲区的缓冲池。每投入（或取出）一
个产品时，缓冲池buffer中暂存产品（或已取走产品的空闲单元）的数组单元指针in（或out）
加1。由于这里由buffer组成的缓冲池是被组织成循环缓冲的，故应把输入指针in（或输出指针
out）加1，表示为in = (in+1) % n（或out = (out+1) % n）。当(in+1) % n=out时表示缓冲池满，而
in=out则表示缓冲池空。此外，还引入了一个整型变量counter，其初值为0 。每当生产者进程向
缓冲池中投放（或取走）一个产品后，使counter加 1（或减1）。生产者进程和消费者进程共享
下列变量：
int in=0， out=0， counter=0;
item buffer[n];
指针in和out初始化为0。在生产者进程中使用一个局部变量nextp，用于暂时存放每次刚生
产出来的产品；而在消费者进程中，则使用一个局部变量nextc，用于存放每次要消费的产品。
生产者程序如下：
1   void producer( ){
2       while(1) {
3            produce an item in nextp ；
4            …
5            while (counter==n) ；
6            buffer ［in］ = nextp ；
7            in = (in+1) % n ；
8            counter++ ；
9       }
10   } ；
消费者程序如下：
1　  void consumer( ){
2　　　   while(1) {
3　　　　    while (counter==0) ；
4　　　　    nextc=buffer ［out］ ；
5　　　　    out = (out+1) % n ；
6　　　　    counter-- ；
7　　　　    consumer the item in nextc ；
8　　　　    …
9　　　   }
10   } ；

--- Page 133 ---
112
计算机操作系统 （慕课版）
上述生产者程序和消费者程序，虽然分开看时都是正确的，而且两者在顺序执行时结果也
是正确的，但若并发执行，就会出现差错，问题在于这两个进程共享变量counter。生产者对它
做加1操作（counter++），消费者对它做减1 操作（counter --），这两个操作在用机器语言实现
时，通常可用下列形式描述：
   register1=counter ；    register2=counter ；
   register1=register1+1 ；    register2=register2-1 ；
  counter=register1 ；    counter=register2 ；
假设counter的当前值是5 。如果首先由生产者进程执行上述左列的3 条语句，然后再由消费
者进程执行右列的3 条语句，则最后共享变量counter的值仍为5 ；如果首先由消费者进程执行右
列的3条语句，然后再由生产者进程执行左列的3条语句，则最后共享变量counter值也还是5 。但
是，如果按下述顺序执行：
1   register1=counter ；    (register1=5)
2   register1=register1+1 ；    (register1=6)
3   register2=counter ；    (register2=5)
4   register2=register2-1 ；    (register2=4)
5   counter=register1 ；    (counter=6)
6   counter=register2 ；    (counter=4)
正确的counter值应当是5 ，但结果却是4。读者可以自己试试，倘若再次改变两段程序中各
条语句交叉执行的顺序，则可能会得到counter=6的答案，这表明程序的执行已经失去了可再现
性。为了预防产生这种错误，关键是应当把变量counter作为临界资源进行处理，亦即，令生产
者进程和消费者进程互斥地访问变量counter。
请思考 counter++ 和 counter-- 的 6 行机器语言（指令）有多少种不同的执行次序和执行结果。
思考题
4.1.2 临界区问题
由前所述可知，不论是硬件临界资源，还是软件临界资源，多个进程必须互斥地对它们进
行访问。人们把在每个进程中访问临界资源的那段代码称为临界区（critical section）。显然，
若能保证各进程互斥地进入自己的临界区，便可实现各进程对临界资源的互斥访问。为此，每
个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正在被访问。如果此
刻该临界资源未被访问，进程便可进入临界区对该资源进行访问，并将访问标志设置为“正被
访问”；如果此刻该临界资源正在被某进程访问，则本进程不能进入临界区。因此，必须在临
界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区（ entry section ）。在临界
区后面也要相应地加上一段被称为退出区（exit section）的代码，用于将临界区正被访问的标志
恢复为未被访问的标志。进程中除上述进入区、临界区及退出区之外的其他部分的代码，在这
里都被称为剩余区。这样，即可将一个访问临界资源的循环进程描述如下：
1   while(TURE)
2     {
3 　　  进入区
4 　　  临界区 ；

--- Page 134 ---
113
第
4章 
进程同步
5 　　  退出区
6 　　  剩余区 ；
7 　  }
为实现进程互斥地进入自己的临界区，可使用软件方法，更多的情况是在系统中设置专门
的同步机构来协调各进程间的运行。解决临界区问题的同步机制都应遵循下述4条准则。
（1）空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许1 个请求进
入临界区的进程立即进入自己的临界区，以有效地利用临界资源。
（2）忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其他试图进入
临界区的进程必须等待，以保证对临界资源的互斥访问。
（3）有限等待。对于要求访问临界资源的进程，应保证其在有限时间内能进入自己的临界  
区，以免陷入“死等”状态。
（4）让权等待（原则上应遵循，但非必须）。当进程不能进入自己的临界区时，应立即释
放处理机，以免进程陷入“忙等”状态。
4.2 软件同步机制
一个经典的基于软件的临界区问题的解决方案是Peterson解决方案。尽管由于现代OS执行
基本机器指令的方式可能不同，不能确保Peterson解决方案能够正确运行在每个机器上，但是该
方案提供了一种解决临界区问题的很好的算法，并能满足 4.1节中提出的准则。因此有必要具体
介绍一下该解决方案。
Peterson解决方案适用于两个进程交替执行临界区的情况。设两个进程分别为P 0和P1，为了
方便，当使用Pi时，用Pj表示另一个进程，即j==i-1。
Peterson解决方案要求两个进程共享两个变量：
int turn;
boolean flag[2];
变量turn表示哪个进程可以进入临界区，即如果turn==i，那么允许进程P i进入临界区内执
行。数组flag[]表示哪个进程准备进入临界区。例如，如果flag[i]为 TRUE，则表示进程Pi准备进
入临界区。下面所示为Peterson解决方案中进程Pi的结构。
1   do {
2     flag[i] = TRUE;
3     turn = j;
4     while (flag[ j] && turn == j);
5     临界区 ;
6     flag[i] = FALSE;
7     剩余区 ;
8   } while (TRUE);
为了进入临界区，进程P i先设置flag[i]的值为TRUE ，并设置turn的值为j ，这表示如果另一
个进程希望进入临界区，那就让它进入，并令当前进程处于“忙等”状态。如果两个进程同时
试图进入临界区，那么turn的值会几乎同时被设置成i 或j，但只有一个赋值语句的结果会被保  
留。因此，最终将由turn的值来决定哪个进程被允许进入临界区执行。
若要证明Peterson解决方案是正确的，则须证明该方案满足解决临界区问题的3 个准则：忙

--- Page 135 ---
114
计算机操作系统 （慕课版）
则等待、空闲让进、有限等待。需要说明的是，尽管在4.1.2小节中提到了解决临界区问题的同
步机制需要遵循4个准则，但此处只须满足前3个。这是因为第4个准则“让权等待”属于较高要
求，在早期的解决方案中均未对此做出要求，因为这样的做法虽会影响系统效率，但不影响临
界区问题的解决。
证明满足“忙则等待”准则，即须保证进程对临界资源进行互斥访问。当一个进程Pi已在其
临界区中进行操作，而另一个进程Pj希望进入临界区时，flag[i]=TRUE，turn=i，flag[j]=TRUE，  
这意味着进程P j中while语句的判断条件始终为真，进程处于“忙等”状态而无法进入临界区。
由此说明满足“忙则等待”准则。
证明满足“空闲让进”和“有限等待”准则时，假设临界区目前没有进程在执行，有两种
情况：第一种情况是只有一个进程希望进入临界区，另一个进程没有要求进入；第二种情况是两
个进程都希望进入临界区。①针对第一种情况，假设P0希望进入临界区，P1没有提出要求，此时
flag[0]=TRUE，flag[1]=FALSE，turn=1，因此P0中while语句的判断条件为FALSE，P0能够进入临界
区执行。②针对第二种情况，如果两个进程都希望进入临界区，那么flag[0]=flag[1]=TRUE，这就
意味着P0和P1进程不可能同时执行while语句，因为turn的值只可能取0或1，不可能同时取两个值。
因此，这两个进程不可能同时进入临界区，而只有一个进程可以进入其临界区，另一个进程将在
进入临界区的进程进入一次临界区后进入，满足了“有限等待”的准则。
4.3 硬件同步机制
虽然利用软件方法可以解决各进程互斥进入临界区的问题，但有一定难度，并且存在很大
的局限性，因而现在已很少采用它。目前许多计算机已提供了一些特殊的硬件指令，允许对一
个字中的内容进行检测和修正或是对两个字的内容进行交换等。因此，可利用这些特殊的指令
来解决临界区问题。
实际上，在对临界区进行管理时，可以将标志看作一个锁，“锁开”进入，“锁关”等
待，初始时锁是打开的。每个要进入临界区的进程，必须先对锁进行测试，当锁未开时，则
必须等待，直至锁被打开。当锁打开时，则应立即把其锁上，以阻止其他进程进入临界区。显
然，为防止多个进程同时测试到“锁开”，测试和关锁操作必须是连续的，不允许分开进行。
1．关中断
关中断是实现互斥最简单的方法之一。在进入锁测试之前，关闭中断，直到完成锁测试并
上锁之后，才能打开中断。这样，进程在临界区执行期间，计算机系统不响应中断，从而不会
引发调度，也就不会发生进程或线程切换。由此，保证了对锁的测试和关锁操作的连续性和完
整性，进而有效地保证了互斥。
但是，关中断的方法存在着许多缺点：①滥用关中断权力可能导致严重后果；②关中
断时间过长会影响系统效率，进而会限制CPU交叉执行程序的能力；③关中断方法不适用于
多CPU系统，因为在一个CPU上进行关中断并不能防止进程在其他CPU上执行相同的临界区  
代码。
2．利用 Test-and-Set 指令实现互斥
这是借助硬件指令TS（Test-and-Set，测试并建立）来实现互斥的一种方法。在许多计算机
中都提供了这种TS指令，其一般性描述如下：

--- Page 136 ---
115
第
4章 
进程同步
1   boolean TS （boolean *lock）  {
2      boolean old ；
3      old = *lock ；
4      *lock = TRUE ；
5      return old;
6   }
这条指令可以被看作一个函数，其执行过程是不可分割的，即一条原语。其中，lock有两
种状态：当lock=FALSE时，表示该资源空闲；当lock=TRUE时，表示该资源正在被使用。
用TS指令管理临界区时，须为每个临界资源设置一个布尔变量lock，由于变量lock代表了该
资源的状态，可把它看作一把锁。lock的初值为FALSE，表示该临界资源空闲。进程在进入临
界区之前，首先用TS指令测试lock，如果其值为FALSE，则表示没有进程在临界区内，可以进
入，并将TRUE值赋予lock，这等效于关闭了临界区，使任何进程都不能进入临界区，否则必须
循环测试直到TS（&lock）为TRUE。利用TS指令实现互斥的循环进程结构可描述为：
1   do {
2     …
3     while TS （&lock） ；     /* do skip */   
4     critical section ；
5     lock ： =FALSE ；
6     remainder section;
7   } while （TRUE） ；
3．利用 swap 指令实现进程互斥
swap指令被称为对换指令，在Intel 80x86中又被称为XCHG指令，用于交换两个字的内容。
其处理过程描述如下：
1   void swap （boolean *a, boolean *b） {
2      boolean temp;
3      temp = *a;
4      *a = *b;
5      *b = temp;
6   }
用对换指令可以简单有效地实现互斥，方法是为每个临界资源设置一个全局的布尔变量
lock，其初值为FALSE，在每个进程中再设置一个局部的布尔变量key，使用swap指令与lock进
行数值交换，以此来循环判断lock的取值。只有当key为 FALSE时，进程才可以进行临界区操
作。利用swap指令实现进程互斥的循环过程描述如下：
1   do { 
2    key=TRUE ；
3    do {
4      swap （&lock， &key） ；
5    } while (key!=FALSE);
6    临界区操作 ；
7    lock =FALSE ；

--- Page 137 ---
116
计算机操作系统 （慕课版）
8    …
9   }  while (TRUE) ；
利用上述硬件指令能有效地实现进程互斥。需要说明的是，当临界资源被访问时，其他访
问进程必须不断地进行测试，即处于一种忙等状态，这不符合“让权等待”的原则，因而会造
成处理机时间的浪费，同时也很难将它们用于解决复杂的进程同步问题。
4.4 信号量机制
信号灯是人类社会中应用于交通管理等领域的一种设备，人们可以利用
信号灯的状态（颜色）来规范相关活动，如十字路口的交通管理等。OS中的
信号量机制类似于信号灯，起着规范进程运行的作用。
1965年，荷兰学者迪杰斯特拉最初提出了信号量（semaphores）机制，其是一种卓有成效
的进程同步工具。在长期且广泛的应用中，信号量机制又得到了很大的发展，它从整型信号量
经记录型信号量、AND型信号量，最终发展为信号量集。现在，信号量机制已被广泛应用于单
处理机和多处理机系统以及计算机网络中。
4.4.1 信号量机制介绍
1．整型信号量
最初由迪杰斯特拉把整型信号量定义为一个用于表示资源数目的整型量 S，它与一般整
型量不同，除初始化外，仅能通过两个标准的原子操作(atomic operation)来访问，即wait(S)和
signal(S)操作。很长的一段时间以来，这两个操作一直被分别称为P 操作和V 操作。wait(S)和
signal(S)操作可描述为：
1   wait(S){
2 　　  while (S<=0) ;  /* do no-op */
3 　　  S-- ；
4   }
5   signal(S){
6 　　  S++ ；
7   }
wait(S)和signal(S)是两个原子操作，因此，它们在执行时是不可中断的。亦即，当一个进程
在修改某信号量时，没有其他进程可同时对该信号量进行修改。此外，在wait(S)操作中，对S 值
进行测试和做S:=S-1操作时都不可中断。
2．记录型信号量
整型信号量机制中的wait(S)操作，只要信号量S＜=0，就会不断地进行测试。因此，该机制
并未遵循“让权等待”准则，而是使进程处于“忙等”状态。记录型信号量机制，是一种不存
在“忙等”现象的进程同步机制。但在采取了“让权等待”策略后，又会出现多个进程等待访
问同一临界资源的情况。为此，在信号量机制中，除了需要一个用于代表资源数目的整型变量
value外，还应增加一个进程链表指针list，用于链接上述所有等待进程。记录型信号量是由于它
采用了记录型的数据结构而得名的。它所包含的上述两个数据项可描述为：
1   typedef struct {
信号量机制


--- Page 138 ---
117
第
4章 
进程同步
2     int value;
3     struct process_control_block *list;
4   } semaphore;
相应地，wait(S)和signal(S)操作可描述为：
1   wait(semaphore *S) {
2        S->value--;
3        if (S->value<0) block(S->list);
4   }
5   signal(semaphore *S){
6        S->value++ ；
7        if (S->value<=0) wakeup(S->list);
8   }
在记录型信号量机制中，S ->value的初值表示系统中某类资源的数目，因而又被称为资源
信号量，对它进行的每次wait(S)操作，意味着进程请求一个单位的该类资源，这会使系统中可
供分配的该类资源数减少一个，因此描述为S ->value --；当S.value ＜0时，表示该类资源已分
配完毕，因此进程应调用block原语，进行自我阻塞，放弃处理机，并将该进程插入信号量链表
S->list中。可见，该机制遵循了“让权等待”准则。此时S->value的绝对值表示在该信号量链表
中已阻塞进程的数目。对信号量的每次signal(S)操作，表示执行进程释放一个单位的资源，这会
使系统中可供分配的该类资源数增加一个，故S ->value++操作表示资源数目加1 。若加1后仍是
S->value＜=0，则表示在该信号量链表中仍有等待该资源的进程被阻塞，故还应调用wakeup原
语以将S->list链表中的第一个等待进程唤醒。如果S ->value的初值为1 ，则表示只允许一个进程
访问临界资源，此时的信号量会转化为互斥信号量，用于进程互斥。
3．AND 型信号量
前面所述的进程互斥问题，针对的是多个并发进程仅共享一个临界资源的情况。在有些应
用场合，一个进程往往需要获得两个或更多的共享资源后方能执行其任务。假定现有进程A和进
程B，它们都要求访问共享数据D 和E，当然，共享数据都应作为临界资源。为此，可为这两个
数据分别设置用于互斥的信号量 Dmutex和Emutex，并令它们的初值都为 1。在两个进程中都要
相应地包含两个针对Dmutex和Emutex的操作，如下所示。
1   process A:　　　　process B:
2   wait(Dmutex) ； 　　wait(Emutex) ；
3   wait(Emutex) ； 　　wait(Dmutex) ；
令进程A和进程B按下述次序交替执行wait(S)操作。
1   process A: wait(Dmutex) ；  于是 Dmutex=0。
2   process B: wait(Emutex) ；  于是 Emutex=0。
3   process A: wait(Emutex) ；  于是 Emutex=-1， A 阻塞。
4   process B: wait(Dmutex) ；  于是 Dmutex=-1， B 阻塞。
最后，进程A和进程B处于僵持状态。在无外力作用下，两者都将无法从僵持状态中解脱出
来。我们称此时的进程A和进程B已进入死锁状态。显然，当进程同时要求的共享资源越多时，
发生进程死锁的可能性就越大。
AND型信号量机制的基本思想是：将进程在整个运行过程中需要的所有资源，一次性全部
分配给进程，待进程使用完后再一起释放。只要尚有一个资源未能分配给进程，其他所有可能

--- Page 139 ---
118
计算机操作系统 （慕课版）
为之分配的资源，也不分配给它。亦即，对若干个临界资源的分配，采取原子操作方式：要么
把它所请求的资源全部分配给它，要么一个也不分配。由死锁理论可知，这样可以避免上述死
锁情况的发生。为此，在wait(S)操作中增加了一个“AND”条件，故称之为AND同步，或同时
wait(S)操作，即Swait(simultaneous wait)，其定义如下：
1   Swait(S1， S2， …， Sn){
2       while (TRUE) {
3 　　　　   if (S1>=1 && … && Sn>=1) {
4 　　　　　      for (i =1; i<=n; i++) Si--; ；
5 　　　　　      break;
6 　　　　   }
7 　　　　   else {
8 　　　　　      place the process in the waiting queue associated with the first 
9 　　　　　      Si found with Si<1， and set the program count of this process to 
10 　　　　　      the beginning of Swait operation
11 　　　　   }
12       }
13   }
14   Ssignal(S1， S2， …， Sn){
15      while (TRUE) {
16 　　       for (i=1; i<=n; i++) {
17                           Si++ ；
18                           Remove all the process waiting in the queue associated with Si   
19                           into the ready queue.
20 　　       }
21      }
22   }
4．信号量集
在前述记录型信号量机制中，wait(S)或signal(S)操作仅能对信号量施以加1或减1操作，这意
味着每次只能对某类临界资源进行一个单位的申请或释放。当一次需要 N个单位时，便要进行N
次wait(S)操作，这显然是低效的，甚至会增加死锁的概率。此外，在有些情况下，为确保系统
的安全性，当所申请的资源数量低于某一下限值时，还必须进行管制，不予以分配。因此，当
进程申请某类临界资源时，在每次分配之前，都必须测试资源的数量，判断其是否大于可分配
的下限值，进而决定是否予以分配。
基于上述两点，可以对AND信号量机制加以扩充，即针对进程所申请的所有资源以及每类
资源不同的需求量，在一次wait(S)或 signal(S)操作中完成它们的申请或释放。进程对信号量S i的
测试值不再是1，而是该资源的分配下限值ti，即要求Si＞=ti，否则不予分配。一旦允许分配，则
基于进程对该资源的需求值d i（表示资源占用量）进行S i:=Si-di操作，而不是简单的S i=Si-1。由
此可以形成一般化的“信号量集”机制。对应的Swait()和Ssignal()格式为：
Swait(S1，t1，d1 ；… ；Sn，tn，dn) ；
Ssignal(S1，d1 ；… ；Sn，dn) ；

--- Page 140 ---
119
第
4章 
进程同步
一般化的“信号量集”还有下列3种特殊情况。
（1）Swait(S, d, d)。此时在信号量集中只有一个信号量S，但允许它每次申请d个资源，当
现有资源数少于d时，不予分配。
（2）Swait(S, 1, 1)。此时的信号量集已蜕化为一般的记录型信号量（S＞1时）或互斥信号
量(S=1时)。
（3）Swait(S, 1, 0) 。这是一种特殊且很有用的信号量操作。当S ＞=1时，允许多个进程
进入某个特定的临界区；当S=0时，将阻止任何进程进入特定区。换言之，它相当于一个可控
开关。
4.4.2 信号量的应用
1．利用信号量实现进程互斥
为使多个进程能互斥地访问某临界资源，只须为该资源设置一个互斥型信号量 mutex，并设
其初值为1，然后将各进程访问该资源的临界区置于wait(mutex)和 signal(mutex)操作之间即可。
这样，每个欲访问该临界资源的进程，在进入临界区之前，都要先对mutex执行wait操作。若该
资源此刻未被访问，则本次wait操作必然成功，进程便可进入自己的临界区，这时若再有其他进
程也欲进入自己的临界区，则由于对mutex执行wait操作定会失败，因而该进程阻塞，从而保证
了该临界资源能被互斥地访问。当访问临界资源的进程退出临界区后，又应对mutex执行signal
操作，以便释放该临界资源。利用信号量实现两个进程互斥的描述如下。
（1）设mutex为互斥型信号量，其初值为1，取值范围为（-1,0,1）。当mutex=1时，表示两
个进程皆未进入需要互斥访问的临界区；当mutex=0时，表示有一个进程进入临界区运行，另一
个必须等待，挂入阻塞队列；当mutex= -1时，表示有一个进程正在临界区运行，而另一个进程
因等待而阻塞在信号量队列中，需要被当前已在临界区运行的进程在退出时唤醒。
（2）代码描述：
1　  semaphore mutex=1;
2　　　     PA(  )  {                P B ( ) {
3　　　     while （1）  {　　　　　　　  　       while （1）  {
4　　　　        wait(mutex) ；                wait(mutex) ；
5　　　　        临界区 ；                   临界区 ；
6　　　　        signal(mutex) ；                signal(mutex) ；
7　           剩余区 ；                   剩余区 ；
8 　 　 　     }                     }
9 　 　 　      }                   }
在利用信号量机制实现进程互斥时应注意，wait(mutex)和 signal(mutex)必须成对出现。缺少
wait(mutex)将会导致系统混乱，无法保证对临界资源的互斥访问；缺少signal(mutex)将会导致临
界资源永远不被释放，从而使因等待该资源而阻塞的进程不能被唤醒。
2．利用信号量实现进程同步
协作进程间除了互斥地访问临界资源外，还需要相互制约和传递信息，以同步它们之间的
运行，利用信号量同样可以达到这一目的。下面举一个简单的例子来说明同步型信号量的使用
方法。

--- Page 141 ---
120
计算机操作系统 （慕课版）
假设进程P1和 P2中有两段代码C1和 C2，若要强制C1先于C2执行，则须在C2前添加
wait(S)，在C1后添加signal(S)。需要说明的是，信号量S 的初值应该被设置为0 。这样，只有P1
在执行完C1后，才能执行signal(S)以把S 的值设置为1。这时，P2执行wait(S)才能申请到信号量
S，并执行C2。如果P1的 C1没有提前执行，则信号量S 的值为0，P2执行wait(S)时会因申请不到
信号量S而阻塞。
（1）设S为同步型信号量，其初值为0 ，取值范围为（ -1,0,1）。当S=0时，表示C1还未执
行，C2也未执行；当S=1时，表示C1已经执行，C2可以执行；当S= -1时，表示C2想执行，但由
于C1尚未执行，C2不能执行，进程P2处于阻塞状态。
（2）代码描述：
1　  semaphore S=0;
2　　　      P1( ) {            P2( ) {
3　　　      while （1）  {　　　　　　　       while （1）  {
4 　 　 　 　    C 1                     wait(S) ；
5　　　　　　  signal(S) ；                  C2 ；
6 　       …                     …     
7 　 　 　      }                  }
8 　 　 　       }              }
同步型信号量的使用通常比互斥型信号量的使用要复杂。一般情况下，同步型信号量的
wait(S)和 signal(S)操作位于两个不同的进程内。另外还有一种比较复杂的同步，如C1和 C2没有
一种固定的执行次序，在某种条件下，C1要先于C2执行；而在另一种条件下，C2要先于C1执
行。有关这种复杂的同步，我们将在4.7节中进行具体介绍。
请思考互斥和同步的关系。它们有哪些地方相同？哪些地方不同？
思考题
4.5 管程机制
虽然信号量机制是一种既方便、又有效的进程同步机制，但每个要访问临界资源的进程都
必须自备同步操作wait(S)和signal(S)。这就使大量的同步操作分散在各个进程中。这不仅给系统
的管理带来了麻烦，而且还会因同步操作的使用不当而导致系统死锁。为此，在解决上述问题
的过程中，便产生了一种新的进程同步工具——管程（monitor）。
1．管程的定义
针对系统中的各种硬件资源和软件资源，均可利用数据结构抽象地描述它们的资源特性，
即用少量信息和对该资源所执行的操作来表征该资源，而忽略了它们的内部结构和实现细节。
因此，可以利用共享数据结构抽象地表示系统中的共享资源，并且将对该共享数据结构实施的
特定操作定义为一组过程。进程对共享资源的申请、释放和其他操作，必须通过由这组过程
间接地对共享数据结构进行操作加以实现。对于请求访问共享资源的诸多并发进程，可以根据
资源的情况接受或阻塞，以确保每次仅有一个进程进入管程。通过执行这组过程来使用共享资
源，可以实现对共享资源所有访问的统一管理，进而有效地实现进程互斥。
代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管

--- Page 142 ---
121
第
4章 
进程同步
理程序，共同构成了一个OS的资源管理模块，我们称之为管程。管程被请求和释放资源的进程
所调用。汉森（Hansan）为管程所下的定义是：一个管程定义了一个数据结构和能被并发进程  
（在该数据结构上）所执行的一组操作，这组操作能同步进程和改变管程中的数据。”
由上述定义可知，管程由4个部分组成：①管程的名称；②局限于管程内的共享数据结构说
明（尽管数据结构是共享的，但该共享变量局限于管程内）；③对该数据结构进行操作的一组
过程；④设置局限于管程内的共享数据初值的语句。图4-2所示为一个管程的示意。
条件（不忙）队列 共享数据
一组操作过程
…
初始化代码
进入队列
图4-2  管程示意
管程的语法描述如下：
1   monitor monitor_name {     /* 管程名 */
2     share variable declarations ；    /* 共享变量说明 */
3     cond declarations ；       /* 条件变量说明 */
4     p u b l i c :            /* 能被进程调用的过程 */
5     void P1(……)         /* 对数据结构操作的过程 */
6           {……}
7     void P2(……)
8           {……}
9     … …
10     void (……)
11          {……}
12     ……
1 3     {            /* 管程主体 */    
14     initialization code;    /* 初始化代码 */ 
15      ……   
16     }
17    }
实际上，管程中包含了面向对象的思想，将表征共享资源的数据结构及其对数据结构操作
的一组过程（包括同步机制），都集中并封装在了一个对象内部，隐藏了实现细节。封装于管
程内部的数据结构仅能被封装于管程内部的过程所访问，管程外的任何过程都不能访问它；同
时，封装于管程内部的过程也仅能访问管程内的数据结构。所有进程当要访问临界资源时，都
只能通过管程间接访问，而管程每次只准许一个进程进入管程，执行管程内的过程，从而实现

--- Page 143 ---
122
计算机操作系统 （慕课版）
了进程互斥。
管程是一种程序设计语言结构的成分，它和信号量有同等的表达能力，从语言的角度看，
管程主要有以下特性：①模块化，管程是一个基本程序单位，可以单独编译；②抽象数据类
型，管程中不仅有数据，而且有对数据的操作；③信息掩蔽，管程中的数据结构只能被管程中
的过程访问，这些过程也是在管程内部被定义的，供管程外的进程调用，而管程中的数据结构
以及过程（函数）的具体实现，外部不可见。
管程和进程不同：①虽然二者都定义了数据结构，但进程定义的是私有数据结构——
PCB，管程定义的是公共数据结构，如消息队列等；②二者都存在针对各自数据结构的操作，
但进程是由顺序程序执行有关操作的，而管程则主要进行同步操作和初始化操作；③设置进程
的目的在于实现系统的并发性，而管程的设置则是为了解决共享资源的互斥使用问题；④进程
通过调用管程中的过程来对共享数据结构进行操作，该过程就像通常的子程序被调用一样，因
而管程为被动工作方式，进程则为主动工作方式；⑤进程之间能并发执行，而管程则不能与其
调用者并发；⑥进程具有动态性，由创建而诞生，由撤销而消亡，而管程则是OS中的一个资源
管理模块，仅供进程调用。
2．条件变量
在利用管程实现进程同步时，必须设置同步工具，如两个同步操作原语wait和 signal。当某
进程通过管程请求获得临界资源而未能被满足时，管程便会调用wait原语以使该进程处于等待状
态，并将其排在等待队列上，如图 4-2所示。仅当另一进程访问完成并释放该资源后，管程才会
调用signal原语，唤醒等待队列中的队首进程。
但是仅有上述同步工具是不够的，考虑一种情况：当一个进程调用了管程，在管程中运
行时被阻塞或挂起，直到阻塞或挂起的原因解除，而在此期间，如果该进程不释放管程，则
其他进程就会因无法进入管程而被迫进行长时间的等待。为了解决这个问题，引入了条件变量
condition。通常，一个进程被阻塞或挂起的条件（原因）可以有多个，因此在管程中设置了多个
条件变量，且对这些条件变量的访问，只能在管程中进行。
管程中对每个条件变量都须予以说明，其形式为：condition x, y。对条件变量的操作仅仅
是wait和 signal，因此条件变量也是一种抽象数据类型，每个条件变量均保存了一个链表，用
于记录因该条件变量而阻塞的所有进程，同时提供的两个操作可表示为x.wait和 x.signal，含义  
如下。
x.wait：如果正在调用管程的进程因x 条件需要而被阻塞或挂起，则调用x.wait将自己插入
到x条件的等待队列上，并释放管程，直到x条件变化。此时其他进程可以使用该管程。
x.signal：如果正在调用管程的进程发现x 条件发生了变化，则调用x.signal，重新启动一个
因x条件而阻塞或挂起的进程，如果存在多个这样的进程，则选择其中的一个；如果没有，则继
续执行原进程，而不产生任何结果。这与信号量机制中的signal操作不同，因为后者总是要执行
s=s+1操作，所以总会改变信号量的状态。
如果有进程Q因x条件而处于阻塞状态，则当正在调用管程的进程 P执行了x.signal 操作后，
进程Q会被重新启动，此时，针对两个进程P 和Q，应该如何确定哪个执行、哪个等待呢？可采
用下述两种方式之一进行处理。
（1）P等待，直至Q离开管程或等待另一条件。
（2）Q等待，直至P离开管程或等待另一条件。
采用哪种处理方式更好，尚无定论。霍尔（Hoare）采用了第一种处理方式，而汉森则采用

--- Page 144 ---
123
第
4章 
进程同步
了两者的折中，他规定管程中的过程所执行的signal操作是过程体的最后一个操作，于是，进程
P执行signal操作后会立即退出管程，因而，进程Q就可以马上被恢复执行。
4.6 经典的进程同步问题
在多道程序环境下，进程同步问题十分重要，也相当有趣，因而吸引了不少学者对它进行
研究，由此而产生了一系列经典的进程同步问题，其中较有代表性的是“生产者 -消费者问题” 
“读者-写者问题”“哲学家进餐问题”等。通过对这些问题的研究和学习，我们可以更好地理
解进程同步的概念与实现方法。
4.6.1 生产者 - 消费者问题
前面已经对生产者-消费者问题（the producer-consumer problem）做了一
些描述，但未考虑进程的互斥与同步问题，因而造成了数据counter的不定性。
生产者-消费者问题是相互合作进程关系的一种抽象，例如，在输入时，输入
进程是生产者，计算进程是消费者；而在输出时，计算进程是生产者，而打印
进程是消费者。因此，该问题有很大的代表性及实用价值。本小节将利用信号量机制来解决生
产者-消费者问题。
1．利用记录型信号量解决生产者 - 消费者问题
假定在生产者和消费者之间的公用缓冲池中，具有n个缓冲区，这时可利用互斥信号量mutex实
现各进程对缓冲池的互斥使用；利用信号量empty和full分别表示缓冲池中空缓冲区和满缓冲区的数
量。又假定这些生产者和消费者相互等效，只要缓冲池未满，生产者便可将消息送入缓冲池；只要
缓冲池未空，消费者便可从缓冲池中取走一个消息。生产者-消费者问题可描述如下：
1　  int in=0, out=0;
2　  item buffer[n];
3　  semaphore mutex=1, empty=n, full=0;
4　  void producer( ) {
5　      do {
6　　　　　　  produce an item nextp ；
7　　　　　　  …
8　　　　　　  wait(empty) ；
9　　　　　　  wait(mutex) ；
10 　　　　　  buffer[in] =nextp ；
11 　　　　　  in=(in+1) % n ；
12 　　　　　  signal(mutex) ；
13 　　　　　  signal(full) ；
14       } while(TRUE) ；
15   }
16   void consumer( ) {
17      do {
18 　　　　　　  wait(full) ；
生产者-消费者
问题


--- Page 145 ---
124
计算机操作系统 （慕课版）
19 　　　　　　  wait(mutex) ；
20 　　　　　　  nextc= buffer[out] ；
21 　　　　　　  out =(out+1) % n ；
22 　　　　　　  signal(mutex) ；
23 　　　　　　  signal(empty) ；
24 　　　　　　  consume the item in nextc ；
25 　　　　　　  …
26 　　  } while(TRUE) ；
27    }
28    void main( ) {
29     cobegin
30     producer( ); consumer( );
31     coend
32    }
在生产者 -消费者问题中应注意：首先，在每个进程中用于实现互斥的 wait(mutex) 和
signal(mutex)必须成对出现；其次，对资源信号量empty和 full的wait和signal操作，同样需要成对
出现，但它们分别处于不同的进程中。例如，wait(empty)在计算进程中，而signal(empty)则在打
印进程中，计算进程若因执行wait(empty)而阻塞，则以后将由打印进程唤醒它；最后，每个程
序中的多个wait操作的顺序不能颠倒，应先执行对资源信号量的wait操作，再执行对互斥信号量
的wait操作，否则可能会引起进程死锁。
2．利用 AND 信号量解决生产者 - 消费者问题
对于生产者 -消费者问题，也可利用 AND信号量来解决，即用 Swait(empty, mutex)来  
代替wait(empty)和 wait(mutex)，用Ssignal(mutex, full)来代替signal(mutex)和 signal(full)，用
Swait(full, mutex)来代替wait(full)和wait(mutex)，以及用Ssignal(mutex, empty)来代替signal(mutex) 
和signal(empty)。利用AND信号量来解决生产者 -消费者问题的算法中的生产者和消费者可描述
如下：
1   int in=0, out=0;
2   item buffer[n];
3   semaphore mutex=1, empty=n, full=0;
4   void producer( ) {
5      do {
6 　　　　　  produce an item nextp ；
7 　　　　　  …
8 　　　　　  Swait(empty， mutex) ；
9 　　　　　  buffer[in] =nextp ；
10 　　　　　  in=(in+1) % n ；
11 　　　　　  Ssignal(mutex， full) ；
12      } while(TRUE) ；
13   }
14   void consumer( ) {

--- Page 146 ---
125
第
4章 
进程同步
15       do {
16 　　　　　　  Swait(full， mutex) ；
17 　　　　　　  nextc= buffer[out] ；
18 　　　　　　  out =(out+1) % n ；
19 　　　　　　  Ssignal(mutex， empty) ；
20 　　　　　　  consume the item in nextc ；
21 　　　　　　  …
22       } while(TRUE) ；
23   }
3．利用管程解决生产者 - 消费者问题
在利用管程来解决生产者 -消费者问题时，首先须建立一个管程，并将其命名为
producerconsumer（简称PC），其中包括以下两个过程。
（1）put(x)过程 ：生产者利用该过程将自己生产的产品投放到缓冲池中，并用整型变量
count来表示在缓冲池中已有的产品数目，当count＞=N时，表示缓冲池已满，生产者应等待。
（2）get(x)过程：消费者利用该过程从缓冲池中取出一个产品，当 count＜=0时，表示缓冲
池中已无可取用的产品，消费者应等待。
对于条件变量notfull和notempty，有以下两个过程可对它们进行操作。
（1）cwait（condition）过程 ：当管程被一个进程占用时，其他进程调用该过程时会阻
塞，并且会被挂在条件condition的队列上。
（2）csignal（condition）过程 ：唤醒在cwait执行后阻塞在条件 condition 队列上的进程，
如果这样的进程不止一个，则选择其中一个实施唤醒操作；如果队列为空，则无操作返回。
PC管程可描述如下：
1   monitor producerconsumer {    
2   item buffer[N];
3   int in, out;
4   condition notfull, notempty;
5   int count;
6   p u b l i c :            
7       void put(item x) {
8              if (count>=N) cwait(notfull) ；  
9 　            buffer[in] = x ；
10 　            in = (in+1) % N ；
11 　            count++ ；
12 　            csignal(notempty);
13       }
14       void get(item x) {
15              if (count<=0) cwait(notempty) ；  
16 　            x = buffer[out] ；
17 　            out = (out+1) % N ；
18 　            count-- ；

--- Page 147 ---
126
计算机操作系统 （慕课版）
19 　            csignal(notfull);
20              }
2 1              {                 
22              in=0;out=0;count=0;
23              }
24    } PC;
在利用管程解决生产者-消费者问题时，其中的生产者和消费者可描述为：
1　　   void producer( ) {
2　　　    item x;
3　　　    while(TRUE) {
4　　       　    ……
5　　       　    produce an item in nextp ；
6　　       　    PC.put(x) ；
7　　  　   }
8　　   }
9　　   void consumer( ) {
10 　 　   item x;
11 　 　   while(TRUE) {
12 　　    PC.get(x) ；
13 　 　   consume the item in nextc ；
14 　 　   ……
15 　 　   }
16 　   }
17   void main( ) {
18 　   cobegin
19 　   producer( ); consumer( );
20 　   coend
21    }
4.6.2 哲学家进餐问题
由迪杰斯特拉提出并解决的哲学家进餐问题是典型的同步问题。该问题可描述为：有5 个哲
学家共用1张圆桌，他们分别坐在圆桌周围的5 把椅子上，在圆桌上有5 个碗和5根筷子，他们的
生活方式是交替地进行思考和进餐；平时，1 个哲学家进行思考，其饥饿时便会试图取用左右两
边最靠近自己的筷子，他只有在拿到2根筷子时才能进餐；进餐毕，放下筷子继续思考。
1．利用记录型信号量解决哲学家进餐问题
经分析可知，放在桌子上的筷子是临界资源，在一段时间内只允许1 位哲学家使用。为了实
现对筷子的互斥使用，可以用1 个信号量表示1 根筷子，由这5 根筷子对应的5 个信号量构成信号
量数组。其描述如下：
semaphore chopstick[5]={1,1,1,1,1} ；
所有信号量均被初始化为1，第i位哲学家的活动可描述为：

--- Page 148 ---
127
第
4章 
进程同步
1　  do {
2　　   wait(chopstick[i]) ；
3　　   wait(chopstick[(i+1)%5]) ；
4　　        …
5　　   //eat
6　　        …
7　　   signal(chopstick[i]) ；
8　　   signal(chopstick[(i+1)%5]) ；
9　　        …
10 　   //think
11 　        …
12   } while[TRUE];
在上述描述中，哲学家饥饿时总是会先去拿他左边的筷子，即执行wait(chopstick[i])；成功
后，再去拿他右边的筷子，即执行wait(chopstick [(i+1)%5])；又成功后便可进餐。进餐毕，先放
下他左边的筷子，再放下他右边的筷子。虽然上述解法可保证不会有两个相邻的哲学家同时进
餐，但是有可能引起死锁。假如5 位哲学家同时饥饿而各自拿起左边的筷子，这时就会使5 个信
号量chopstick均为0 ；当他们再试图去拿右边的筷子时，都将会因无筷子可拿而进行无限期的等
待。对于这样的死锁问题，可采取以下3种方法进行解决。
（1）至多只允许有4 位哲学家同时去拿左边的筷子，最终能保证至少有1 位哲学家能够进
餐，并在进餐毕时能释放出他用过的2根筷子，从而使更多的哲学家能够进餐。
（2）仅当哲学家的左右两根筷子均可用时，才允许他拿起筷子进餐。
（3）规定奇数号哲学家先拿他左边的筷子，然后再去拿他右边的筷子；而偶数号哲学家则
相反。按此规定，1号、2号哲学家将竞争1号筷子；3号、4号哲学家将竞争3号筷子。即5位哲学
家都先竞争奇数号筷子，获得后，再去竞争偶数号筷子，最后总会有一位哲学家能获得两根筷
子而进餐。
2．利用 AND 信号量机制解决哲学家进餐问题
在哲学家进餐问题中，要求每个哲学家先获得两个临界资源（筷子）后方能进餐，这在本
质上就是前面所介绍的AND同步问题，故用AND信号量机制可获得更简捷的解法。
1　  semaphore chopstick chopstick[5]={1,1,1,1,1} ；
2　　　  do {
3　　　　　　  …
4　　　　　  //think
5 　       …
6　　　　　  Swait(chopstick[(i+1)%5]， chopstick[i]) ；
7　　　　　　  …
8　　　　　  //eat
9 　       …
10 　　　　  Ssignal(chopstick[(i+1)%5]， chopstick[i]) ；
11 　　  } while[TRUE] ；

--- Page 149 ---
128
计算机操作系统 （慕课版）
3．利用管程解决哲学家进餐问题
利用管程解决哲学家进餐问题时，可使一个哲学家只有在左右两根筷子都可用时才被允许
拿起筷子。为了对这个方案进行编码，需要区分哲学家所处的3 个状态。为此，引入以下枚举类
型变量：
enum {thinking, hungry,eating} state[5];
哲学家i只有在其左右两个邻居不进餐时才能将变量state[i]设置为eating，即state[(i+4)%5]!=  
eating && state[(i+1)%5]!=eating。
还需要声明条件变量：
condition self [5];
其中，哲学家i在饥饿且又不能拿到所需筷子时，需要阻塞自己。
对筷子的拿起与否由管程dp来控制，管程dp的定义如下所示。
1   monitor dp{
2           enum { thinking, hungry, eating} state [5];
3           condition self [5];
4           initialization_code( ) { 
5                      for (int i = 0; i < 5; i++)
6                      state[i] = thinking;
7           }
8           void pickup (int i) { 
9                      state[i] = hungry;
10                      test(i);
11                      if (state[i] != eating) self [i].wait( );
12           }
13           void putdown (int i) { 
14                      state[i] = thinking;
15                      // test left and right neighbors
16                      test((i + 4) % 5);
17                      test((i + 1) % 5);
18           }
19           void test (int i) { 
20                      if ( (state[(i + 4) % 5] != eating) &&(state[i] == hungry) &&
21                      (state[(i + 1) % 5] != eating) ) { 
22                             state[i] = eating ;
23                             self[i].signal( ) ;
24                       }
25            }
26   }
每个哲学家在进餐前必须调用 pickup 操作，这有可能会挂起该哲学家进程。在成功完成该
操作后，哲学家才可进餐。接着，哲学家调用putdown操作以放下筷子，并开始思考。因此，哲
学家i的活动可描述为：
1   do {
2   dp.pickup (i);

--- Page 150 ---
129
第
4章 
进程同步
3           …
4           eat
5           …
6       dp.putdown (i);
7   } while[TRUE];
很容易看出，这个方案确保了相邻的两个哲学家不会同时进餐，且不会死锁。然而，存在
一个问题，即哲学家可能会饿死。
很容易看出，上述方案确保了相邻的两个哲学家不会同时进餐，且不会死锁。然而，存在
一个问题，即哲学家可能会饿死。请读者思考该如何解决这一问题。
思考题
4.6.3 读者 - 写者问题
一个数据文件或记录可被多个进程共享，我们把只要求读该文件的进程称为“reader进
程”，其他进程称为“writer进程”。允许多个进程同时读一个共享对象，因为读操作不会使数
据文件混乱。但不允许一个writer进程和其他reader进程或writer进程同时访问共享对象，因为这
种访问将会引起混乱。所谓“读者-写者问题”（reader-writer problem）是指保证一个writer进程
必须与其他进程互斥地访问共享对象的同步问题。读者-写者问题常被用于测试新同步原语。
读者-写者问题被提出后，就一直被用于测试几乎所有的新同步原语。该问题有多个变种，
它们都与优先级有关。最为简单的通常被称为“第一”读者 -写者问题，该问题要求没有读者需
要保持等待，除非有一个写者已被允许使用共享对象。换言之，如果有读者在访问对象，则不
管有没有写者在等待，后续读者都可以进行读操作。“第二”读者 -写者问题要求，一旦写者就
绪，那么写者会尽可能快地执行写操作。换言之，如果有一个写者在等待访问对象，那么就不
会有新读者开始读操作。
对这两个问题的解答都有可能导致饥饿。第一种情况下，写者可能饥饿；第二种情况下，
读者可能饥饿。本小节所介绍的都是对“第一”读者-写者问题的解答。
1．利用记录型信号量解决读者 - 写者问题
为了实现reader与writer进程在读/写时的互斥，设置了一个互斥信号量wmutex。另外，又设
置了一个整型变量readcount，用于表示正在读的进程数目。由于只要有一个reader进程在读，便
不允许writer进程去写。因此，仅当readcount=0表示尚无reader进程在读时，reader进程才需要执
行wait(wmutex)操作。若wait(wmutex)操作成功，reader进程便可去读，相应地做readcount+1操
作。同理，reader进程仅当在执行了readcount -1操作后其值为0时，才执行signal(wmutex)操作，
以便让writer进程写。又因为readcount是一个可被多个reader进程访问的临界资源，因此，也应
该为它设置一个互斥信号量rmutex。
读者-写者问题可描述如下：
1　  semaphore rmutex=1， wmutex=1 ；
2　  int readcount=0 ；
3　　   void reader( ) {
4　　　　  do {

--- Page 151 ---
130
计算机操作系统 （慕课版）
5　　　　　   wait(rmutex) ；
6　　　　　   if (readcount==0) wait(wmutex) ；
7　　　　　   readcount++ ；
8　　　　　   signal(rmutex) ；
9　　　　　   …
10 　　　　   perform read operation ；
11 　　　　   …
12 　　　　   wait(rmutex) ；
13 　　　　   readcount-- ；
14 　　　　   if (readcount==0) signal(wmutex) ；
15 　　　　   signal(rmutex) ；
16 　　  　 } while(TRUE);
17   　 }
18 　   void writer( ) {
19 　        do {
20 　　  　　 wait(wmutex) ；
21 　　  　　 perform write operation ；
22 　　  　　 signal(wmutex) ；
23 　        } while(TRUE) ；
24 　   }
25   void main( ) {
26     cobegin ；
27     reader( ) ； writer( ) ；
28     coend ；
29    }
2．利用“信号量集”机制解决读者 - 写者问题
这里的读者-写者问题与前面的略有不同，它增加了一个限制，即最多只允许RN个读者同
时进行读操作。为此，又引入了一个信号量L ，并赋予其初值RN，通过执行Swait(L,1,1)操作来
控制读者的数目，每当有一个读者进行读操作时，就要先执行Swait(L,1,1)操作以使L 的值减1。
当有RN个读者进行读操作后，L 便会减为0，此时第RN+1个读者若要进行读操作，则必然会因
Swait(L,1,1)操作失败而阻塞。利用“信号量集”机制来解决读者-写者问题的描述如下：
1　  int RN ；
2　  semaphore L=RN， mx=1 ；
3　　      void reader( ) {
4　        do {
5　　　　  　　  Swait(L,1,1) ；
6　　　  　　　  Swait(mx,1,0) ；
7　　　  　　      …
8　　　  　　　  perform read operation ；
9　　　  　　      …

--- Page 152 ---
131
第
4章 
进程同步
10 　　　　        Ssignal(L,1) ；
11         } while(TRUE) ；
12     }
13     void writer( ) {
14            do {
15 　　　　           Swait(mx,1,1； L,RN,0) ；
16 　　　　           perform write operation ；
17 　　　　           Ssignal(mx,1) ；
18            } while(TRUE) ；
19     }
20   void main( ) {
21     cobegin ；
22     reader( ) ； writer( ) ；
23     coend ；
24   }
其中， Swait(mx,1,0)语句起着“开关”的作用。只要无writer进程进行写操作，mx=1，
reader进程就可以读。但只要有writer进程进行写操作，mx=0，任何reader进程就都无法进行读
操作。Swait(mx,1,1;L,RN,0)语句表示，仅当既无writer进程在写(mx=1)，又无reader进程在读
(L=RN)时，writer进程才能进入临界区写。
通过分析前述经典的进程同步问题的解决方法，可以总结出进程同步的编程实现方法：首
先，编写程序核心代码；然后，分析进程同步关系；最后，分析进程互斥关系。
进程同步分析方法：①找出需要同步的代码片段（关键代码）；②分析所找代码片段的执
行次序；③增加同步信号量并赋初值；④按照4.5节介绍的方法，在所找代码片段前后加wait(S)
和signal(S)操作。
进程互斥分析方法：①查找临界资源；②划分临界区；③定义互斥信号量并赋初值；④在
临界区前后的进入区和退出区中分别加入wait(S)和signal(S)操作。
4.7 Linux进程同步机制
Linux系统下并发的主要来源介绍如下。
（1）中断处理：例如，当进程在访问某个临界资源的时候发生了中断，随后进入中断处理
程序，如果在中断处理程序中也访问了该临界资源，则虽然不是严格意义上的进程并发，但是
也会造成对该资源的竞争使用。
（2）内核态抢占： 例如，当进程在访问某个临界资源的时候发生内核态抢占，随后进
入了高优先级的进程，如果该进程也访问了同一临界资源，那么就会造成进程与进程之间的  
并发。
（3）多处理机并发：多处理机系统上的进程与进程之间是严格意义上的并发（并行），每
个处理机都可以独自调度运行一个进程，在同一时刻有多个进程在同时运行。
采用同步机制的目的就是避免多个进程并发访问同一临界资源。为此，Linux内核提供了一
组相当完备的同步方法，这些方法使得内核开发者能够编写出高效的代码。针对资源访问的不
同需求而使用不同的同步方法，有些同步方法可以相互适用，但是所依据的法则是：把系统中

--- Page 153 ---
132
计算机操作系统 （慕课版）
的并发度保持在尽可能高的程度。Linux内核同步机制有多种，且其数量会随着内核版本的更新
而增加。本节主要介绍常用的同步方法。
1．原子操作
首先介绍同步方法中的原子操作，因为它是其他同步方法的基石。原子操作可以保证指令
以原子的方式执行——执行过程不被打断。
Linux内核通过一些手段来实现某些操作的原子性，举例如下。
（1）操作码前缀为lock的汇编指令，即使在多CPU下也能保证其后的汇编指令的原子性，
lock会锁定内存总线，保证在执行汇编指令时没有其他CPU同时读/写内存。
（2）在多处理机中，Linux内核通过提供atomic_t类型封装了一系列的原子操作，如atomic_
inc(v)表示把数值从1加到v。
2. 自旋锁
Linux内核中最常用的锁是自旋锁(spin lock)，其最初的设计目的是在多处理机系统中提供对
共享数据的保护。
自旋锁的设计思想是：在多处理机之间设置一个全局变量V，表示锁，并定义当V=1时为锁
定状态，V=0时为解锁状态。自旋锁同步机制是针对多处理机而设计的，属于“忙等”机制。
自旋锁机制只允许唯一的一个执行路径持有自旋锁。如果处理机A上的代码要进入临界区，就要
先读取V的值。如果V!=0（即锁定状态），则表明有其他处理机上的代码正在对共享数据进行
访问，那么此时处理机A就会进入忙等状态（即自旋状态）；如果V=0，则表明当前没有其他处
理机上的代码进入临界区，此时处理机A 可以访问该临界资源。然后把V 设置为1，再进入临界
区，访问完毕后离开临界区时将V 设置为0。需要注意的是，必须确保处理机A “读取V、判断V
的值、更新V”这一操作是一个原子操作。
自旋锁的实现与体系结构相关，具体的实现被定义在文件<linux/spinlock.h>中，其基本使用
形式如下：
1   DEFINE_SPINLOCK(mr_lock);
2   spin_lock(&mr_lock);
3   /* 临界区 */
4   spin_unlock(&mr_lock);
除了普通的自旋锁外，自旋锁还有一些变种，如读写自旋锁（ rwlock）、顺序自旋锁
（seqlock）等。
3. 信号量
前面介绍的自旋锁同步机制是一种忙等机制，其在临界资源被锁定的时间很短的情况下很
有效。但是在临界资源被持有的时间很长或者不确定的情况下，忙等机制会浪费很多宝贵的处
理机时间。针对这种情况，Linux内核中提供了信号量（semaphore）机制，此类型的同步机制在
进程无法获取临界资源的情况下，会立即释放处理机的使用权，并使进程阻塞在所访问的临界
资源对应的等待队列上；在临界资源被释放时，再唤醒阻塞在该临界资源上的进程。另外，信
号量机制不会禁用内核态抢占，因此持有信号量的进程一样可以被抢占，这意味着信号量机制
不会给系统的响应能力、实时能力带来负面的影响。
信号量的实现与体系结构相关，具体的实现被定义在文件 <asm/semaphore.h> 中。它的基本
使用形式如下：

--- Page 154 ---
133
第
4章 
进程同步
1   /* 定义并声明一个信号量， 名字为 mr_sem， 用于信号量计数 */
2   static DECLARE_MUTEX(mr_sem);
3   /* 试图获取信号量 */
4   if (down_interruptible(&mr_sem)){
5       /* 信号被接收， 信号量还未被获取 */
6   }
7   /* 临界区 */
8   /* 释放给定的信号量 */
9   up(&mr_sem);
与自旋锁类似，信号量除了有普通信号量这一类型外，还有读/写信号量（rwsem）。
4．互斥锁
新版Linux 内核中，引入了互斥锁（ mutex）这个数据类型，其又称为互斥体，是一种可以
阻塞的强制互斥锁。
互斥锁的行为与使用计数为1的信号量类似，但操作接口更简单，实现更高效，而且使用限
制更强。
静态定义互斥锁：DEFINE_MUTEX(name);
动态初始化互斥锁：mutex_init(&name);
对互斥锁进行锁定和解锁的操作如下：
1   mutex_lock(&name);
2   /* 临界区 */
3   mutex_unlock(&name);
基于上述介绍可知，互斥锁就是一个简化版的信号量，因为它不再需要使用任何计数。
5．禁用中断（单处理机不可抢占系统）
由本节所述内容可知，对于单处理机不可抢占系统来说，系统的异步并发源主要是中断处
理。因此在进行临界资源访问时，禁用/ 使能中断即可达到消除异步并发源的目的。Linux系统
中提供了两个宏（local_irq_enable 和local_irq_disable ）来使能和禁用中断。在 Linux系统中，使
用这两个宏来使能和禁用中断以保护临界区时，要确保处于两者之间的代码的执行时间不能太
长，否则将会影响系统的性能，主要是会导致系统不能及时响应外部中断。
4.8 本章小结
进程同步是现代OS并发运行的重要基础。本章介绍了进程同步的基本概念、临界区问题、
常用的进程同步机制和经典的进程同步问题。在进程同步机制中，分别介绍了软件同步、硬件
同步、信号量和管程等4种机制。
通过本章的学习，读者应该了解进程同步的概念、解决临界区问题的4 个原则以及管程等，
掌握记录型信号量的定义和使用方法，并且能够使用信号量来实现进程间的互斥与同步。由于
进程同步是个抽象的概念，读者通常难以理解它，因此通过对经典进程同步问题的解答，可帮
助读者理解实际编程中的同步问题，提高读者的逻辑思维能力和实践编程能力。

--- Page 155 ---
134
计算机操作系统 （慕课版）
习题4（含考研真题）
一、简答题
1．什么是临界资源？什么是临界区？
2．同步机制应遵循的准则有哪些？
3．为什么各进程对临界资源的访问必须互斥？
4．如何保证各进程互斥地访问临界资源？
5．何谓“忙等”？它有什么缺点？
6．试述采用Peterson算法实现临界区互斥的原理。
7．哪些硬件方法可以解决进程互斥问题？简述它们的用法。
8．（考研真题）如果用于进程同步的信号量的P 、V操作不用原语实现，则会产生什么后
果？举例说明。
9．AND信号量机制的基本思想是什么？它能解决什么问题？
10．利用信号量机制实现进程互斥时，针对互斥信号量的wait()和 signal()操作为什么要成对
出现？
11．什么是管程？它有哪些特性？
12．试简述管程中条件变量的含义与作用。
二、计算题
13．若信号量的初值为2，当前值为-1，则表示有多少个等待进程？请分析。
14．有m个进程共享同一临界资源，若使用信号量机制实现对某个临界资源的互斥访问，
请求出信号量的变化范围。
15．若有4个进程共享同一程序段，而且每次最多允许3 个进程进入该程序段，则信号量值
的变化范围是什么？
三、综合应用题
16．（考研真题）  3 个进程 P1、P2、P3 互斥地使用一个包含 N （N ＞0） 个单元的缓冲区。 P1 每
次用 produce( ) 生成一个正整数， 并用 put( ) 将其送入缓冲区的某一空单元中 ； P2 每次用 getodd( )
从该缓冲区中取出一个奇数， 并用 countodd( ) 统计奇数的个数 ； P3 每次用 geteven( ) 从该缓冲区中
取出一个偶数， 并用 counteven( ) 统计偶数的个数。 请用信号量机制实现这 3 个进程的同步与互斥
活动， 并说明所定义的信号量的含义。 要求用伪代码描述。
17．（考研真题）某银行提供了 1 个服务窗口和 10 个供顾客等待时使用的座位。 顾客到达银
行时， 若有空座位， 则到取号机上领取一个号， 等待叫号。 取号机每次仅允许一位顾客使用。 当营
业员空闲时， 通过叫号选取一位顾客， 并为其服务。 顾客和营业员的活动过程描述如下。
1　  cobegin{
2　　     process 顾客 i{
3　　　    从取号机上获得一个号码 ;
4　　　    等待叫号 ;

--- Page 156 ---
135
第
4章 
进程同步
5　　  　  获得服务 ;
6　　     }
7　　     process 营业员 {
8　　　    while (TRUE) {
9　　　　      叫号 ;
10 　　　      为顾客服务 ;
11 　　    }
12 　     }
13   } coend
请添加必要的信号量和 P、V操作或wait()、signal()操作，实现上述过程中的互斥与同步。
要求写出完整的过程，说明信号量的含义并赋初值。
18．如图4-3所示，有1个计算进程和1个打印进程，它们共享一个单缓冲区，计算进程不断
计算出一个整型结果，并将它放入单缓冲区中；打印进程则负责从单缓冲区中取出每个结果并
进行打印。请用信号量机制来实现它们的同步关系。
单缓冲区
计算进程 打印进程
图4-3  共享单缓冲区的计算进程和打印进程
19．有3个进程P1、P2、P3协作解决文件打印问题。P 1将文件记录从磁盘读入内存的缓冲区
1，每执行一次读一个记录；P 2将缓冲区1 中的内容复制到缓冲区2 中，每执行一次复制一个记
录；P3将缓冲区2 中的内容打印出来，每执行一次打印一个记录。缓冲区的大小与记录大小一
样。请用信号量来保证文件的正确打印。
20．桌上有一个能盛得下5 个水果的空盘子。爸爸不停地向盘中放苹果和橘子，儿子不停
地从盘中取出橘子享用，女儿不停地从盘中取出苹果享用。规定3 人不能同时向（从）盘子中放
（取）水果。试用信号量机制来实现爸爸、儿子和女儿这3个“循环进程”之间的同步。
21．试用记录型信号量写出一个不会死锁的哲学家进餐问题的算法。

--- Page 157 ---
存储器管理
