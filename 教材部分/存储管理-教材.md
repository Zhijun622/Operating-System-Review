# 存储管理

第5章
存储器历来都是计算机系统的重要组成部分。近年来，随着计算机技术的发展，系统
软件和应用软件在种类、功能等方面都在急剧膨胀，虽然存储器容量也一直在不断扩大，
但其仍不能满足现代软件发展的需要。因此，存储器仍然是一种宝贵而又稀缺的资源。如
何对它加以有效管理，不仅直接影响存储器的利用率，而且对系统性能也有重大影响。存
储器管理的主要对象是内存。由于对外存的管理与对内存的管理相类似，只是它们的用途
不同，即外存主要用于存放文件，因此本书把对外存的管理放在第8章（文件管理）中进行
介绍。本章知识导图如图5-1所示。
存储器管理
存储器的层次结构
程序的装入与链接
对换与覆盖
连续分配存储管理方式
离散分配存储管理方式
地址绑定和内存保护
程序的装入
程序的链接
逻辑地址
物理地址
内存保护
单一连续分配
固定分区分配
对换
覆盖
可变分区分配
动态分区分配
动态重定位分区分配
分页存储管理方式
分段存储管理方式
段页式存储管理方式
图5-1  第5章知识导图
第5 章导读


--- Page 158 ---
137
第
5章 
存储器管理
5.1 存储器的层次结构
计算机在执行指令时，几乎每条指令都会涉及对存储器的访问，因此要求计算机对存储器
的访问速度能跟得上处理机的运行速度，或者说，存储器的速度必须非常快，以能与处理机的
速度相匹配，否则会明显地影响处理机的运行。此外还要求存储器具有非常大的容量，而且存
储器的价格还应很便宜。对于上述十分严格的3 个要求，目前是无法同时满足的。因此在现代计
算机系统中，都无一例外地采用了多层结构的存储器。
5.1.1 多层结构的存储器
1．存储器的多层结构
对于通用计算机而言，存储层次至少应具有3 层：最高层为CPU寄存器，中间层为主存储
器，最低层为辅助存储器（简称辅存）。在较高档的计算机中，还可以根据具体的功能分工，
将存储层次细分为寄存器、高速缓存、主存储器、磁盘缓存、固定磁盘、可移动存储介质等6
层。如图5-2所示，在存储层次中，层次越高（越靠近 CPU），存储介质的访问速度越快，价格
也越高，所配置的存储容量也越小。其中，寄存器、高速缓存、主存储器和磁盘缓存，均属于
OS存储管理的管辖范畴，断电后它们所存储的信息将不再存在。而低层的固定磁盘和可移动存
储介质，则属于设备管理的管辖范畴，它们所存储的信息会被长期保存。
寄存器
高速缓存
主存储器
磁盘缓存
固定磁盘
可移动存储介质
CPU寄存器
主存储器
辅助存储器
图5-2  计算机系统存储层次示意
2．可执行存储器
在计算机系统的存储层次中，寄存器和主存储器又被称为可执行存储器。对于存放在其中
的信息，与存放在辅存中的信息相比而言，计算机所采用的访问机制是不同的，所须耗费的时
间也是不同的。进程可以在很少的时钟周期内使用一条load或 store指令对可执行存储器进行访
问，但对辅存的访问则需要通过 I/O设备实现。因此，在访问中将涉及中断、设备驱动程序以及
物理设备的运行，所须耗费的时间远远高于对可执行存储器访问的时间，一般会相差3 个数量级
甚至更多。
不同层次的存储介质会由OS进行统一管理。OS的存储管理会负责对可执行存储器进行分配
与回收，以及向其提供在不同存储层次间数据移动的管理机制，如主存储器与磁盘缓存、高速
缓存与主存储器间的数据移动等。而在设备和文件管理中，OS则会根据用户的需求，对辅存提
供管理机制。本章主要讨论有关主存储器管理部分的问题，针对辅存管理问题，本书将会在第9
章中进行介绍。

--- Page 159 ---
138
计算机操作系统 （慕课版）
5.1.2 主存储器和寄存器
1．主存储器
主存储器，简称主存或内存，也称为可执行存储器，是计算机系统中的主要部件，用于
保存进程运行时的程序和数据。通常，处理机都会从内存中取得指令和数据，并将其所取得的
指令放入指令寄存器中，而将其所读取的数据装入数据寄存器中，或者进行相反操作，即将寄
存器中的数据存入内存。早期的内存是由磁芯做成的，其容量一般为数十KB到数百KB。随着
VLSI 的发展，现在的内存已由 VLSI 构成，即使是微机系统，其容量也在数十 MB到数GB，而
且还在不断增加。而嵌入式计算机系统则一般仅有几十KB到几MB。 CPU与外围设备交换的信
息，一般也会依托于内存的地址空间。由于内存的访问速度远低于CPU执行指令的速度，为缓
和这一矛盾，在计算机系统中引入了寄存器和高速缓存。
2．寄存器
寄存器是CPU内部的一些小型存储区域，用于暂时存放参与运算的指令、数据和运算结
果等内容。寄存器具有与处理机相同的速度，因此寄存器的访问速度也是最快的，其完全能与
CPU协调工作，但价格却十分昂贵，故其容量不可能做得很大。在早期计算机中，寄存器的数
目仅为几个，主要用于存放处理机运行时的数据，以加速存储器访问速度，如使用寄存器存放
操作数，或将其用作地址寄存器以加快地址变换速度等。随着VLSI的发展，寄存器的成本也
在迅速降低，在当前的微机系统和大中型计算机中，寄存器的数目都已增加到数十个到数百个
了，而寄存器的长度一般是32位或64位；但是在小型嵌入式计算机中，寄存器的数目仍只有几
个到十几个，而且寄存器的长度通常只有8位。
5.1.3 高速缓存和磁盘缓存
1．高速缓存
高速缓存是现代计算机结构中的一个重要部件，它是介于寄存器和内存之间的存储器，
主要用于备份内存中较常用的数据，以减少处理机对内存的访问次数，这样可大幅度地提高程
序执行速度。高速缓存的容量远大于寄存器，而又比内存约小两个到三个数量级，容量一般为
几十KB到几MB，访问速度快于内存。在计算机系统中，为了缓和内存与处理机速度之间的矛
盾，许多地方都设置了高速缓存。在以后各章中将会经常遇见各种高速缓存，届时再对它们进
行详细介绍。
将一些常用数据放在高速缓存中是否有效，这涉及程序执行的局部性原理（程序在执行时
将呈现出局部性规律，即在较短的时间内，程序的执行仅局限于某个部分，关于局部性原理问
题，本书将在第6章中做进一步的介绍）。通常，进程的程序和数据存放在内存中，每当要访问
它们时，它们才会被临时复制到一个速度较快的高速缓存中。这样，当CPU访问一组特定信息
时，须首先检查它是否在高速缓存中，如果在，便可直接从中取出并使用，以避免访问内存。
否则，就须从内存中读出信息。例如，大多数计算机系统都有一个指令高速缓存，用来暂存下
一条将要执行的指令。如果没有这种指令高速缓存，CPU将会空等若干个时钟周期，直到下一
条指令从内存中取出。由于高速缓存的速度越高，价格越贵，故在有的计算机系统中设置了两
级或多级高速缓存。紧靠CPU的一级高速缓存的速度最高，但容量最小；二级高速缓存的容量
稍大，但速度稍低。

--- Page 160 ---
139
第
5章 
存储器管理
2．磁盘缓存
由于目前磁盘的I/O速度远低于对内存的访问速度，为了缓和两者在速度上的不匹配，特设
置了磁盘缓存，主要用于暂时存放频繁使用的一部分磁盘数据，以减少访问磁盘的次数。但磁
盘缓存与高速缓存不同，它本身并不是一种实际存在的存储器，而是利用内存中的部分存储空
间，暂时存放从磁盘中读出（或写入）的信息。内存也可被看作辅存的高速缓存，因为辅存中
的数据必须复制到内存方能使用；此外，数据也必须先存在于内存中才能输出到辅存。
一个文件的数据，可能会先后出现在不同层次的存储器中，例如，一个文件的数据通常被
存储在辅存（如硬盘）中，当其需要运行或被访问时，就必须调入内存，也可以暂时存放在内
存的磁盘高速缓存中。大容量的辅存通常会采用磁盘，磁盘数据经常会备份到磁带或可移动磁
盘组上，以防止磁盘故障时丢失数据。有些系统自动地把老文件数据从辅存转移存储到海量存
储器（如磁带）中，这样做能降低存储价格。
5.2 程序的装入与链接
要在系统中运行用户程序，就必须先将其装入内存中，然后将其转变为
一个可以执行的程序，这一过程通常要经过以下3 个步骤：①编译，由编译程
序（compiler）对用户源程序进行编译，形成若干个目标模块（ object module ）；②链接，由链
接程序（linker）将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个
完整的装入模块（load module）； ③装入，也称为加载，由装入程序（loader）将装入模块装入
内存。图5-3所示为处理用户程序的3 个步骤。本节将在介绍这些过程中涉及的地址绑定和内存
保护的基础上，扼要阐述程序（含数据）的链接与装入过程。
编译程序产生
的目标模块
…
库
链接
程序
第一步 第二步 第三步
内存
装入
程序装入模块
图5-3  处理用户程序的3个步骤
5.2.1 地址绑定和内存保护
1．逻辑地址和物理地址
在用户程序执行前，需要经过图5-3所示的步骤。在这些步骤中，地址可能有不同的表示形
式。源程序中的地址通常用符号表示，如变量count。编译器通常将这些符号地址绑定（bind）
到可重定位的地址或相对地址（如从本模块开始的第10个字节）上。链接程序或装入程序再将
这些相对地址绑定到绝对地址（如内存的第74 010个字节）。每次绑定都是从一个地址空间到另
一个地址空间的映射。地址绑定通常发生在程序编译时、装入时或运行时，具体的绑定方式详
见5.2.2小节。
内存管理背景


--- Page 161 ---
140
计算机操作系统 （慕课版）
CPU生成的地址通常称为 逻辑地址（logic address）或相对地址，而内存单元看到的地址
（即装入内存地址寄存器的地址），通常称为物理地址（physical address）或绝对地址。
在编译时和装入时的地址绑定会生成相同的逻辑地址和物理地址，而执行时的地址绑定
则会生成不同的逻辑地址和物理地址。在这种情况下，我们也称逻辑地址为虚拟地址（virtual 
address）。由程序所生成的所有逻辑地址的集合称为逻辑地址空间（logic address space），这些
逻辑地址对应的所有物理地址的集合称为物理地址空间（ physical address space ）。因此，对于
执行时的地址绑定方案，逻辑地址空间与物理地址空间是不同的。
2．内存保护
系统不仅需要完成地址变换，还需要保证操作的正确。为了系统操作的正确，应保证OS
不被用户访问。在多用户系统上，还应保证用户进程不会相互影响。这种保证是用硬件来实现
的，因为OS通常不干预CPU对内存的访问（倘若干预，则会导致性能损失）。硬件实现具有多
种不同的方式。
首先，需要确保每个进程都有一个单独的内存空间。单独的内存空间可以保证进程不会
相互影响，这对于将多个进程加载到内存以便并发执行至关重要。为了分开内存空间，需要
确定一个进程可以访问的合法地址范围，并确保该进程只能访问这些合法地址。系统通过两
个寄存器来实现这种保护，这两个寄存器即基地址寄存器（base register）和界限寄存器（limit 
register）。基地址寄存器保存最小的合法物理内存地址（基地址），界限寄存器指定了合法范
围的大小（界限地址）。例如，如果基地址寄存器为300 040而界限寄存器为120 900，那么进程
可以合法访问从300 040到420 939（含）的所有地址。
内存空间保护的实现是通过CPU硬件对在用户态下产生的物理地址与寄存器的地址进行比
较来完成的，即判断“基地址≤物理地址＜（基地址+界限地址）”是否成立。当在用户态下执
行的程序试图访问OS内存或其他用户内存时，其会陷入OS内核，而OS内核则会将其作为致命
错误来处理。这种方案可以防止用户程序无意或故意修改OS以及其他用户的代码或数据。
加载基地址寄存器和界限寄存器时必须使用特权指令，由于特权指令只能在内核态下执
行，因此只有OS内核才可以加载基地址寄存器和界限寄存器。这种方案允许OS内核修改这两个
寄存器的值，而不允许用户程序修改它们。
5.2.2 程序的装入
为了便于读者理解，我们先介绍一个无须进行链接的单个目标模块的装入过程。该目标模
块就是装入模块。在将一个装入模块装入内存时，可以有如下3种装入方式。
1．绝对装入方式
当计算机系统很小，且仅能运行单道程序时，完全有可能知道程序将驻留在内存的什么位
置。此时可以采用绝对装入方式（absolute loading mode ）。用户程序经编译后，将产生绝对地
址的目标代码。例如，事先已知用户程序（进程）驻留在从R处开始的位置，则编译程序所产生
的目标模块（即装入模块），便可从R处开始向上扩展。绝对装入程序便可按照装入模块中的地
址，将程序和数据装入内存。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址
完全相同，故无须对程序和数据的地址进行修改。
程序中所使用的绝对地址，既可在编译或汇编时给出，又可由程序员直接赋予。但在由
程序员直接给出绝对地址时，不仅要求程序员熟悉内存的使用情况，而且一旦程序或数据被修

--- Page 162 ---
141
第
5章 
存储器管理
改，就可能要改变程序中的所有地址。因此，通常会选择在程序中采用符号地址，然后在编译
或汇编时，再将这些符号地址变换为绝对地址。
2．可重定位装入方式
绝对装入方式只能将目标模块装入内存中事先指定的位置，这只适用于单道程序环境。而在
多道程序环境下，编译程序不可能预知经编译后所得到的目标模块应放在内存的何处。因此，对
于用户程序编译所形成的若干个目标模块，它们的起始地址通常都是从0开始的，程序中的其他地
址也都是相对于起始地址计算的。此时，不可能再用绝对装入方式，而应采用可重定位装入方式
（relocation loading mode），它可以根据内存的具体情况，将装入模块装入内存的适当位置。
值得注意的是，采用可重定位装入方式将装入模块装入内存，会使装入模块中的所有逻辑
地址与实际装入内存的物理地址不同，图5-4展示了这一情况。在用户程序的1 000号单元处有
一条指令LOAD 1,2 500，该指令的功能是将2 500单元中的整数365取至寄存器1 。但若将该用户
程序装入内存的10 000 ～15 000号单元而不进行地址变换，则在执行11 000号单元中的指令时，
它将仍从2 500 号单元中把数据取至寄存器 1，进而就会导致数据错误。由图 5-4可见，正确的处
理方法应该是，将取数指令中的地址2 500修改成12 500，即把指令中的相对地址2 500与本程序
在内存中的起始地址10 000相加，进而得到正确的物理地址12 500。除了数据地址应修改外，
指令地址也应做同样的修改，即将指令的相对地址1 000与起始地址10 000相加，得到绝对地址  
11 000。通常，把在装入时对目标程序中指令和数据的逻辑地址变换为物理地址的过程，称为重
定位。如果地址变换是在进程装入时一次性完成的，以后不再改变，则称这种重定位方式为静
态重定位。
0
1 000
10 000
11 000
12 500
15 000
2 500
LOAD 1,2 500 LOAD 1,2 500
365
365
5 000
作业地址空间
内存空间
图5-4  程序装入内存时的情况
3．动态运行时装入方式
可重定位装入方式可将装入模块装入内存中任何允许的位置，故可用于多道程序环境。但
该方式并不允许程序运行时在内存中移动位置。因为程序在内存中的移动，意味着它的物理位
置发生了变化，这时必须对程序和数据的地址（绝对地址）进行修改后，程序方能运行。然而
实际情况是，在运行过程中它在内存中的位置可能经常要改变，例如，在具有对换功能的系统
中，一个进程可能被多次换出，又被多次换入，每次换入后的位置通常是不同的。在这种情况
下，就应采用动态运行时装入方式（dynamic run-time loading mode）。
动态运行时装入方式在把装入模块装入内存后，并不会立即把装入模块中的相对地址变换
为绝对地址，而是会把这种地址变换推迟到程序真正要执行时才进行。因此，装入内存后的所
有地址都仍是相对地址。这种在运行时进行地址变换的重定位方式称为动态重定位。为使地址
变换不影响指令的执行速度，这种方式需要一个重定位寄存器的支持，我们将在 5.4节中对此做
详细介绍。

--- Page 163 ---
142
计算机操作系统 （慕课版）
5.2.3 程序的链接
源程序经过编译后，可得到一组目标模块。链接程序的功能是将这组目标模块以及它们所
需要的库函数，装配成一个完整的装入模块。在对目标模块进行链接时，根据进行链接的时间
的不同，可把链接分成以下3种。
1．静态链接
在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后
不再拆开。我们把这种事先进行链接而以后不再拆开的方式，称为静态链接（static linking）方
式。我们通过一个例子来说明在实现静态链接时应解决的一些问题。在图5-5（ a）中给出了经
过编译后所得的3 个目标模块A 、B、C，它们的长度分别为L 、M、N。在模块A 中有一条语句
CALL B，用于调用模块B 。在模块B中有一条语句CALL C，用于调用模块C 。B和C都属于外部
调用符号，在将这几个目标模块装配成一个装入模块时，须解决以下两个问题。
（1）修改相对地址。在由编译程序所产生的所有目标模块中，使用的都是相对地址，它们
的起始地址都为0，每个模块中的地址都是相对起始地址计算的。在将它们链接成一个装入模块
后，原模块B和C在装入模块中的起始地址不再是0 ，而分别是L和L+M，故此时须修改模块B 和
C中的相对地址，即使原模块B 中的所有相对地址都加上L ，原模块C 中的所有相对地址都加上
L+M。
（2）变换外部调用符号。将每个模块中所用的外部调用符号也都变换为相对地址，如把B
的起始地址变换为L，把C的起始地址变换为L+M，如图5-5 （b）所示。这种先进行链接所形成
的一个完整的装入模块，又称为可执行文件。其形成后便通常不再拆开，要运行时可直接将其
装入内存。把这种事先进行链接而以后不再拆开的链接方式，称为静态链接方式。
0
L-1
0
L-1
L+M-1
L+M+N-1
L+M
L0
M-1
0
N-1
模块A
CALL B；
Return；
模块B
CALL C；
Return；
模块C
Return；
模块A
JSR“L”
Return；
模块B
JSR“L+M”
Return；
模块C
Return；
（a）目标模块 （b）装入模块
图5-5  静态链接示意
2．装入时动态链接
装入时动态链接（load-time dynamic linking）是指，将用户源程序编译后所得的一组目标模
块，在装入内存时，采用边装入边链接的链接方式，即在装入一个目标模块时，若发生一个外
部模块调用事件，则将引起装入程序找出相应的外部目标模块，并将它装入内存，还要按照图
5-5所示的方式修改目标模块中的相对地址。装入时动态链接方式有以下优点。
（1）便于修改和更新。对于经静态链接装配在一起的装入模块，如果要修改或更新其中的
某个目标模块，则要求重新打开装入模块。这不仅是低效的，而且有时是不可能的。若采用动
态链接方式，则由于各目标模块是分开存放的，因此要修改或更新各目标模块是一件非常容易

--- Page 164 ---
143
第
5章 
存储器管理
的事。
（2）便于实现对目标模块的共享。在采用静态链接方式时，每个应用模块都必须含有其目
标模块的复制版本，而无法实现对目标模块的共享。但采用装入时动态链接方式时，OS很容易
将一个目标模块链接到几个应用模块上，实现多个应用程序对该目标模块的共享。
3．运行时动态链接
在许多情况下，应用程序在运行时，每次要运行的模块可能是不相同的。但由于事先无法
知道本次要运行哪些模块，故只能将所有可能要运行的模块全部装入内存，并在装入时全部链
接在一起。显然这是低效的，因为往往会有部分目标模块根本就不运行。比较典型的例子是作
为错误处理所使用的目标模块，如果程序在整个运行过程中都不出现错误，则显然就不会用到
该模块。
目前流行的运行时动态链接（ run-time dynamic linking ）方式，是对上述装入时动态链接
方式的一种改进。这种链接方式将对某些模块的链接推迟到程序执行时才进行。亦即，在执行
过程中，当发现一个“被调用模块”尚未被装入内存时，立即由OS去找到该模块，将其装入内
存，并链接到装入模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接
到装入模块上，这样不仅能加快程序的装入过程，而且可节省大量内存空间。
请思考动态装入和动态链接技术的联系与区别，以及各自的优缺点。
思考题
5.3 对换与覆盖
当内存空间不足或进程所需的空间大于系统能够提供的空间时，系统应如何满足进程的请
求？除了拒绝该进程运行外，还可以使用一些特殊的技术来保证能够在较小的内存空间运行较
大的进程，这些技术被称为内存“扩充”技术。所谓的内存“扩充”，并不是指增加系统的物
理内存，而是指在现有的物理内存的基础上扩大内存的使用效率。
常用的内存扩充技术包括对换、覆盖、紧凑和虚拟存储器等。其中，紧凑将在5.4.4小节介
绍，虚拟存储器将在第6章介绍。本节主要介绍对换（swapping）技术和覆盖（overlay）技术，
重点是对换技术。
5.3.1 多道程序环境下的对换技术
对换技术也称为交换技术，最早应用于麻省理工学院的单用户分时系统中。由于当时计算
机的内存都非常小，为了使该系统能分时运行多个用户程序，特引入了对换技术。系统把所有
的用户作业存放在磁盘上，每次只能调一个作业进入内存，当该作业的一个时间片用完时，将
它调至外存的后备队列上等待，再从后备队列上将另一个作业调入内存。这就是最早出现的分
时系统中所用的对换技术，现在已很少使用。
1．对换的引入
在多道程序环境下，一方面，内存中的某些进程，可能由于某事件尚未发生而被阻塞运
行，但同时它们却占用了大量的内存空间，有时甚至可能出现在内存中所有进程都被阻塞而迫

--- Page 165 ---
144
计算机操作系统 （慕课版）
使CPU停下来等待的情况；另一方面，在上述情况发生时，可能又有着许多作业因内存空间不
足（一直驻留在外存上）而不能进入内存运行。显然这对系统资源是一种严重的浪费，且会导
致系统吞吐量下降。为了解决这一问题，在系统中又增设了对换（也称交换）设施。所谓“对
换”，是指把内存中暂时不能运行的进程或者暂时不用的程序和数据，转移到外存上，以便腾
出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据存入内存，进而实
现所谓的“对换”。对换是改善内存利用率的有效措施，它可以直接提高处理机的利用率和系
统吞吐量。
自20世纪60年代初期出现“对换”技术后，其便引起了人们的重视。在早期的UNIX系统
中已引入了对换功能，该功能一直保留至今，各个UNIX版本实现对换功能的方法也大体上是
一样的，即在系统中设置一个对换进程，由它将内存中暂时不能运行的进程调出到磁盘的对
换区，同样也由该进程将磁盘上已具备运行条件的进程调入内存。在Windows系统中也具有对
换功能。如果一个新进程在装入内存时发现内存不足，则可以将已在内存中的老进程调至磁
盘，以腾出内存空间。由于对换技术的确能有效改善内存的利用率，故现在已被广泛应用于
OS中。
2．对换的类型
在每次对换时，都会将一定数量的程序或数据换入或换出内存。根据每次对换时所对换的
数量，可将对换分为以下两类。
（1）整体对换。在第3章中介绍处理机调度时已说明，处理机中级调度实际上就是存储器
的对换功能，其目的是解决内存紧张问题，并进一步提高内存的利用率和系统吞吐量。由于在
中级调度中，对换是以整个进程为单位的，因此称之为“进程对换”或“整体对换”。这种对
换被广泛应用于多道程序系统中，并被作为处理机中级调度。
（2）页面（分段）对换。如果对换是以进程的一个“页面”或“分段”为单位而进行的，
则称之为“页面对换”或“分段对换”，它们统称为“部分对换”。这种对换方法是实现后面
要讲到的请求分页和请求分段存储管理的基础，其目的是支持虚拟存储系统。在此只介绍进程
对换，而分页或分段对换将在第6章（虚拟存储器）中进行介绍。为了实现进程对换，系统必须
能实现3方面的功能：对换区的管理、进程的换出与换入。
5.3.2 对换区的管理
1．对换区管理的主要目标
在具有对换功能的OS中，通常把磁盘空间分为文件区和对换区这两部分。
（1）文件区管理的主要目标。文件区占用了磁盘空间的大部分区域，用于存放各类文件。
由于通常的文件会较长时间地驻留在外存上，系统访问它们的频率较低，故对文件区管理的主
要目标是提高文件存储空间的利用率，然后才是提高对文件的访问速度。因此，对文件区的管
理应采取离散分配存储管理方式（具体介绍详见本书第9章）。
（2）对换区管理的主要目标 。对换区只占用磁盘空间的小部分区域，用于存放从内存
换出的进程。由于这些进程在对换区中驻留的时间是短暂的，而对换操作的频率却较高，故
对对换区进行管理的主要目标是提高进程换入和换出的速度，然后才是提高文件存储空间的
利用率。因此，对对换区的管理应采取连续分配存储管理方式，很少需要考虑外存中的碎片  
问题。

--- Page 166 ---
145
第
5章 
存储器管理
2．对换区空闲盘块管理中的数据结构
为了实现对对换区中的空闲盘块的管理，在系统中应配置相应的数据结构，用于记录外
存对换区中的空闲盘块的使用情况。其数据结构的形式，与内存在动态分区分配方式中所用的
数据结构相似，即同样可以用空闲分区表或空闲分区链。空闲分区表的每个表目中均应包含两
项，即对换区的起始地址及其大小，它们分别用盘块号和盘块数来表示。
3．对换区的分配与回收
由于对换区的分配采用的是连续分配存储管理方式，因而对换区的分配与回收，与采用动
态分区方式时的内存分配与回收方法类似。其分配算法可以是首次适应算法、循环首次适应算
法或最佳适应算法等。具体的分配与回收操作也与动态分区方式相同，故不再赘述。
5.3.3 进程的换出与换入
当内核因执行某操作而发现空间不足时，例如，当一进程由于创建子进程而需要更多的内
存空间，但又无足够的内存空间供它使用时，便会调用（或唤醒）对换进程，它的主要任务是
实现进程的换出与换入。图5-6所示为对换示意。
OS
用户空间
进程P1
进程P2
① 换出
② 换入
内存空间
对换空间
图5-6  对换示意
1．进程的换出
对换进程在实现进程换出时，是将内存中的某些进程调出至对换区，以便腾出内存空间。
换出过程可分为以下两步。
（1）选择被换出的进程。对换进程在选择被换出的进程时，将检查所有驻留在内存中的进
程，首先选择处于阻塞状态或睡眠状态的进程，当有多个这样的进程时，应当选择优先级最低
的进程作为换出进程。在有的系统中，为了防止低优先级进程在被调入内存后很快又被换出，
还须考虑进程在内存中的驻留时长。如果系统中已无阻塞进程，而现在的内存空间仍不足以满
足需要，则选择优先级最低的就绪进程换出。
（2）换出进程。应当注意，在选择好换出的进程后，在对进程进行换出时，只能换出非共
享的程序和数据段，而对于那些共享的程序和数据段，只要还有进程需要它，就不能被换出。
在进行换出时，应先申请对换区，若申请成功，就启动磁盘，将该进程的程序和数据传送到磁
盘的对换区上。若传送过程未出现错误，则可回收该进程所占用的内存空间，并对该进程的
PCB和内存分配表等数据结构做相应的修改。若此时内存中还有可换出的进程，则继续执行换

--- Page 167 ---
146
计算机操作系统 （慕课版）
出操作，直到内存中再无阻塞进程为止。
2．进程的换入
对换进程将定时执行换入操作，它首先会查看PCB集合中所有进程的状态，从中找出处于
“就绪”状态但已被换出的进程。当有许多这样的进程时，它将选择其中已换出到磁盘上且时
间最久（必须大于规定时间，如2s）的进程作为换入进程，并为它申请内存空间。如果申请成
功，则可直接将进程从外存换入内存；如果申请失败，则须先将内存中的某些进程换出，腾出
足够的内存空间后，再将进程换入。
在对换进程成功地换入一个进程后，若还有可换入的进程，则继续执行换入操作，将其余
处于“就绪且换出”状态的进程陆续换入，直到内存中再无处于“就绪且换出”状态的进程为
止，或者已无足够的内存来支持换入进程，此时对换进程才会停止换入操作。
由于要交换一个进程需要很多时间，因此，对于提高处理机的利用率而言，它并不是一个
非常有效的解决方法。目前用得较多的对换方案是，在处理机正常运行时并不启动对换程序，
但如果发现有许多进程在运行时经常发生缺页，且显现出内存紧张的情况，则启动对换程序，
将一部分进程调至外存。如果发现所有进程的缺页率都已明显减少，而系统吞吐量已下降时，
则可暂停运行对换程序。
如何制定策略来提高对换的效率？
思考题
5.3.4 覆盖
为了能让进程的大小比它所分配到的内存空间大，可以使用覆盖技术。覆盖的思想是，在
任何时候只在内存中保留所需的指令和数据；当需要其他指令和数据时，它们就会被装入刚刚
不需要的指令和数据所占用的内存空间。
覆盖在具体实现时是指，在程序执行过程中，程序的不同部分相互替换。详细来说就是，
只在内存中保留那些在任何时候都需要的指令和数据，程序其余的部分（即那些不会同时执行
的程序段）则根据它们自身的逻辑结构，使它们共享同一块内存区域。
覆盖技术要求程序各模块之间有明确的调用结构。这个工作是程序员完成的，因为只有程
序员最了解自己的程序。程序员声明覆盖结构后，OS只是完成覆盖的过程。
举例：某程序由符号表（20KB）、公共例程（30KB）、分枝1（70KB）和分枝2（80KB）
组成。为了将所有代码一次性装入内存，需要200KB内存空间，如果只有150KB，那么就不能将
该程序全部装入。不过，由于分枝1 和分枝2不会同时执行，不必同时位于内存，因此可以使用
覆盖技术，但须增加覆盖驱动程序（10KB）。图5-7所示是覆盖举例（程序驻留内存的情况），
从图中可以看出，内存中驻留了符号表、通用例程和覆盖驱动程序等需要常驻内存的部分，而
程序的两个分枝（分枝1和分枝2）则共享一块存储区域（90KB）。设计时须注意这块共享内存
的大小，分枝1须占用70KB，分枝2须占用80KB，这块内存要能够分时容纳这两段代码，其空间
大小应该选择两者中较大的容量，即至少应为80KB。
覆盖技术的优点：不需要OS的特别支持。用户通过简单的文件结构将文件读入内存，并执
行所读指令，即可实现完全覆盖。OS只不过会注意到I/O操作比平常多了一些而已。

--- Page 168 ---
147
第
5章 
存储器管理
70KB 80KB
10KB
30KB
20KB
分枝1 分枝2
符号表
通用例程
覆盖驱动程序
图5-7  覆盖示例
覆盖技术的缺点：覆盖结构的程序设计很复杂，需要程序员对程序结构、数据结构有完全
的了解。由于程序比较大时才需要使用覆盖，小程序无须使用覆盖，因此获得对程序足够且完
整的理解可能比较困难。由于这些原因，覆盖的使用通常局限于微处理机和只有有限物理内存
且缺乏先进硬件支持的其他系统。
5.4 连续分配存储管理方式
为了能将用户程序装入内存，则必须为它分配一定大小的内存空间。连续分
配存储管理方式（简称连续分配方式），是最早出现的一种存储器分配方式，曾
被广泛应用于20世纪60— 80年代的OS中。该分配方式为一个用户程序分配一个连
续的内存空间，即程序中代码或数据的逻辑地址相邻，体现在内存空间中为分配的物理地址相邻。
连续分配方式可分为4类：单一连续分配、固定分区分配、动态分区分配、动态重定位分区分配。
5.4.1 单一连续分配
在单道程序环境下，早期的存储器管理方式是把内存分为系统区和用户区两部分。系统区
仅供OS使用，它通常放在内存的低址部分。而在用户区内存中，仅装有一道用户程序，即整个
内存的用户区由该程序独占。这样的存储器分配方式被称为单一连续分配。
虽然在早期的单用户单任务OS 中，有不少都配置了存储器保护机构，用于防止用户程序对
OS的破坏，但在20世纪80年代所产生的几种常见的单用户OS（如CP/M、 MS-DOS及 RT11等）
中，并未采取存储器保护措施。这是因为，一方面可以节省硬件资源，另一方面在单用户环境
下，机器由一个用户独占，不可能存在受其他用户干扰的问题，因此这是可行的。即使出现破
坏行为，也只会是用户程序自己破坏OS，其后果并不严重，只会影响该用户程序的运行，且OS
也很容易通过系统的再启动而重新装入内存。
5.4.2 固定分区分配
20世纪60年代出现的多道程序系统，如IBM 公司开发的MFT系统，为了能在内存中装入
多道程序，且使这些程序之间不会发生相互干扰，于是将整个用户空间划分为若干个固定大小
的区域（称为分区），并在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的
一种可运行多道程序的分区式存储管理方式。如果在内存中有4 个用户分区，便允许4 个程序并
发运行。当有1 个空闲分区时，便可从外存的后备作业队列中选择1 个适当大小的作业装入该分
区。当该作业结束时，又可从后备作业队列中选择另一作业装入该分区。
连续分配存储
管理方式


--- Page 169 ---
148
计算机操作系统 （慕课版）
1．分区划分
可用下列两种方法将内存的用户空间划分为若干个固定大小的分区。
（1）分区大小相等，即所有的内存分区大小相等。该方法的缺点是缺乏灵活性，即当程序
太小时，会造成内存空间的浪费；当程序太大时，一个分区又装不下该程序，致使该程序无法
运行。尽管如此，对于利用一台计算机同时控制多个相同对象的场合，因为这些对象所需的内
存空间大小往往相同，这种划分方法又比较方便和实用，所以其被广泛采用。例如，炉温群控
系统，就是利用一台计算机去控制多台相同的冶炼炉的。
（2）分区大小不等 。为了增加存储器分配的灵活性，还可将存储器划分为若干个大小不
等的分区。最好能对常在该系统中运行的作业大小进行调查，根据用户的需要来划分。通常，
可把内存划分成含有多个小分区、适量的中等分区及少量的大分区。这样，便可根据程序的大
小，为之分配适当的分区。
2．内存分配
为了便于内存分配，通常将分区按其大小进行排队，并为之建立一张固定分区使用表，其
中包括每个分区的起始地址、大小及状态（是否已分配），如图 5-8所示。当有一用户程序要装
入时，由内存分配程序依据用户程序的大小检索该表，从中找出一个能满足要求的、尚未分配
的分区，将之分配给该程序，然后将该表项中的状态置为“已分配”。若未找到大小足够的分
区，则拒绝为该用户程序分配内存。
分区号
1
2
3
4
12
32
64
128
20
已分配
已分配
已分配
已分配
32
64
128
分区大小（KB）
分区起始地址（K）
分区起始地址（K）
20
作业A
作业B
作业C
32
64
128
256
…
…
分区状态
OS
（a）分区使用表
（b）存储空间分配情况
图5-8  固定分区使用表
固定分区分配，是最早出现的、可用于多道程序系统的存储管理方式，由于每个分区的大
小固定，必然会造成存储空间的浪费，因而现在已很少将它用于通用的OS中。但在某些用于控
制多个相同对象的控制系统中，由于每个对象的控制程序都是事先编好的，大小相同，其所需
的数据也是一定的，故仍采用固定分区存储管理方式。
5.4.3 动态分区分配
动态分区分配属于可变分区分配，它是根据进程的实际需要，动态地为之分配内存空间
的。在实现动态分区分配时，将涉及动态分区分配中所用的数据结构、动态分区分配算法以及
分区的分配与回收操作这3方面的问题。
1．动态分区分配中的数据结构
为了实现动态分区分配，系统中必须配置相应的数据结构，用以描述空闲分区和已分配分
区的情况，进而为分配提供依据。常用的数据结构有以下两种形式。 ①空闲分区表。在系统中
设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括

--- Page 170 ---
149
第
5章 
存储器管理
分区号、分区大小和分区起始地址等数据项，如图5-9所示。 ②空闲分区链 。为了实现对空闲
分区的分配和链接，在每个分区的头部，设置一些用于控制分区分配的信息和链接各分区所用
的前向指针，在每个分区的尾部则设置一个后向指针。通过前、后向指针可将所有的空闲分区
链接成一个双向链，如图5-10所示。为了检索方便，在分区尾部重复设置状态位和分区大小表
目。当分区被分配出去以后，把状态位由“0”改为“1”，此时，前、后向指针已无意义。
分区号
1
2
3
4
…
…
…
…
50
32
70
60
85
空闲
空闲
空闲
空闲
155
275
532
分区大小（KB）
分区起始地址（K）
分区状态
图5-9  空闲分区表
前向指针
N
+
2
N个字节可用
0 0
N
+
2
后向指针
图5-10  空闲分区链
2．动态分区分配算法
为了把一个新作业装入内存，须按照一定的分配算法从空闲分区表或空闲分区链中选出一
分区分配给该作业。由于内存分配算法对系统性能有很大的影响，因此人们对它进行了广泛且
深入的研究，并产生了许多动态分区分配算法。常用的分区分配算法按分区检索方式可分为顺
序分配算法和索引分配算法。
（1）基于顺序搜索的动态分区分配算法（顺序分配算法）。
为了实现动态分区分配，通常会将系统中的空闲分区链接成一个链。所谓顺序搜索，是指
依次搜索空闲分区链上的空闲分区，以寻找一个大小能满足要求的分区。基于顺序搜索的动态
分区分配算法有4种：首次适应算法、循环首次适应算法、最佳适应算法和最坏适应算法。下面
分别对它们进行介绍。
① 首次适应算法。
以空闲分区链为例，来说明采用首次适应（first fit， FF）算法时的分配情况。首次适应算
法要求空闲分区链以地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一
个大小能满足要求的空闲分区为止。然后按照作业的大小，从该分区中划出一块内存空间分配
给请求者，余下的空闲分区仍留在空闲链中。若从链首直至链尾都找不到一个能满足要求的分
区，则表明系统中已没有足够大的内存分配给该进程，内存分配失败，返回。
首次适应算法倾向于优先利用内存中低址部分的空闲分区，从而保留了高址部分的大空闲
分区。这为以后到达的大作业分配大的内存空间创造了条件。其缺点是低址部分不断被划分，
进而会留下许多难以利用的、很小的空闲分区，称之为碎片；此外，每次查找又都是从低址部

--- Page 171 ---
150
计算机操作系统 （慕课版）
分开始的，这无疑又会增加查找可用空闲分区时的开销。
② 循环首次适应算法。
为了避免低址部分留下许多很小的空闲分区，以及减少查找可用空闲分区时的开销，提出
了循环首次适应（next fit， NF）算法。循环首次适应算法在为进程分配内存空间时，不再是每
次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个
能满足要求的空闲分区，然后从中划出一块与请求的大小相等的内存空间分配给作业。为实现
循环首次适应算法，应设置一个起始查寻指针，用于指示下一次起始查寻的空闲分区，并采用
循环查找方式，即如果最后一个（链尾）空闲分区的大小仍不能满足要求，则应返回第一个空
闲分区并比较其大小是否满足要求。找到满足要求的空闲分区后，应调整起始查寻指针。循环
首次适应算法能使内存中的空闲分区分布得更均匀，从而减少了查找空闲分区时的开销，但这
样会使得大的空闲分区较缺乏。
③ 最佳适应算法。
所谓“最佳”，是指每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配
给作业，避免“大材小用”。为了加速寻找，最佳适应（best fit，BF）算法要求将所有的空闲分
区按其容量以从小到大的顺序，排成一个空闲分区链。这样，第一次找到的、能满足要求的空闲
分区，必然是最佳的。孤立地看，最佳适应算法似乎是最佳的，然而在宏观上却不一定。因为每
次分配后所切割下来的剩余部分总是最小的，这样，在存储器中会留下许多难以利用的碎片。
④ 最坏适应算法。
由于最坏适应（worst fit， WF）算法选择空闲分区的策略正好与最佳适应算法相反：它在
扫描整个空闲分区表或空闲分区链时，总是会挑选一个最大的空闲区，从中分割一部分存储空
间给作业使用，以至于存储器中会缺乏大的空闲分区，故把它称为最坏适应算法。实际上，这
样的算法未必是最坏的。它的优点是可使剩下的空闲区不至于太小，产生碎片的概率最小，这
对中、小作业有利，同时最坏适应算法查找效率很高。最坏适应算法要求将所有的空闲分区，
按容量以从大到小的顺序排成一个空闲分区链，查找时，只看第一个分区能否满足作业要求。
（2）基于索引搜索的动态分区分配算法（索引分配算法）。
基于顺序搜索的动态分区分配算法，比较适用于不太大的系统。当系统很大时，系统中的内
存分区可能会很多，相应的空闲分区链就可能会很长，这时采用基于顺序搜索的动态分区分配算
法可能会很慢。为了提高搜索空闲分区的速度，在大、中型系统中，往往会采用基于索引搜索的
动态分区分配算法。目前常用的基于索引搜索的动态分区分配算法有快速适应（quick fit）算法、
伙伴系统（duddy system）和哈希算法。这些算法的基本思想都是将空闲分区根据分区大小进行分
类，对于每类（具有相同大小的）空闲分区，单独设立一个空闲分区链表，并设置一张索引表来
管理这些空闲分区链表。在为进程分配空间时，在索引表中查找所需空间大小对应的表项，并从
中得到对应的空闲分区链表表头指针，从而实现通过查找得到一个空闲分区。
① 快速适应算法。
空闲分区的分类是根据进程常用的空间大小进行划分的。快速适应算法在搜索可分配的
空闲分区时分为两步：第一步是根据进程的长度，在索引表中找到能容纳它的最小空闲分区链
表；第二步是从链表中取下第一块进行分配。该算法在进行空闲分区分配时，不会对任何分区
产生分割，因此能保留大的分区，满足对大空间的需求，也不会产生内部碎片。优点是查找效
率高，主要缺点在于为了有效合并分区，分区归还内存时的算法较复杂，系统开销较大。此
外，由于该算法在分配空闲分区时以进程为单位，一个分区只属于一个进程，因此在为进程所
分配的一个分区中，或多或少地存在一定的浪费。这是典型的以空间换时间的做法。

--- Page 172 ---
151
第
5章 
存储器管理
② 伙伴系统。
伙伴系统规定，无论已分配分区还是空闲分区，其大小均为2 的k次幂，k为正整数。对于具
有相同大小的所有空闲分区，为它们单独设立一个空闲分区双向链表。当需要为进程分配一个
长度为n的存储空间时，首先计算一个 i值，使2
i-1
＜n≤2
i
，然后在空闲分区大小为2
i
的空闲分区
链表中查找。若能找到，则把该空闲分区分配给进程。否则，表明大小为2
i
的空闲分区已经耗
尽，须在分区大小为2
i+1
的空闲分区链表中接着查找。若存在大小为2
i+1
的一个空闲分区，则把该
空闲分区分为相等的两个分区，这两个分区称为“一对伙伴”，其中的一个分区用于分配，而
把另一个分区加入大小为2
i
的空闲分区链表中。若不存在，则需要继续查找，如此循环直至找到
为止。回收分区时也可能要进行多次合并。
③ 哈希算法。
利用哈希快速查找的优点，以及空闲分区在可利用空闲分区链表中的分布规律，建立哈希
函数，构造一张以空闲分区大小为关键字的哈希表，该表的每个表项均记录了一个对应的空闲
分区链表表头指针。当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算得到
哈希表中的位置，从中得到相应的空闲分区链表，最终实现最佳分配策略。
3．分区的分配与回收操作
在动态分区存储管理方式中，主要的操作是分配内存和回收内存。
（1）分配内存。
分配内存是指系统利用某种分配算法，从空闲分区链表中找到所需大小的分区。设请求的分区
大小为u.size，表中每个空闲分区的大小为m.size。若m.size-u.size≤size（size是事先规定的不再切割
的剩余分区的大小），则说明多余部分太小，可不再切割，并将整个分区分配给请求者。否则（即
多余部分超过size），从该分区中按请求的大小，划分出一块内存空间并分配出去，余下的部分仍留
在空闲分区链表中；然后，将分配区的起始地址返回给调用者。图5-11所示为内存分配流程。
从头开始查表
返回
将该分区从链中移出
继续检索下一个表项
返回是
是
是
否
否
否
从该分区中划分出
u.size大小的分区
    将该分区分配给请求者，
并修改有关的数据结构
是否检索完毕？
m.size＞a.size ?
m.size-u.size≤size ?
图5-11  内存分配流程

--- Page 173 ---
152
计算机操作系统 （慕课版）
（2）回收内存。
当进程运行完毕而须释放内存时，系统会根据回收区的起始地址，从空闲分区链表中找到
相应的插入点，此时可能会出现以下四种情况之一。
① 回收区与插入点的前一个空闲分区F1相邻接，如图5-12（a）所示。此时应将回收区与插
入点的前一分区合并，不必为回收分区分配新表项，而只须修改其前一分区F1的大小。
… … …
… ……
F1
F2 F2
F1
回收区
（a）情况1 （b）情况2 （c）情况3
回收区 回收区
图5-12  内存回收时的情况
② 回收区与插入点的后一个空闲分区F2相邻接，如图5-12（b）所示。此时可将两分区合并，
形成新的空闲分区，但须将回收区的起始地址作为新空闲区的起始地址，分区大小为两者之和。
③ 回收区同时与插入点的前、后两个分区邻接，如图5-12（ c）所示。此时将三个分区合
并，使用F1的表项和起始地址，取消F2的表项，分区大小为三者之和。
④ 回收区既不与F1邻接，也不与F2邻接。这时应为回收区单独建立一个新表项，填写回收区的
起始地址和大小，并根据其起始地址将其插入空闲分区链表中的适当位置。图5-13所示为内存回收
流程。
是
是
是
否
否
否否
是
回收区
m.free
顺序检索可用资源表
直至找到某表目的
m.addr＞aa或m.size=0
不是第一个表目且
与前一个可用分区相邻？
把所释放的可用分区
与前一分区合并
与后一可用
  分区相邻？
与后一可用分区合并
将该表目以上的
所有表目下移一格
与后一个可用分区相邻
   且不为空表目？
所释放的可用分区与
后一可用分区合并
返回
将该表目以上的所有表目
上移一格，并插入
新释放的可用分区表目
所释放的可用
分区的size=0?
图5-13  内存回收流程
5.4.4 动态重定位分区分配
1．紧凑
连续分配方式的一个重要特点是，一个系统或用户程序必须被装入一个连续的内存空间

--- Page 174 ---
153
第
5章 
存储器管理
中。当一台计算机运行了一段时间后，它的内存空间将会被分割成许多小分区，而缺乏大的
空闲空间。即使这些分散的许多小分区的容量总和大于要装入的程序，但由于这些分区不相邻
接，也无法把该用户程序装入内存。例如，图 5-14（a）中给出的内存中现有四个互不邻接的小
分区，它们的容量分别为10KB、 30KB、14KB和26KB，总容量为80KB。假设现在有一作业到
达，要求获得40KB的内存空间，由于必须为它分配一连续空间，故此作业无法装入。这种不能
被利用的小分区，就是前面已提及的“碎片”，也称为“零头”。
OS
用户程序1
10KB
用户程序3
30KB
用户程序6
14KB
用户程序9
26KB
（a）紧凑前
（b）紧凑后
OS
用户程序1
用户程序3
用户程序6
用户程序9
80KB
图5-14  紧凑示意
在上述例子中，若想把大作业装入内存，可采用的一种方法是：将内存中的所有作业进行
移动，使它们全都相邻接。这样，即可把原来分散的多个小分区拼接成一个大分区，这时就可
以把一个作业装入该分区了。这种通过移动内存中作业的位置，把原来分散的多个小分区拼接
成一个大分区的方法，称为“紧凑”，亦称为“紧缩”或“拼接”，如图5-14（b）所示。
虽然“紧凑”能获得大的空闲空间，但也带来了新的问题，即经过紧凑后的用户程序在内
存中的位置发生了变化，此时若不对程序和数据的地址加以修改（变换），则程序必将无法执
行。为此，在每次“紧凑”后，都必须对移动后的程序或数据进行重定位。为了提高内存的利
用率，系统在运行过程中经常需要进行“紧凑”，每“紧凑”一次，就要对移动了的程序或数
据的地址进行修改，这不仅是一件相当麻烦的事情，而且还会大大影响系统的效率。下面要介
绍的动态重定位方法，可以很好地解决此问题。
2．动态重定位
在5.2.2小节中所介绍的动态运行时装入方式中，作业装入内存后的所有地址仍然是相对地
址，而将相对地址变换为物理地址的工作，被推迟到程序指令要真正执行时进行。为使地址的
变换不会影响指令的执行速度，必须有硬件地址变换机构的支持，即须在系统中增设一个重定
位寄存器，用它来存放程序（数据）在内存中的起始地址。程序在执行时，真正访问的内存地
址是相对地址与重定位寄存器中的地址相加而形成的。图5-15所示为动态重定位的实现原理。
地址变换过程是在程序执行期间随着对每条指令或数据的访问自动进行的，故称之为动态重定
位。当系统对内存进行了“紧凑”，而使若干程序从内存的某处移至另一处时，无须对程序做
任何修改，只要用该程序在内存中的新起始地址去置换原来的起始地址即可。
3．动态重定位分区分配算法
动态重定位分区分配算法与动态分区分配算法基本相同，差别仅在于：在这种分配算法中
增加了“紧凑”功能。通常，当该算法不能找到一个足够大的空闲分区以满足用户需求时，如
果所有小的空闲分区的容量总和大于或等于用户的要求，则此时便须对内存进行“紧凑”，并
将“紧凑”后所得的大空闲分区分配给用户。如果所有小的空闲分区的容量总和仍小于用户的
要求，则返回分配失败信息。图5-16所示为动态重定位分区分配算法流程图。

--- Page 175 ---
154
计算机操作系统 （慕课版）
+
0
100
2 500
2 500
10 000
10 000
10 100
12 500
15 000
Load 1,2 500 Load 1,2 500
365 365
作业J
5 000
相对地址
处理机一侧 存储器一侧 内存
重定位寄存器
图5-15  动态重定位的实现原理
请求分配
u.size分区
无法分配
返回
否
否
是
是
检索空闲分区链表
是否找到大于u.size
的可用分区？
空闲分区
  总和≥u.size？
进行“紧凑”以形成
连续空闲分区
进行“紧凑”以形成
连续空闲分区
返回分区号
与起始地址
按动态分区分配算法
进行分配
修改有关的数据结构
图5-16  动态重定位分区分配算法流程图
5.5 分页存储管理方式
连续分配方式会形成许多“碎片”，虽然可以通过“紧凑”方法将许多碎片拼接成可用的
大块空间，但须为之付出很大的开销。如果允许将一个进程直接分散地装入许多不相邻接的分
区中，则可充分地利用内存空间而无须再进行“紧凑”。基于这一思想而产生了离散分配存储
管理方式（简称离散分配方式）。根据在离散分配时所分配地址空间的基本单位的不同，可将
离散分配方式分为以下3种。
（1）分页存储管理方式 。在该方式中，将用户程序的地址空间分为若干个固定大小的区
域，称之为“页”或“页面”。典型的页面大小为1KB、2KB、4KB等。相应地，也将内存空间
分为若干个物理块或页框（frame），页和块的大小相同。这样就可以将用户程序的任一页放入
任一物理块中，进而实现离散分配。
（2）分段存储管理方式 。这也是为了满足用户要求而形成的一种离散分配方式。它把用
户程序的地址空间分为若干个大小不同的段，每段可定义一组相对完整的信息。在存储器分配
时，以段为单位，这些段在内存中可以不相邻接，因此也同样实现了离散分配。
分页存储管理
方式


--- Page 176 ---
155
第
5章 
存储器管理
（3）段页式存储管理方式。这是分页和分段两种存储管理方式相结合的产物，它同时具有
两者的优点，是目前应用较广泛的一种存储管理方式。
本节主要介绍分页存储管理方式，另外两种方式将在5.6节中进行介绍。
5.5.1 分页存储管理的基本方法
1．页面和物理块
（1）页面 。分页存储管理将进程的地址空间分成若干个页，并为每页加以编号，从0 开
始，如第0页、第1页等。相应地，也把内存空间分成若干个块，同样也为它们加以编号，如0#
块、1#块等。在为进程分配内存时，以块为单位，将进程中的若干个页分别装入多个可以不相
邻接的物理块中。由于进程的最后一页经常装不满一块，进而形成了不可利用的碎片，称之为
“页内碎片”或“内碎片”。
（2）页面大小 。在分页系统中，若选择过小的页面大小，则虽然可以减小内部碎片，起
到减少内部碎片总空间的作用，有利于内存利用率的提高，但是会造成每个进程占用较多的页
面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换入/ 换出的效率。然而，
如果选择过大的页面大小，则虽然可以减少页表的长度，以及提高页面换入/ 换出的效率，但是
又会使页内碎片增大。因此，页面的大小应选择得适中，且页面大小应是2 的幂，通常为1KB、
2KB、4KB、8KB。
2．地址结构
分页地址中的地址结构如图5-17所示。
31 12 11 0
页号P 位移量W
图5-17  分页地址中的地址结构
该结构包含两部分内容：前一部分为页号 P，后一部分为位移量W，即页内地址。图5-17中
的地址长度为32位，其中0～11位为页内地址，即每页的大小为4KB； 12～31位为页号，地址空
间最多允许有1M页。
对某特定机器，其地址结构是一定的。若给定一个逻辑地址空间中的地址为A，页面大小为
L，则页号P和页内地址d可按下式求得：
P = INT
 ，
d = [A] MOD L，
其中，INT 是向下取整函数，MOD 是取余函数。 例如， 其系统的页面大小L 为 1KB，设A=2 170B，
则由上式可以求得 P =2，d =122。
3．页表
在分页系统中，允许将进程的各个页离散地存储在内存的任一物理块中，以保证进程仍
然能够正确地运行，即能在内存中找到每个页面所对应的物理块。为此，系统又为每个进程建
立了一张页面映像表，简称页表。在进程地址空间内的所有页（0 ～n），依次在页表中有一页
表项，其中记录了相应页在内存中对应的物理块号，如图5-18所示的中间部分。在配置了页表
后，当进程在执行时，通过查找该表即可找到每页在内存中的物理块号。由此可见，页表的作
用是实现从页号到物理块号的地址映射。

--- Page 177 ---
156
计算机操作系统 （慕课版）
用户程序 页号 物理块号 内存
0页
1页
0
1
2
3
4
5
6
7
8
9
10
2页
3页
4页
5页
n页
…
0
1
2
3
4
2
3
6
8
9
5…
…
图5-18  页表的作用
即使在简单的分页系统中，也常会在页表的表项中设置一个存取控制字段，用于对该存储
块中的内容加以保护。当存取控制字段仅有一位时，可用于规定该存储块中的内容是允许读/
写，还是只读；若存取控制字段为二位，则可用于规定读/ 写、只读和只执行等存取方式。如果
有一进程试图去写一个只允许读的存储块，则会引起OS的一次中断。如果要利用分页系统去实
现虚拟存储器，则还须增设一个数据项，这一点将在第6章后面做详细介绍。
不同页的大小对分页系统性能的影响是什么？
思考题
5.5.2 地址变换机构
为了能将用户地址空间中的逻辑地址变换为内存空间中的物理地址，在系统中必须设置
地址变换机构。该机构的基本任务是实现从逻辑地址到物理地址的变换。由于页大小等于块大
小，因此页内地址和块内地址是一一对应的，例如，页面大小是1KB的页内地址是0～1 023，其
相应的物理块内的地址也是0～1 023，无须再进行变换。由此可知，地址变换机构的任务实际上
只是将逻辑地址中的页号变换为内存中的物理块号。又因为页表的作用就是用于实现从页号到
物理块号的变换，因此，地址变换是借助页表来完成的。
1．基本的地址变换机构
进程在运行期间，需要对程序和数据的地址进行变换，即将用户地址空间中的逻辑地址变换
为内存空间中的物理地址，由于它执行的频率非常高，每条指令的地址都需要进行变换，因此需要
利用硬件来实现。页表功能是由一组专门的寄存器来实现的，一个页表项用一个寄存器。由于寄存
器具有较高的访问速度，因而有利于提高地址变换的速度；但由于寄存器成本较高，且大多数现代
计算机的页表又可能很大，这使页表项的总数可达几千甚至几十万，显然这些页表项不可能都用寄
存器来实现，因此，页表大多驻留在内存中。在系统中只设置一个页表寄存器（page-table register，
PTR），在其中存放页表（在内存中）的起始地址和页表长度。平时，在进程未执行时，页表的起
始地址和页表长度存放在本进程的PCB中。当调度程序调度到某进程时，才将这两个数据装入页表
寄存器中。因此，在单处理机环境下，虽然系统中可以运行多个进程，但只需要一个页表寄存器。
当进程要访问某个逻辑地址中的数据时，分页地址变换机构会自动将有效地址（相对地
址）分为页号和页内地址两部分，再以页号为索引去检索页表。查找操作由硬件执行。在执
行检索之前，先将页号与页表长度进行比较，如果页号大于或等于页表长度，则表示本次所访
问的地址已超越进程的地址空间。于是，这一错误将被系统发现，并产生一个地址越界中断。

--- Page 178 ---
157
第
5章 
存储器管理
若未出现越界错误，则将页表
起始地址与“页号和页表项长
度的乘积”相加，便可得到该
表项在页表中的位置，于是可
以从中得到该页的物理块号，
然后将之装入物理地址寄存
器中。与此同时，再将有效地
址寄存器中的页内地址送入物
理地址寄存器的块内地址字段
中。这样便完成了从逻辑地址
到物理地址的变换。图5-19所示
为分页系统的地址变换机构。
2．具有快表的地址变换机构
页表是存放在内存中的，这使CPU在每次存取一个数据时都要访问内存两次。第一次是
访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量拼接，以形成物理地
址。第二次访问是从第一次所得地址中获得所需数据（或向此地址中写入数据）。因此，采用
这种方式将使计算机的处理速度降低近50%。由此可见，以此高昂代价来换取存储器空间利用
率的提高，是得不偿失的。
为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的高速缓冲寄存
器，称为“联想寄存器”（associative memory）或“快表”，在IBM系统中又将其取名为地址
变换高速缓存（translation look aside buffer， TLB），用以存放当前访问的那些页表项。此时
的地址变换过程是：在CPU给出有效地址后，由地址变换机构自动地将页号送入高速缓冲寄存
器，并将此页号与高速缓存寄存器中的所有页号进行比较，若其中有与此页号相匹配的页号，
则表示所要访问的页表项在快表中。于是，可直接从快表中读出该页所对应的物理块号 b，并将
其送到物理地址寄存器中。若在快表中未找到对应的页表项，则还须再访问内存中的页表，直
至找到后，把从页表项中读出的物理块号送到地址寄存器；同时，再将此页表项存入快表的一
个寄存器单元中，亦即重新修改快表。但如果快表已满，则OS必须找到一个老的且已被认为是
不再需要的页表项，并将它换出。图5-20所示为具有快表的地址变换机构。
+
＞
页表寄存器
页号 块号 页号 块号
快表
TLB命中
TLB未命中
输入寄存器
物理地址
页表
b
b
b d
0
1
2
3
逻辑地址
越界中断页表起始地址 页表长度 页号（3） 页内地址
图5-20  具有快表的地址变换机构
+
＞
页表寄存器
页号 块号
物理地址
页表
b
10
1
2
3
逻辑地址
越界中断
页表起始地址 页表长度 页号（3） 页内地址
图5-19  分页系统的地址变换机构

--- Page 179 ---
158
计算机操作系统 （慕课版）
由于成本的关系，快表不可能做得很大，通常只存放16～512个页表项，这对中、小型作业
来说，已有可能把全部页表项放在快表中了；但对于大型作业，则只能将其一部分页表项放入
其中。由于对程序和数据的访问往往带有局限性，因此据统计，从快表中能找到所需页表项的
概率可达90%以上。这样，由增加了地址变换机构而造成的速度损失，可减少到10%以下，达到
了可接受的程度。
5.5.3 引入快表后的内存有效访问时间
从进程发出指定逻辑地址的访问请求，经地址变换，到在内存中找到对应的实际物理地址
单元并取出数据，这一过程所需要花费的总时间，称为内存的有效访问时间（effective access 
time，EAT）。假设访问一次内存的时间为 t，在基本分页存储管理方式中，有效访问时间等于
第一次访问内存时间（即查找页表对应的页表项所耗费的时间 t）与第二次访问内存时间（即将
页表项中的物理块号与页内地址拼接成实际物理地址所耗费的时间t）之和，如下式所示：
EAT = t + t = 2t。
在引入快表的分页存储管理方式中，通过快表查询，可以直接得到逻辑页所对应的物理块
号，由此拼接形成实际物理地址，减少了一次内存访问，缩短了进程访问内存的有效时间。但
是，由于快表的容量限制，不可能将一个进程的整个页表全部装入快表，因此在快表中查找所
需表项，存在着命中率的问题。所谓命中率，是指使用快表并在其中成功查找到所需页面的表
项的概率。这样，在引入快表的分页存储管理方式中，有效访问时间的计算公式为：
EAT =а×λ + (1-а)×(t + λ) + t
                 = 2 t +λ-t×а，
上式中，λ表示查找快表所需的时间，а表示命中率，t 表示访问一次内存所需要的时间。
可见，引入快表后的内存有效访问时间可分为查找到逻辑页对应的页表项的平均时间
（EAT-t）和对应实际物理地址的内存访问时间 t两部分。假设对快表的访问时间 λ为20ns，对内
存的访问时间t为100ns，则不同的命中率а与其对应的有效访问时间EAT如表5-1所示。
表5 -1 不同命中率与有效访问时间的对应关系
命中率а（%） 有效访问时间EAT（ns）
0 220
50 170
80 140
90 130
98 122
正是由于引入了快表，CPU访问数据所耗费的时间明显减少。
5.5.4 两级页表和多级页表
现代的大多数计算机系统，都支持非常大的逻辑地址空间（2
32
～2
64
）。在这样的环境下，
页表变得非常大，且要占用相当大的内存空间。例如，对于一个具有32位逻辑地址空间的分页
系统，规定页面大小为4KB，即2
12
B，则在每个进程页表中的页表项数可达1M之多。假设每个
页表项占用1B，则每个进程仅其页表就要占用1MB的内存空间，而且还要求是连续的。显然这
是不现实的，我们可以采用下述两个方法来解决这一问题：①对于页表所需的内存空间，可采
用离散分配方式，以解决难以找到一块连续的大内存空间的问题；②只将当前需要的部分页表

--- Page 180 ---
159
第
5章 
存储器管理
项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。
对于方法①中提及的页表离散分配的实现，有一个简单的方法是将页表划分成更小的块，
完成这种划分有多种方法，其中一种方法是使用两级或多级页表。
1．两级页表
针对难以找到连续的大内存空间来存放页表的问题，可利用将页表进行分页的方法，使每
个页面的大小与内存物理块的大小相同，并为它们编号，依次编为0
#
页、1
#
页……n
#
页，然后离
散地将各个页面分别存放在不同的物理块中。同样，也要为离散分配的页表再建立一张页表，
称之为外层页表（outer page table），在每个页表项中记录页表页面的物理块号。下面仍以32位
逻辑地址空间为例来说明。
当页面大小为4KB时（12位），若采用一级页表结构，则应具有20位的页号，即页表项应
有1M个；在采用两级页表（two-level page table）结构时，再对页表进行分页，假设每个页表项
占用4B，则每页中包含2
10
（即1 024）个页表项，最多允许有2
10
个页表分页；或者说，外层页表
中的外层页内地址P2为10位，外层页号P1也为10位。此时的逻辑地址结构如图5-21所示。
外层页号
P1
2231 21 12 11 0
P2 d
外层页内地址 页内地址
图5-21  两级页表的逻辑地址结构
从图5-21 中可以看出，在页表的每个表项中，存放的都是进程的某页在内存中的物理块
号，如第0页存放在1#物理块中，第1 页存放在4#物理块中。而在外层页表的每个页表项中，所
存放的是某页表分页的起始地址，如第0 页页表存放在1011#物理块中。我们可以利用外层页表
和页表这两级页表来实现进程从逻辑地址到内存中物理地址的变换。
为了方便实现地址变换，在地址变换机构中，同样需要增设一个外层页表寄存器，用于存放外层
页表的起始地址，并将逻辑地址中的外层页号作为外层页表的索引，从中找到指定页表分页的起始地
址，再将P2作为指定页表分页的索引，找到指定的页表项，其中含有该页在内存中的物理块号，用该
块号和页内地址d即可构成访问的内存物理地址。图5-22所示为具有两级页表的地址变换机构。
0# 0
1
0
1
2
1 023
1 023
…
1
4
6
0
1
2
3
4
5
6
7
114
115
1 468
…
…
114
1 468
115
……
……
0
1
1 023
…
…
1 011
1 078
1 742
内存空间
外部页表
第0页页表
第1页页表
第n页页表
1#
2#
n#
图5-22  具有两级页表的地址变换机构

--- Page 181 ---
160
计算机操作系统 （慕课版）
上述对页表施行离散分配的方法，虽然解决了对大页表无需大片连续存储空间的问题，但
并未解决用较少的内存空间去存放大页表的问题。换言之，只用离散分配空间的办法并未减少
页表所占用的内存空间。能够用较少的内存空间存放页表的唯一方法是，仅把当前需要的一批
页表项调入内存，以后再根据需要陆续调入。在采用两级页表结构的情况下，对于正在运行的
进程，必须将其外层页表调入内存，而对于页表则只须调入一页或几页。为了表征某页的页表
是否已经调入内存，还应在外层页表项中增设一个状态位 S，其值若为0，则表示该页表分页不
在内存中，否则表示该页表分页已调入内存。进程运行时，地址变换机构根据逻辑地址中的 P1
查找外层页表；若所找到的页表项中的状态位为0，则产生一个中断信号，并请求OS将该页表分
页调入内存。关于请求调页的详细情况，将在第6章（虚拟存储器）中进行介绍。
2．多级页表
对于32位的计算机，采用两级页表结构是合适的，但对于64位的计算机，采用两级页表是
否仍然合适，须做以下简单分析。
如果页面大小仍采用4KB，即2
12
B，每个页表项占用4B，那么还剩下52位，假定仍按物
理块的大小（2
12
位）来划分页表，则将余下的42位用于外层页号。此时在外层页表中可能有  
4 096GB个页表项，要占用16 384GB的连续内存空间。这样的结果显然是不能令人接受的。因  
此，必须采用多级页表将外层页表再进行分页，即将各分页离散地装入不相邻接的物理块中，
再利用第二级的外层页表来映射它们之间的关系。
对于64位的计算机，如果要求它能支持2
64
B（即1 844 744TB）规模的物理存储空间，则即
使是采用三级页表结构也难以办到，而在当前的实际应用中也无此必要。故在现在的64位计算
机中，把可直接寻址的存储器空间减少为48位长度（即2
48
）左右，这样便可利用三级页表结构
实现分页存储管理。
5.5.5 反置页表
1．反置页表的引入
在分页系统中，为每个进程配置了一张页表，进程逻辑地址空间中的每一页，在页表中
都对应有一个页表项。在现代计算机系统中，通常允许一个进程的逻辑地址空间非常大，因此
就需要有许多的页表项，它们会占用大量的内存空间。为了减少页表占用的内存空间，引入了
反置页表。一般页表的页表项是按页号进行排序的，页表项中的内容是物理块号。而反置页表
（inverted page table）则是为每个物理块设置一个页表项，并将它们按物理块的编号进行排序，
其中的内容则是页号和其所隶属进程的标识符。IBM公司推出的许多系统（如AS/400、 IBM 
RISC system、IBM RT等）中都采用了反置页表。
2．地址变换
在利用反置页表进行地址变换（见图5-23）时，会根据进程标识符 pid和页号 p检索反置页 
表。如果检索到了与之匹配的页表项，则该表项的序号 i便是该页所在的物理块号，可用该块号i
与页内地址d一起构成物理地址送往内存地址寄存器。若检索了整个反置页表都未找到匹配的页
表项，则表明此页尚未装入内存。对于不具有请求调页功能的存储器管理系统，此时则显示地
址出错。对于具有请求调页功能的存储器管理系统，此时则产生请求调页中断，系统将把此页
调入内存。

--- Page 182 ---
161
第
5章 
存储器管理
CPU
pid
pid p
p d i
i
d
逻辑地址
物理地址
物理内存
页表
检索
图5-23  利用反置页表进行地址变换
虽然反置页表可有效地减少页表占用的内存，例如，对于一个具有64MB的机器，如果页
面大小为4KB，那么反置页表只占用64KB内存。然而在该表中只包含了已经调入内存的页面，
而并不包含尚未调入内存的页面。因此，还必须为每个进程建立一个外部页表（external page 
table）。该页表与传统的页表一样，当所访问的页面在内存中时，并不需要访问外部页表，仅
当发现所需之页面不在内存中时，才会使用它。页表中包含了各个页在外存中的物理位置，通
过它可将所需之页面调入内存。
由于反置页表中为每个物理块都设置了一个页表项，当内存容量很大时，页表项的数目会
非常大。要利用进程标识符和页号去检索这样大的一张线性表是相当费时的。于是可利用哈希
算法来进行检索，这样可以很快地找到在反置页表中的相应页表项。不过在采用哈希算法时，
可能会出现所谓的“地址冲突”，即有多个逻辑地址被映射到同一个哈希表项上，必须妥善解
决这一问题。本书将在第8章中对这一问题做进一步的介绍。
5.6 分段存储管理方式
存储管理方式随着OS的发展也在不断发展。当OS由单道发展为多道时，存
储管理方式便由单一连续分配发展为固定分区分配。为了能更好地适应不同大小
的用户程序要求，存储管理方式又从固定分区分配发展到动态分区分配。为了能
更好地提高内存的利用率，其又从连续分配方式发展到了离散分配方式，如分页存储管理方式。如
果说，推动上述发展的主要动力都是为了直接或间接地实现提高内存利用率这一目的，那么，引入
分段存储管理方式的目的，则主要是为了满足用户（程序员）在编程和使用上的多方面要求，其中
有些要求是其他几种存储管理方式所难以满足的。因此，分段存储管理方式已成为当今所有存储管
理方式的基础，许多高级语言（如C语言等）编译的程序也都支持分段存储管理方式。
5.6.1 分段存储管理方式的引入
为什么要引入分段存储管理方式，可以从两个方面加以说明：一方面是由于通常的程序都
可分为若干段，如主程序段、子程序段A 、子程序段B、…、数据段以及栈段等，每个段大多是
一个相对独立的逻辑单位；另一方面，实现和满足信息共享、信息保护、动态链接以及信息的
动态增长等需要，也都是以段为基本单位的。更具体地说，分段存储管理方式更符合用户下列
所示的多方面需要。
分段存储管理
方式


--- Page 183 ---
162
计算机操作系统 （慕课版）
1．方便编程
通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都从0 开始编址，并且有自
己的名字和长度。因此，程序员们都迫切地需要访问的逻辑地址是由段名（段号）和段内偏移
量（段内地址）决定的，这不仅可以方便程序员编程，也可使程序非常直观、更具可读性。例
如，下述的两条指令便使用了段名和段内地址：
LOAD 1， [A] | 〈D〉 ；
STORE 1， [B]| 〈C〉 ；
其中， 前一条指令的含义是， 将分段A 中 D 单元内的值读入寄存器 1 中 ； 后一条指令的含义是，
将寄存器 1 中的内容存入分段 B 中 C 单元内。
2．信息共享
实现对程序和数据的共享，是以信息的逻辑单位为基础的，例如，共享某个过程、函数或
文件。分页系统中的“页”只是存放信息的物理单位（块），并无完整的逻辑意义，这样，一
个可被共享的过程往往可能需要占用数十个页面，这为实现共享增加了难度。如前所述，段可
以是信息的逻辑单位，因此，我们可以为该被共享过程建立一个独立的段，这就极大地简化了
共享的实现。为了实现段的共享，存储管理应能与用户程序分段的组织方式相适应，有关段共
享的具体实现方法将在5.6.3小节中进行介绍。
3．信息保护
信息保护同样是以信息的逻辑单位为基础的，而且经常以一个过程、函数或文件为基本单
位进行保护。例如，我们希望函数A仅允许进程执行，而不允读，更不允许写，那么，我们只须
在包含了函数A的这个段上标上只执行标志即可。但是在分页系统中，函数A 可能要占用若干个
页面，而且其中的第一个和最后一个页面还会装有其他程序段的数据，它们可能有着不同的保
护属性，如可以允许进程读/ 写，这样就很难对这些页面实施统一的保护。因此，分段存储管理
方式能更有效和方便地实现对信息的保护功能。
4．动态链接
在5.2.3小节中已对运行时动态链接做了介绍。为了提高内存的利用率，系统只将真正要运
行的目标程序装入内存，也就是说，动态链接在作业运行之前，并不是把所有的目标程序段都
链接起来。当程序要运行时，首先将主程序和它立即需要用到的目标程序装入内存，即启动运
行。而在程序运行过程中，当需要调用某个目标程序时，才将该段（目标程序）调入内存并进
行链接。可见，动态链接要求的是以目标程序（即段）为链接的基本单位，因此，分段存储管
理方式非常适用于动态链接。
5．动态增长
在实际应用中，往往存在着一些段，尤其是数据段，在它们的使用过程中，由于数据量的
不断增加，数据段会动态增长，相应地它所需要的存储空间也会动态增加。然而，对于数据段
究竟会增长到多大，事先又很难确切地知道。对此，很难采取预先多分配的方法解决问题。前
述的其他几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式则能较好
地解决这一问题。

--- Page 184 ---
163
第
5章 
存储器管理
5.6.2 分段系统的基本原理
1．分段
在分段存储管理方式中，作业的地址空间被划分为若干段，每个段都定义了一组逻辑信
息，如有主程序段MAIN、子程序段X 、数据段D 及栈段S等。每个段都有自己的名字。为了实
现简单起见，通常可用一个段号来代替段名，每个段都从0 开始编址，并采用一段连续的地址空
间。段的长度由相应的逻辑信息组的长度决定，因此各段的长度并不相等。整个作业的地址空
间，由于被分成了多个段，因此呈现出了二维特性，亦即，每个段既包含了一部分地址空间，
又标志了逻辑关系。段的逻辑地址由段号（段名）和段内地址所组成。
分段地址中的地址具有图5-24所示的结构。
31 16 15 0
段号 段内地址
图5-24  分段地址中的地址结构
在该地址结构中，允许一个作业最长有64K个段，每个段的最大长度为64KB。
分段方式已得到许多编译程序的支持，编译程序能自动地根据源程序的情况产生若干个
段。例如，Pascal编译程序可以为“全局变量、用于存储相应参数及返回地址的过程调用栈、
每个过程或函数的代码部分、每个过程或函数的局部变量等”分别建立各自的段。类似地，
FORTRAN编译程序可以为公共块（common block）建立单独的段，也可以为数组分配一个单独
的段。装入程序将装入所有的这些段，并为每个段赋予一个段号。
2．段表
在前面所介绍的动态分区分配方式中，系统会为整个进程分配一个连续的内存空间。而在
分段存储管理系统中，则是为每个分段分配一个连续的分区。进程中的各个段可以离散地装入
内存中不同的分区。为保证程序能正常运行，就必须能从物理内存中找出每个逻辑段所对应的
位置。为此，在系统中（类似于分页系统）须为每个进程建立一张段映射表，简称“段表”。
每个段在表中均占有一个表项，其中记录了该段在内存中的起始地址和段的长度，如图5-25所
示。段表可以存放在一组寄存器中，以提高地址变换速度，但更常见的方法是将段表存放在内
存中。在配置了段表后，执行中的进程可通过查找段表来找到每个段所对应的内存区。可见，
段表是用于实现从逻辑段到物理内存区映射的。
作业空间
（MAIN）=1
（MAIN）=0
30K
（X）=1
30K
（D）=2
15K
（S）=3
10K
内存空间
段表
段号
0 30KB
20KB
15KB
10KB
40K
80K
120K
150K
1
2
3
段长 起始
地址
（X）=1
（D）=2
（S）=3
0 0
40K
80K
120K
150K
30K
0
20K
0
15K
0
10K
图5-25  利用段表实现地址映射

--- Page 185 ---
164
计算机操作系统 （慕课版）
3．地址变换机构
为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放
段表起始地址和段表长度TL。在进行地址变换时，系统将逻辑地址中的段号 S与段表长度TL进
行比较。若 S＞TL，则表示段号太大，访问越界，于是产生越界中断信号。若未越界，则根据
段表起始地址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存中的起始地
址。然后，再检查段内地址d是否超过该段的段长SL。若超过，即 d＞SL，则同样产生越界中断
信号。若未越界，则将该段的起始地址 d与段内地址相加，即可得到要访问的内存物理地址。  
图5-26所示为分段系统的地址变换过程。
控制寄存器
段号
0 1KB
600B
500B
200B
6K
4K
8K
9 200
8 192
8K
8 292
8 692
1
2
3
段长 起始地址
段号S 位移量W越界
有效地址
物理地址
内存
2 100＞
+
+
段表起始地址 段表长度
图5-26  分段系统的地址变换过程
像分页系统一样，当段表放在内存中时，每当要访问一个数据时，都须访问两次内存，从
而成倍地降低了计算机的速率。解决的方法同分页系统类似，也增设一个联想存储器，用于保
存最近常用的段表项。一般情况下，由于段比页大，段表项的数目比页表项的数目少，其所需
的联想存储器也相对较小，因此可以显著地减少存取数据的时间，与没有地址变换的常规存储
器相比，其存取速度慢了10%～15%。
4．分页和分段的主要区别
由上所述不难看出，分页和分段系统有许多相似之处。例如，两者都采用离散分配方式，
且都通过地址映射机构实现地址变换。但在概念上，两者完全不同，主要表现在下列3个方面。
（1）页是信息的物理单位。采用分页存储管理方式是为了实现离散分配方式，以消减内存
的外零头，提高内存的利用率。或者说，分页只是系统管理上的需要，完全是系统的行为，对
用户是不可见的。分段存储管理方式中的段，则是信息的逻辑单位，它通常包含的是一组意义
相对完整的信息。分段的目的主要在于能更好地满足用户的需要。
（2）页的大小固定且由系统决定 。在采用分页存储管理方式的系统中，在硬件结构上就
把用户程序的逻辑地址划分为页号和页内地址两部分，也就是说该管理方式是直接由硬件实现
的，因而在每个系统中只能有一种大小的页面。而段的长度则不固定，其取决于用户所编写的
程序，通常由编译程序在对源程序进行编译时根据信息的性质来划分。
（3）分页的用户程序地址空间是一维的。分页完全是系统的行为，故在分页系统中，用户

--- Page 186 ---
165
第
5章 
存储器管理
程序的地址属于单一的线性地址空间，程序员只须利用一个标识符即可表示一个地址。而分段
是用户的行为，故在分段系统中，用户程序的地址空间是二维的，程序员在标志一个地址时，
既须给出段名，又须给出段内地址。
5.6.3 信息共享
分段系统的一个突出优点是易于实现段的共享，即允许若干个进程共享一个或多个分段，
且对段的保护也十分简单易行。
1．分页系统中对程序和数据的共享
在分页系统中，虽然也能实现对程序和数据的共享，但远不如分段系统来得方便。我们通
过一个例子来说明这个问题。例如，有一个多用户系统，可同时接纳40个用户，他们都需要执
行一个文本编辑程序（text editor ）。如果文本编辑程序有160KB的代码和另外40KB的数据区，
则总共须有8 000KB的内存空间来支持40个用户。如果160KB的代码是可重入的（reentrant ），
则无论是在分页系统还是分段系统中，该代码都能被共享，即在内存中只须保留一份文本编辑
程序的副本，此时所需的内存空间仅为1 760（ 40×40+160） KB，而不是8 000KB。假定每个
页面的大小为4KB，那么，160KB的代码将占用40个页面，数据区占用10个页面。为实现代码
的共享，应在每个进程的页表中都建立40个页表项，它们的物理块号都是21# ～60#。在每个进
程的页表中，还须为自己的数据区建立页表项，它们的物理块号分别是61# ～70#，71#～80#，
81#～90#，…。图5-27所示为分页系统中共享editor示意。
进程1
ed1
ed2
ed40
data1
data10
…
…
ed1
ed2
ed40
data1
data10
data1
data10
21
22
60
61
70
71
80
…
…
…
页表
内存
21
22
60
61
70
…
…
…
进程2
ed1
ed2
ed40
data1
data10
…
…
页表
21
22
60
71
80
…
…
0
图5-27  分页系统中共享editor示意
2．分段系统中对程序和数据的共享
在分段系统中，由于以段为基本单位，不管该段有多大，我们都只须为该段设置一个段表
项，因此实现共享变得非常容易。我们仍以共享editor为例，此时只须在（每个）进程1 和进程2
的段表中为文本编辑程序设置一个段表项，让段表项中的起始地址（80）指向editor在内存中的
起始地址。图5-28所示为分段系统中共享editor示意。

--- Page 187 ---
166
计算机操作系统 （慕课版）
进程1
段长
起始地址
160
80
40
240
160
80
40
380
段表
editor
data1
editor
80
240
280
380
420
data1
data2
…
…
进程2
editor
data2
图5-28  分段系统中共享editor示意
可重入代码（reentrant code）又称为“纯代码”（pure code），是一种允许多个进程同时
访问的代码。为使各个进程所执行的代码完全相同，绝对不允许可重入代码在执行中有任何
改变。因此，可重入代码是一种不允许任何进程对它进行修改的代码。但事实上，大多数代码
在执行时都可能会有些改变，例如，用于控制程序执行次数的变量、指针、信号量及数组等。
为此，在每个进程中都必须配以局部数据区，把在执行中可能改变的部分复制到该数据区。这
样，程序在执行时，就只须对该数据区中（属于该进程私有）的内容进行修改，而不必去改变
共享的代码。这时的可共享代码即为可重入代码。
5.7 段页式存储管理方式
分页系统以页面为内存分配的基本单位，能有效地提高内存利用率；而分段系统则以段为
内存分配的基本单位，能更好地满足用户多方面的需要。如果能对两种存储管理方式“各取所
长”，则可形成一种新的存储管理方式——段页式存储管理方式。这种新的管理方式，既具有
分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点，又能像分页系统那
样很好地解决内存分配中的外部碎片问题。
1．基本原理
段页式存储管理方式的基本原理，是分段和分页原理的结合，即先将用户程序分成若干
段，再把每段分成若干页，并为每一个段赋予一个段名。图5-29（ a）所示为作业地址空间结
构。该作业有3个段，主程序段、子程序段和数据段，页面大小为4KB。在段页式存储管理方式
中，地址结构由段号、段内页号及页内地址这3部分组成，如图5-29（b）所示。
（a）作业地址空间结构
段号（S） 段内页号（P） 页内地址（W）
（b）地址结构
子程序段
0
4K
8K
数据段
0
4K
8K
12K
10K
主程序段
0
4K
8K
12K
15K16K
图5-29  作业地址空间结构和地址结构
在段页式存储管理方式下，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表
和页表。段表的内容与分段系统略有不同，它不再是内存起始地址和段长，而是页表起始地址和页
表长度。图5-30所示为利用段表和页表进行从用户地址空间到物理（内存）地址空间的映射。

--- Page 188 ---
167
第
5章 
存储器管理
段表寄存器
段表大小
段表
页表
段号
0
1
2
3
4
1
1
1
0
1
0
1
2
3
4
1
1
1
0
1
状态 页表大小
页号 状态 存储块#
页号 状态
内存
存储块#
OS
页表起始地址
段表起始地址
图5-30  利用段表和页表实现地址映射
2．地址变换过程
在段页式存储管理方式下，为了便于实现地址变换，须为系统配置一个段表寄存器，其中
存放段表起始地址和段长TL。在进行地址变换时，首先比较段号S与段长TL。若S＜TL，则表示
未越界，于是利用段表起始地址和段号来求出该段所对应的段表项在段表中的位置，从中得到
该段的页表起始地址，并利用逻辑地址中的段内页号P来获得对应页的页表项位置，从中读出该
页所在的物理块号 b，再利用物理块号 b和页内地址来构成物理地址。图5-31所示为段页式存储
管理方式下的地址变换机构。
段表寄存器 逻辑地址地址越界
段表起始地址
段表 页表
物理地址
…
…
0
1
2
3
0
1
2 b b W
3
段表长度 段号S 页号P 页内地址W
+
+
＞
图5-31  段页式存储管理方式下的地址变换机构
在段页式存储管理方式下，为了获得一条指令或数据，须三次访问内存。第一次访问是访
问内存中的段表，从中取得页表起始地址；第二次访问是访问内存中的页表，从中取得该页所
在的物理块号，并利用该物理块号与页内地址来一起构成指令或数据的物理地址；第三次访问
才是真正地从第二次访问所得的地址中取出指令或数据。
显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一
个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的
表项，则可从中得到相应页的物理块号，利用其与页内地址一起来构成物理地址；若未找到匹

--- Page 189 ---
168
计算机操作系统 （慕课版）
配的表项，则仍须再进行三次访问内存。由于它的基本原理与分页及分段的情况相似，故此处
不再赘述。
5.8 实例：基于IA-32/x86-64架构的内存管理策略
多年来，Intel公司的芯片架构（intel architecture， IA）一直主宰着个人计算机。从20世纪
70年代发布的16位 Intel 8086开始，到32位的IA -32架构（Pentium家族），如今已发展到了最
新的64位的x86 -64架构。目前，最受欢迎的个人计算机OS（如Windows、 Mac OS X和 Linux  
等）都运行在上述架构中。
本节将简要讨论运行在IA-32架构和x86-64架构上的Linux系统的地址变换问题。
1．IA-32 架构
IA-32架构中OS的内存管理可分为两部分：分段和分页。其工作方案为： CPU生成逻辑地
址，并将其交给分段单元；分段单元为每个逻辑地址生成一个线性地址；然后，将线性地址交
给分页单元，以生成内存的物理地址。因此，分段和分页单元组成了内存管理单元（memory 
management unit，MMU）。
作为一个例子，考虑运行在IA -32架构上的Linux系统。由于Linux被设计为在一系列处理
机上均能运行（其中许多处理机可能仅提供对段的有限支持），因此，Linux并不依赖段，并
且能够最低限度地使用段。在IA -32架构中， Linux 仅使用6个段：内核代码段、内核数据段、
用户代码段、用户数据段、任务状态段（task state segment， TSS）和默认的本地描述符（local 
descriptor table， LDT）段。用户代码段和用户数据段被所有以用户模式运行的进程所共享。
每个进程都有它自己的TSS，该段的段描述符被保存在全局描述符表（global descriptor table，
GDT）中。TSS被用来保存在上下文切换中每个进程的硬件上下文。
IA-32架构的页可分为4KB或 4MB两种。对于4KB的页，IA -32架构采用二级分页方法，其
中32位线性地址的划分如图5-32所示。
IA-32架构的地址变换方案类似于图5-22， IA-32架构的分页如图5-33所示。最高的10位引
用外部页表的条目，称为页目录（page directory）。需要说明的是，CR3寄存器指向当前进程
的页目录。页目录内的条目指向由线性地址中间10位索引的内部页表（简称页表）。最低12位
（0～11）为页表条目指向的4KB页内偏移。
P1 P2 d
页码 页内偏移
10 10 12
       
（线性地址）
页目录
页目录
CR3
寄存器
页目录
31 22 21 12 11 0
31 22 21 0
页表
页表
偏移
偏移
4MB页面
4KB页面
           图5-32  32位线性地址的划分                                                          图5-33  IA-32架构的分页

--- Page 190 ---
169
第
5章 
存储器管理
尽管IA-32架构采用了二级分页模式，但是由于Linux被设计为能运行在多种硬件平台上，
其中许多硬件平台是64位的，二级分页并不适合。因此，Linux采用了适合32位和64位架构的三
级分页模式，如图5-34所示。
（线性地址）
页目录
页目录指针表 页目录 页表
31 2230 21 12 11 0
页表 偏移
4KB页面
CR3寄存器
图5-34  Linux系统中的三级分页模式
三级分页模式中采用了页地址扩展（page address extension， PAE），故允许访问大于4GB
的物理地址空间。采用PAE的根本特点是，从两级的分页方案（见图5-33）变成了三级的分页方
案（见图5-34），后者的最高两位用于指向页目录指针表。
PAE将页目录和页表的条目大小从32位增大到了64位，这让页表和页帧的起始地址从20位
增大到了24位。结合12位的偏移，加上IA-32 PAE的支持，可增加地址空间到36位，最多可支持
64GB的物理内存。需要重点注意的是，采用PAE时需要OS支持。
2．x86-64 架构
支持64位的地址空间意味着可寻址的内存达到了惊人的2
64
B，即大于16EB（ 1EB=  
2
20
TB）。然而，即使 64位系统有能力访问这么多的内存，实际上目前设计的地址也远远少于
64位。目前提供的x86 -64架构采用四级分页模式，支持48位虚地址，它的页面大小可为4KB、
2MB或1GB。这种线性地址的表示如图5-35所示。由于这种寻址方案能够采用PAE，系统虚拟地
址的大小为48位，可支持52位的物理地址（4 096TB）。
未用
63 48 47 39 38 30 29 22 21 12 11 0
页面映射级别4 页目录指针表 页目录 页表 偏移
图5-35  x86-64架构的线性地址
5.9 本章小结
本章首先介绍了存储器管理的背景知识，包括存储器的层次结构、程序的装入与链
接、对换与覆盖等内容；其次，介绍了连续分配方式，其中重点介绍了动态分区分配和动
态重定位分区分配；再次，详细介绍了离散分配存储管理方案中的分页、分段和段页式存
储管理方式；最后，以IA -32架构和x86 -64架构为例，说明了目前个人计算机OS 的内存管
理策略。
不同的存储管理方式在许多方面都存在着不同，在比较不同的存储管理方式时，需要综合
考虑如下几点：硬件支持、性能、碎片、重定位、对换、共享和保护。

--- Page 191 ---
170
计算机操作系统 （慕课版）
习题5（含考研真题）
一、简答题
1．存储器管理的基本任务，是为多道程序的并发执行提供良好的存储器环境。请问：“良
好的存储器环境”应包含哪几个方面？
2．内存保护是否可以完全由软件实现？为什么？
3．（考研真题）请解释什么是重定位？为什么要重定位？
4．动态重定位的实现方式有哪几种？
5．可采用哪几种方式将程序装入内存？它们分别适用于何种场合？
6．何谓静态链接？静态链接时需要解决哪两个问题？
7．（考研真题） 编写程序时，源代码必须经过编译和链接生成目标代码，请问什么是链
接？链接主要解决了什么问题？简述链接的主要类型及其优缺点。
8．为什么要引入对换？对换可分为哪几种类型？
9．在对换技术中，对文件区管理的目标和对对换空间管理的目标有何不同？
10．为什么说分段系统较分页系统更易实现信息共享与保护？
11．提高内存利用率的途径主要有哪些？
二、计算题
12．（考研真题）假设一个分页存储系统具有快表，多数活动页表项都可以存在于其中。
若页表放在内存中，内存访问时间是1ns，快表的命中率是85%，快表的访问时间为0.1ns，则有
效存取时间为多少？
13．对一个将页表存放在内存中的分页系统：
（1）如果访问内存需要0.2µs，则有效访问时间为多少？
（2）如果加一快表，且假定在快表中找到页表项的概率高达90%，则有效访问时间又是多
少（假定查快表须花费的时间为0）？
14．某系统采用分页存储管理方式，拥有逻辑空间32页，每页2KB，拥有物理空间1MB。
（1）写出逻辑地址的格式。
（2）若不考虑访问权限等，则进程的页表有多少项？每项至少有多少位？
（3）如果物理空间减少一半，则页表结构应相应地做怎样的改变？
15．已知某分页系统，内存容量为 64KB ，页面大小为 1KB，对一个 4页大的作业，其 0、
1、2、3页分别被分配到内存的2、4、6、7块中。
（1）将十进制的逻辑地址1 023、2 500、3 500、4 500变换为物理地址。
（2）以十进制的逻辑地址1 023为例，画出地址变换过程图。
16．（考研真题）已知某系统页面长4KB，每个页表项的大小为4B，采用多层分页策略映
射64位的用户地址空间。若限定最高层页表只占1页，问它可采用几层分页策略。
17．对于表5-2所示的段表，请将逻辑地址（0, 137），（1, 4 000)，（2, 3 600)，（5, 230）
变换成物理地址。

--- Page 192 ---
171
第
5章 
存储器管理
表5 -2 段表
段号 内存起始地址 段长
0 50K 10KB
1 60K 3KB
2 70K 5KB
3 120K 8KB
4 150K 4KB
三、综合应用题
18．（考研真题）某系统采用动态分区分配方式管理内存，内存空间为 640KB，低端40KB
存放OS。系统为用户作业分配空间时，从低地址区开始。针对下列作业请求序列，画图表示使
用首次适应算法进行内存分配和回收后内存的最终映像。作业请求序列如下：
作业1申请200KB，作业2申请70KB；
作业3申请150KB，作业2释放70KB；
作业4申请80KB，作业3释放150KB；
作业5申请100KB，作业6申请60KB；
作业7申请50KB，作业6释放60KB。
19．某OS采用分段存储管理方式，用户区内存为512KB，空闲块链入空闲块表，分配时
截取空闲块的前半部分（小地址部分）。初始时全部空闲。执行申请、释放操作序列request
（300KB）、request（l00KB）、release（300KB）、request（150KB）、request（50KB）、request
（90KB）后：
（1）若采用首次适应算法，则空闲块表中有哪些空闲块（指出大小及起始地址）？
（2）若采用最佳适应算法，则空闲块表中有哪些空闲块（指出大小及起始地址）？
（3）若随后又要申请80KB，则针对上述两种情况会产生什么后果？这说明了什么问题？
20．某系统的空闲分区如表5-3所示，采用可变分区分配策略处理作业。现有作业序列
96KB、20KB、200KB，若采用首次适应算法和最佳适应算法来处理这些作业序列，则哪种算法
能满足该作业序列的请求？为什么？
表5 -3 空闲分区表
分区号 分区大小 分区起始地址
1 32KB 100K
2 10KB 150K
3 5KB 200K
4 218KB 220K
5 96KB 530K

--- Page 193 ---
虚拟存储器

第6章
在第1章中介绍存储器管理功能时，提到了内存扩充功能，该功能并非从物理上去扩大
内存容量，而是借助虚拟存储器等技术，从逻辑上扩大内存容量，使用户所感觉到内存容
量比实际内存容量大得多，于是便可让比内存空间更大的程序运行，或者让更多的用户程
序并发运行。这样既满足了用户的需要，又改善了系统的性能。本章将对虚拟存储技术做
较详细的阐述。本章知识导图如图6-1所示。
虚拟存储器
虚拟存储器概述 
请求分页存储管理方式
页面置换算法
“抖动”与工作集
请求分段存储管理方式
局部性原理
定义与特征
实现方法
最佳页面置换算法
先进先出页面置换算法
最近最久未使用页面置换算法
最少使用页面置换算法
Clock页面置换算法
页面缓冲算法
图6-1  第6章知识导图
第6 章导读


--- Page 194 ---
173
第
6章 
虚拟存储器
6.1 虚拟存储器概述
6.1.1 常规存储器管理方式的特征和局部性原理
1．常规存储器管理方式的特征
我们把第5章中所介绍的各种存储器管理方式，统称为传统存储器管理方式，它们全都具有
以下两个共同的特征。
（1）一次性是指作业必须一次性地全部装入内存后，方能开始运行。在传统存储器管理方
式中，无一例外地要求先将作业全部装入内存后方能运行。正是这一特征导致了下述两种情况
的发生：①当作业很大时，它所要求的内存空间超过了内存总容量，此时无法将全部作业装入
内存，导致该作业无法运行；②在有大量作业要求运行的情况下，由于每个作业都需要全部装
入内存后方能运行，因此每次只能装入少量的作业，致使系统的多道程序度下降，这对于提高
处理机的利用率和系统吞吐量都会产生不利影响。事实上，许多作业在运行时，并非需要用到
全部程序和数据，如果一次性地装入其全部程序和数据，显然是对内存空间的一种浪费。
（2）驻留性是指作业被装入内存后，整个作业都一直驻留在内存中，其中任何部分都不会
被换出，直至作业运行结束。尽管运行中的进程会因 I/O等原因而被阻塞，可能处于长期等待状
态，或者有的程序模块在运行过一次后就不再需要（运行）了，但它们都仍将驻留在内存中，
继续占用宝贵的内存资源。
由此可以看出，上述的一次性及驻留性特征，使得许多在程序运行中不用或暂时不用的程
序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入内存运行，显然，这是
在浪费宝贵的内存资源。现在要研究的问题是：一次性及驻留性特征，是否是程序在运行时所
必须保留的和不可改变的特征。
2．局部性原理
程序运行时存在的局部性现象，很早就已被人发现，但直到1968年，布兰农 ·邓宁 
（Brannon Denning）才真正指出：程序在执行时将呈现出局部性规律，即在一段较短的时间
内，程序的执行仅局限于某个部分，它所访问的存储空间也局限于某个区域。布兰农 ·邓宁提
出了下列论点。
（1）程序在执行时，除了少部分的转移和过程调用指令外，在大多数情况下是顺序执行
的。该论点也在后来许多学者对高级程序设计语言（如FORTRAN语言、Pascal语言及C 语言
等）规律的研究中被证实。
（2）过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域。但经研究发现，过
程调用的深度在大多数情况下都不会超过5 。这就是说，程序将会在一段时间内都局限在这些过
程的范围内运行。
（3）程序中存在许多循环结构，这些结构虽然只由少数指令构成，但是它们将会被多次执行。
（4）程序中还包括许多对数据结构的处理，如对数组进行操作，它们往往都局限于很小的
范围内。
局限性又表现在下述两个方面。
（1）时间局限性。如果程序中的某条指令被执行，则不久以后该指令可能会被再次执行；
如果某数据被访问过了，则不久以后该数据可能会被再次访问。产生时间局限性的典型原因是
在程序中存在着大量的循环操作。
内存扩充技术


--- Page 195 ---
174
计算机操作系统 （慕课版）
（2）空间局限性。一旦程序访问了某个存储单元，不久之后，其附近的存储单元也将会被
访问，即程序在一段时间内所访问的地址可能集中在一定的范围之内，其典型情况便是程序的
顺序执行。
3．虚拟存储器的基本工作情况
基于局部性原理可知，在运行应用程序之前，没有必要将之全部装入内存，而仅须将那些
当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它
所要访问的页（段）已被调入内存，则可继续执行下去；但如果程序所要访问的页（段）尚未被
调入内存（称为缺页或缺段），则须发出缺页（段）中断请求，此时OS将利用请求调页（段）
功能，将它们调入内存，以使进程能继续执行下去。如果此时内存已满，无法再装入新的页
（段），则OS还须再利用页（段）的置换功能，将内存中暂时不用的页（段）调至盘上，在腾出
足够的内存空间后，再将要访问的页（段）调入内存，使程序继续执行下去。这样，便可使一个大
的用户程序能在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。
6.1.2 虚拟存储器的定义与特征
1．虚拟存储器的定义
当用户看到自己的程序能在系统中正常运行时，他会认为，该系统所具有的内存容量一定
比自己的程序大，或者说，用户所感觉到的内存容量会比实际内存容量大得多。但用户所看到
的大容量只是一种错觉，是“虚”的，故人们把这样的存储器称为虚拟存储器。
综上所述，所谓虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑上对内存容量
加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近
于内存速度，而每个存储位的成本却又接近于外存。可见，虚拟存储技术是一种性能非常优越
的存储器管理技术，故被广泛应用于大、中、小和微型计算机中。
2．虚拟存储器的特征
与传统的存储器管理方式相比，虚拟存储器具有以下3个重要特征。
（1）多次性。
多次性是相对于传统存储器管理方式的一次性而言的，是指一个作业中的程序和数据，无
须在作业运行时一次性地全部调入内存，而是允许被分成多次调入内存运行，即只须将当前要
运行的那部分程序和数据装入内存即可开始运行。以后当要运行到尚未调入的那部分程序时，
再将它调入即可。正是虚拟存储器的多次性特征，才使它具有从逻辑上扩大内存的功能。无
疑，多次性是虚拟存储器最重要的特征，它是任何其他的存储管理方式所不具有的。因此，我
们也可以认为虚拟存储器是具有多次性特征的存储器管理系统。
（2）对换性。
对换性是相对于传统存储器管理方式的驻留性而言的，是指一个作业中的程序和数据无
须在作业运行时一直常驻内存，而允许它们在作业运行时进行换入、换出；亦即，在进程运行
期间，允许将那些暂不使用的代码和数据从内存调至外存的对换区（换出），待以后需要时再
将它们从外存调至内存（换入）。甚至还允许将暂时不运行的进程调至外存，待它们重又具备
运行条件时再调入内存。换入和换出能有效提高内存利用率。可见，虚拟存储器具有对换性特
征，也正是这一特征，才使得虚拟存储器得以正常运行。试想，如果虚拟存储器不具有换出功
能，即不能把那些在内存中暂时不运行的进程或页面（段）换至外存，那么不仅不能充分利用

--- Page 196 ---
175
第
6章 
虚拟存储器
内存，而且会导致在换入时，因无足够的内存空间而经常以失败告终。
（3）虚拟性。
虚拟性是指能够从逻辑上扩大内存容量，使用户所看到的内存容量远大于实际内存容量。
这样，就可以在小的内存中运行大的作业，或者能提高多道程序度。它不仅能有效改善内存利
用率，还能提高程序执行的并发程度，从而可以增加系统吞吐量。这是虚拟存储器所表现出来
的最重要的特征，也是实现虚拟存储器最重要的目标。正是它具有的这一特征，使得虚拟存储
器目前已成为在大、中、小及微型计算机上被广泛采用的存储器管理方式。
值得说明的是，虚拟性是以多次性和对换性为基础的，或者说，仅当系统允许将作业分多
次调入内存，并能将内存中暂时不运行的程序和数据换至外存时，才有可能实现虚拟存储器；
而多次性和对换性，显然又必须建立在离散分配方式的基础上。
6.1.3 虚拟存储器的实现方法
在虚拟存储器中，允许将一个作业分多次调入内存。如果采用连续分配方式，则由于要求
必须将作业装入一个连续的内存区域中，因此就必须事先为作业一次性申请一个足以容纳整个
作业的内存空间，以便能将该作业分先后多次装入内存。这不仅会使相当一部分内存空间都处
于暂时或“永久”空闲状态，造成内存资源的严重浪费，而且无法也无意义再从逻辑上扩大内
存容量。因此，虚拟存储器的实现，都毫无例外地建立在离散分配方式的基础上。目前，所有
的虚拟存储器都是采用下述方式之一实现的。
1．请求分页系统
请求分页系统是在分页系统的基础上，增加了请求调页功能和页面置换功能所形成的页式
虚拟存储系统。它允许用户程序只装入少数页面的程序（及数据）即可启动运行；以后，再通
过请求调页功能和页面置换功能，陆续地把即将运行的页面调入内存，同时把暂不运行的页面
换出到外存上。置换时以页面为单位。为了能实现请求调页功能和页面置换功能，系统必须提
供必要的硬件支持和实现请求分页的软件。
（1）硬件支持。主要的硬件支持有：①请求分页的页表机制，它是在纯分页的页表机制上
通过增加若干项而形成的，被作为请求分页的数据结构；②缺页中断机构，即每当用户程序要
访问的页面尚未调入内存时，便产生一个缺页中断，以请求OS将所缺的页调入内存；③地址变
换机构，这同样是在纯分页地址变换机构的基础上发展形成的。
（2）实现请求分页的软件，包括用于实现请求调页的软件和实现页面置换的软件。它们在
硬件的支持下，将程序运行时所需的（尚未在内存中的）页面调入内存，再将内存中暂时不用
的页面从内存置换到外存上。
2．请求分段系统
请求分段系统是在分段系统的基础上，增加了请求调段功能和分段置换功能后所形成的段式
虚拟存储系统。它允许用户程序只装入少数段（而非所有的段）的程序和数据即可启动运行；以
后，通过请求调段功能和分段置换功能将暂不运行的段调出，再调入即将运行的段。置换是以段
为单位进行的。为了实现请求分段，系统同样需要必要的硬件支持和实现请求分段的软件。
（1）硬件支持。主要的硬件支持有：①请求分段的段表机制，它是在纯分段的段表机制上
通过增加若干项而形成的，被作为请求分段的数据结构；②缺段中断机构，即每当用户程序要
访问的段尚未调入内存时，便产生一个缺段中断，以请求OS将所缺的段调入内存；③地址变换

--- Page 197 ---
176
计算机操作系统 （慕课版）
机构，这同样是在纯分段地址变换机构的基础上发展形成的。
（2）实现请求分段的软件，包括用于实现请求调段的软件和实现段置换的软件。它们在硬
件的支持下，先将内存中暂时不用的段从内存置换到外存上，再将程序运行时所需的（尚未在
内存中的）段调入内存。
虚拟存储器在实现上是有一定难度的。相对于请求分段系统，因为请求分页系统换入与换出的
基本单位都是固定大小的页面，所以在实现上要容易些。而请求分段系统换入与换出的基本单位是
段，其长度是可变的，且段的分配类似于动态分区分配，它在内存分配和回收上都比较复杂。
目前，有不少虚拟存储器是建立在段页式系统基础上的，通过增加请求调页和页面置换功
能，形成了段页式虚拟存储器系统，而且它们会把实现虚拟存储器所需的硬件支持集成在处理
机芯片上。例如，早在20世纪80年代中期出现的Intel 80386处理机芯片，便已具备了支持段页式
虚拟存储器的功能，以后推出的80486、 80586以及P2、 P3、P4等芯片中，都无一例外地具有支
持段页式虚拟存储器的功能。
6.2 请求分页存储管理方式
请求分页系统是建立在基本分页基础上的，为了能支持虚拟存储器功能，
其增加了请求调页功能和页面置换功能。每次换入和换出的基本单位都是长度
固定的页面，这使得请求分页系统在实现上要比请求分段系统简单（后者换入和换出的基本单位
是长度可变的段）。因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式。
6.2.1 请求分页中的硬件支持
为了实现请求分页，系统必须提供一定的硬件支持。计算机系统除了要求一定容量的内存
和外存外，还需要有请求页表机制、缺页中断机构以及地址变换机构。
1．请求页表机制
在请求分页系统中，需要的主要数据结构是请求页表。其基本作用仍然是将用户地址空间
中的逻辑地址映射为内存空间中的物理地址。为了满足页面换入与换出的需要，在请求页表中
又增加了四个字段。这样，请求分页系统中的每个页表即应包含以下各项。
页号 物理块号 状态位P 访问字段A 修改位M 外存地址
现对页表中新增的各字段进行说明，如下所示。
（1）状态位P ：又称为存在位。由于在请求分页系统中，只将应用程序的一部分调入内
存，还有一部分仍在外存中，故须在页表中增加一个存在位字段。由于该字段仅有一位，故又
称为字。它用于指示该页是否已调入内存，供程序访问时参考。
（2）访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时
间未被访问，供页面置换算法（程序）在选择换出页面时参考。
（3）修改位M：又称为脏位（dirty bit），标志该页在调入内存后是否被修改过。由于内存
中的每一页都在外存中保留一份副本，因此在置换该页时，若未被修改，就无须再将该页写回
到外存中，以减少系统的开销和启动磁盘的次数；若已被修改，则必须将该页重写到外存中，
以保证外存中所保留的副本始终是最新的。简而言之，修改位M供置换页面时参考。
请求分页


--- Page 198 ---
177
第
6章 
虚拟存储器
（4）外存地址：用于指出该页在外存中的地址，通常是物理块号，供调入该页时参考。
2．缺页中断机构
在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求OS 将
所缺之页调入内存。缺页中断作为中断，它们同样需要经历诸如保护CPU现场环境、分析中断原
因、转入缺页中断处理程序进行处理以及在中断处理完成后恢复CPU现场环境等步骤。但缺页中
断又是一种特殊的中断，它与一般的中断相比有着明显的不同，主要表现在以下两个方面。
（1）在指令执行期间，产生和处理中断信号。CPU通常会在一条指令执行完后，才检查是
否有中断请求到达。若有，便去响应；否则，继续执行下一条指令。然而，缺页中断是在指令
执行期间，若发现所要访问的指令或数据不在内存中时，便立即
产生和处理缺页中断信号，以便能及时将所缺之页调入内存。
（2）一条指令在执行期间，可能会产生多次缺页中断。  
图6-2所示为一个涉及6 次缺页中断的指令举例。如在执行一条指
令copy A to B时，可能要产生6次缺页中断，其中指令本身跨了两
个页面，A和B又分别各是一个数据块，也都跨了两个页面。基于
这些特征，系统中的硬件机构应能保存多次中断时的状态，并保
证最后能返回到中断前产生缺页中断的指令处，继续执行。
3．地址变换机构
请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟存储
器而通过增加某些功能所形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等。
图6-3所示为请求分页系统中的地址变换过程。在进行地址变换时，首先会检索快表，试图从中
找到所要访问的页。若能找到，则修改页表项中的访问位，供页面置换算法选择换出页面时参
考。对于写指令，还须将修改位置成“1”，表示该页在调入内存后已被修改。然后利用页表项
中给出的物理块号和页内地址形成物理地址。地址变换过程到此结束。
保留CPU现场环境
程序请求
访问一页
从外存中找到缺页
内存是否已满？
选择一页换出
该页是否被修改？
将该页写回外存
将第一页从外存换入内存
修改页表
修改快表
访问页表
修改访问位和修改位
页是否在内存中？
页表项是否在快表中？
页号＞页表长度？
开始
越界中断
CPU检索快表
形成物理地址
地址变换结束
OS命令CPU从外存读缺页
启动I/O硬件
是
是
是
是
是
否
否
否
否
否
图6-3  请求分页系统中的地址变换过程
页面
指令
copy A
to B
6
B：
A：
5
4
3
2
1
图6-2  涉及6次缺页中断的指令举例

--- Page 199 ---
178
计算机操作系统 （慕课版）
如果在快表中未找到该页的页表项，则应到内存中去查找页表，再通过找到的页表项中的
状态位P来了解该页是否已调入内存。若该页已调入内存，则应将该页的页表项写入快表。当快
表已满时，则应先调出按某种算法所确定的页的页表项，然后再写入该页的页表项；若该页尚
未调入内存，则应产生缺页中断，请求OS从外存把该页调入内存。
6.2.2 请求分页中的内存分配
在为进程分配内存时，将涉及3 个问题： 第一，为保证进程能正常运行，所需要的最小物
理块数的确定； 第二，在为每个进程分配物理块时，应采取什么样的内存分配策略，即所分配
的物理块是固定的，还是可变的； 第三，在为不同进程分配物理块时，是采取平均分配算法分
配，还是根据进程的大小按比例分配。
1．最小物理块数的确定
一个显而易见的事实是，随着为每个进程所分配的物理块数的减少，进程在执行过程中的
缺页率将会上升，从而会降低进程的执行速度。为使进程能有效地工作，应为它分配一定数目
的物理块，但这并不是最小物理块数的概念。
最小物理块数是指，能保证进程正常运行所需的最小物理块数，当系统为进程分配的物理
块数少于此值时，进程将无法运行。进程应获得的最小物理块数与计算机的硬件结构有关，取
决于指令的格式、功能和寻址方式。对于某些简单的机器，若是单地址指令，且采用直接寻址
方式，则所需的最小物理块数为2。其中，一块是用于存放指令的页面，另一块则是用于存放数
据的页面。如果该机器允许间接寻址，则至少要求有3 个物理块。对于某些功能较强的机器，其
指令长度可能是两个或多于两个字节，因而其指令本身有可能跨两个页面，且源地址和目标地
址所涉及的区域，也都可能跨两个页面。正如前面所介绍的在缺页中断机构中要发生6 次中断的
情况一样，对于这种机器，至少要为每个进程分配6个物理块，以装入6个页面。
2．内存分配策略
在请求分页系统中，可采取两种内存分配策略，即固定分配（ fixed allocation ）和可变
分配（variable allocation）。在进行置换时，也可采取两种置换策略，即全局置换（global 
replacement）和局部置换（local replacement）。于是可组合出以下3种适用的策略。
（1）固定分配局部置换 。所谓固定分配是指，为每个进程分配一组数目固定的物理块，
在进程运行期间不再改变。所谓局部置换是指，如果进程在运行中发现缺页，则只能从分配给
该进程的n个页面中选出一页换出，然后再调入一页，以保证分配给该进程的内存空间不变。采
用该策略时，为每个进程分配多少物理块，是根据进程类型（如交互型或批处理型等）或程序
员、程序管理员的建议来确定的。实现这种策略的困难在于：应为每个进程分配多少个物理块
难以确定。若太少，则会频繁地出现缺页中断，降低系统吞吐量。若太多，则又必然会使内存
中驻留的进程数目减少，进而可能造成CPU或其他资源空闲的情况，而且在实现进程对换时，
会花费更多的时间。
（2）可变分配全局置换。所谓可变分配是指，先为每个进程分配一定数目的物理块，然后
在进程运行期间，可根据情况做适当的增加或减少。所谓全局置换是指，如果进程在运行中发
现缺页，则将OS所保留的空闲物理块（一般组织为一个空闲物理块队列），取出一块分配给该
进程，或者以所有进程的全部物理块为标的，选择一块换出，然后将所缺之页调入。这样，分
配给该进程的内存空间就会随之增大。可变分配全局置换可以说是最易实现的一种物理块分配

--- Page 200 ---
179
第
6章 
虚拟存储器
和置换策略，已用于若干个OS中。在采用这种策略时，凡产生缺页（中断）的进程，都将获得
新的物理块，仅当空闲物理块队列中的物理块用完时，OS才会从内存中选择一页调出。被选择
调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程所拥有的物理块会减少，
这将导致其缺页率增加。
（3）可变分配局部置换。该策略同样是根据进程的类型或程序员的要求，为每个进程分配
一定数目的物理块的；但当某进程发现缺页时，则只允许从该进程在内存的页面中选择一页换
出，这样就不会影响其他进程的运行。如果进程在运行中频繁地发生缺页中断，则系统须再为
该进程分配若干附加的物理块，直至该进程的缺页率减少到适当程度为止。反之，若一个进程
在运行过程中的缺页率特别低，则此时可适当减少分配给该进程的物理块数，但不应引起其缺
页率的明显增加。
3．物理块分配算法
在采用固定分配策略时，为了将系统中可供分配的所有物理块分配给各个进程，一般可采
用下列几种算法。
（1）平均分配算法。将系统中所有可供分配的物理块，平均分配给各个进程。例如，当系
统中有100个物理块且有5 个进程在运行时，每个进程可分得20个物理块。这种方式貌似公平，
但由于未考虑各进程本身的大小，会造成实际上的不公平。例如，一个进程只有10页，为其分
配20个物理块后则会有10个物理块闲置；而另外一个进程有200页，也被分配了20个物理块，则
显然不够用，且必然会有很高的缺页率。
（2）按比例分配算法 。根据进程的大小按比例分配物理块，如果系统中共有 n个进程，每
个进程的页面数为Si，则系统中各进程页面数的总和S为：
。
再假定系统中可用的物理块总数为m，则可由下式算得每个进程所能分到的物理块数bi为：
，
其中，bi 应该取整， 它必须大于最小物理块数。
（3）考虑优先权的分配算法。在实际应用中，为了使重要的、紧迫的作业能尽快完成，应
为它分配较多的内存空间。通常采取的方法是把内存中可供分配的所有物理块分成两部分：一
部分按比例分配给各进程；另一部分则根据各进程的优先权进行分配，为高优先权进程适当地
增加其相应的分配份额。在有的系统（如重要的实时控制系统）中，可能会完全按优先权来为
各进程分配物理块。
6.2.3 页面调入策略
为使进程能够正常运行，必须事先将要执行的那部分程序和数据所在的页面调入内存。但
问题是：①系统应在何时调入所需页面；②系统应从何处调入这些页面；③系统应如何进行调
入；④与调入次数相关的缺页率是如何定义的。
1．何时调入页面
为了确定系统将进程运行时所缺的页面调入内存的时机，可采取预调页策略或请求调页策
略，现分述如下。
（1）预调页策略。如果进程的许多页都存放在外存的一个连续区域中，则一次调入若干个

--- Page 201 ---
180
计算机操作系统 （慕课版）
相邻的页会比一次调入一页更高效些。但如果调入的一批页面中的大多数都未被访问，则这样
做又是低效的。于是便考虑采用一种以预测为基础的预调页策略，将那些预计在不久之后会被
访问的页面，预先调入内存。如果预测较准确，那么这种策略显然是很有吸引力的。但遗憾的
是，目前预调页的成功率仅约50%。
但是，预调页策略又因其特有的长处取得了很好的效果。首先，其可用于在第一次将进程
调入内存时，此时可将程序员指出的那些页先调入内存。其次，在采用工作集的系统中，每个
进程都具有一张表，表中记录有运行时的工作集，每当程序被调度运行时，就将工作集中的所
有页调入内存。关于工作集的概念将在6.4节中进行介绍。
（2）请求调页策略 。当进程在运行中需要访问某部分程序和数据时，若发现其所在的页
面不在内存中，则立即提出请求，由OS将其所需页面调入内存。由请求调页策略所确定调入
的页，是一定会被访问的，再加之请求调页策略比较易于实现，故在目前的虚拟存储器中大
多采用此策略。但这种策略每次仅能调入一页，故需要花费较大的系统开销，增加了磁盘I/O
的启动频率。
2．从何处调入页面
请求分页系统中的外存可分为两部分：用于存放文件的文件区和用于存放对换页面的对换
区。通常，由于对换区采用连续分配方式，而文件区采用离散分配方式，因此对换区的数据存
取（磁盘I/O）速度比文件区的高。这样，每当发生缺页请求时，系统应从何处将缺页调入内
存，可分为以下3种情况。
（1）系统拥有足够的对换区空间，这时可以从对换区调入全部所需页面，以提高调页速
度。为此，在进程运行前，须将与该进程有关的文件从文件区复制到对换区。
（2）系统缺少足够的对换区空间，这时，凡是不会被修改的文件都直接从文件区调入；
而当换出这些页面时，由于它们未被修改，不必再将它们重写到磁盘（换出），以后再调入时
仍从文件区直接调入。但对于那些可能已被修改的部分，在将它们换出时，须将它们调到对换
区，以后需要时再从对换区调入。
（3）UNIX方式。由于与进程有关的文件都放在文件区，故凡是未运行过的页面，都应从
文件区调入。而对于曾经运行过但又被换出的页面，由于被放在对换区，因此在下次调入时，
应从对换区调入。由于UNIX系统允许页面共享，因此，某进程所请求的页面有可能已被其他进
程调入内存，此时也就无须再从对换区调入。
3．如何调入页面
每当程序所要访问的页面未在内存时（存在位为“0 ”），便向 CPU发出一个缺页中
断，中断处理程序首先保留CPU现场环境，分析中断原因后转入缺页中断处理程序。该程序
通过查找页表得到该页的外存地址后，如果此时内存能容纳新页，则启动磁盘I/O，将所缺
之页调入内存，然后修改页表。如果内存已满，则须先按照某种页面置换算法，从内存中
选出一页准备换出；如果该页未被修改过（修改位为“0 ”），则不必将该页写回磁盘；但
如果该页已被修改（修改位为“1 ”），则必须将该页写回磁盘，然后再把所缺的页调入内
存，并修改页表中的相应表项，置其存在位为“1 ”，并将此页表项写入快表中。在缺页调
入内存且利用修改后的页表形成了所要访问数据的物理地址后，再去访问内存数据。整个页
面调入过程对用户是透明的。

--- Page 202 ---
181
第
6章 
虚拟存储器
4．缺页率
假设一个进程的逻辑空间为n页，系统为其分配的内存物理块数为m（m≤n）。如果在进程
运行过程中，访问页面成功（即所访问页面在内存中）的次数为 S，访问页面失败（即所访问页
面不在内存中，需要从外存调入）的次数为 F，则该进程总的页面访问次数为： A=S+F，该进
程在其运行过程中的缺页率为：f=F/A。
通常，缺页率会受到以下几个因素的影响。 ①页面大小 ：若页面划分较大，则缺页率较
低；反之，则缺页率较高。 ②进程所分配物理块的数目 ：所分配的物理块数目越多，缺页率
越低；反之，缺页率越高。 ③页面置换算法：算法的优劣决定了进程执行过程中缺页中断的次
数，因此缺页率是衡量页面置换算法的重要指标。 ④程序固有特性：程序本身的编制方法对缺
页中断次数有影响，根据程序执行的局部性原理，程序编制的局部化程度越高，相应执行时的
缺页程度就越低。
事实上，在缺页中断处理时，当由于空间不足而需要置换部分页面到外存时，选择被置换
页面还需要考虑置换的代价，例如页面是否被修改过。没有修改过的页面可以直接放弃，而已
被修改过的页面则必须进行保存，因此处理这两种情况时的耗时是不同的。假设被置换的页面
被修改的概率是 β，其缺页中断处理时间是 ta，被置换页面没有被修改的缺页中断时间是 tb，那
么，缺页中断处理时间的计算公式可表示为：
t =β×ta+（1-β）×tb。
请思考并比较纯请求分页和预调页的优缺点。
思考题
6.3 页面置换算法
在进程运行过程中，当其所要访问的页面不在内存中，而须把它们调入
内存，但内存已无空闲空间时，为了保证该进程能正常运行，系统必须从内存
中调出一页程序或数据，并将其送入磁盘的对换区中。但应将哪个页面调出，
须根据一定的算法来确定。通常，把选择换出页面的算法称为页面置换算法（page-replacement 
algorithm）。页面置换算法的好坏将直接影响系统的性能。
不适当的算法可能会导致进程发生“抖动”（thrashing），即刚被换出的页，很快又要被
访问，因此需要将它重新调入，此时又需要再选一页调出；而此刚被调出的页，很快又被访
问，又需要将它调入，如此频繁地更换页面，以致一个进程在运行中把大部分时间都花费在了
页面置换工作上，我们称该进程发生了“抖动”。
一个好的页面置换算法应具有较低的页面置换频率。从理论上讲，应将那些以后不再会访
问的页面或那些在较长时间内不会再访问的页面换出。目前已有多种页面置换算法，它们都试
图更接近于理论上的目标。下面介绍几种常用的页面置换算法。
6.3.1 最佳页面置换算法和先进先出页面置换算法
目前有许多页面置换算法，相比而言，最佳页面置换算法和先进先出页面置换算法是两种
比较极端的算法。最佳页面置换算法是一种理想化的算法，它具有最好的性能，但实际上是无
页面置换


--- Page 203 ---
182
计算机操作系统 （慕课版）
法实现的，我们可以将其作为标准来评价其他算法的优劣。先进先出页面置换算法是最直观的
算法，由于与通常的页面使用规律不符，可能是性能最差的算法，故实际应用极少。
1．最佳页面置换算法
最佳（optimal， OPT）页面置换算法是由贝莱迪（Belady）于1966年提出的一种理论上的
算法。其所选择的被淘汰页面，将是以后永不使用的或在（未来）最长时间内不会被访问的页
面。采用最佳页面置换算法通常可保证获得最低的缺页率。但由于人们目前还无法预知一个进
程在内存的若干个页面中，哪个页面是在（未来）最长时间内不会被访问的，因此该算法是无
法实现的，但可以利用该算法去评价其他算法，举例说明如下。
假定系统为某进程分配了三个物理块，并考虑有以下页面号引用串：
7 ，0 ，1 ，2 ，0 ，3 ，0 ，4 ，2 ，3 ，0 ，3 ，2 ，1 ，2 ，0 ，1 ，7 ，0 ，1
进程运行时，先将7 ，0，1三个页面装入内存。以后，当进程要访问页面2 时，会产生缺
页中断，此时OS根据最佳页面置换算法，将选择页面7 予以淘汰。这是因为页面0 将作为第5
个被访问的页面，页面1 将作为第14个被访问的页面，而页面7 则要在第18次页面访问时才调
入。下次访问页面0 时，因它已在内存而不必产生缺页中断。当进程访问页面3 时，又将引起
页面1被淘汰；因为，它在现有的 2，0，1三个页面中将是以后最晚才被访问的。图 6-4所示为
采用最佳页面置换算法时的置换图。从图中可以看出，采用最佳页面置换算法发生了6 次页面
置换。
7
7
7
0
7
0
1
7
0
1
2
0
1
2
0
3
2
4
3
2
0
3
2
0
1
0
1
2
0
3
0
4
2
3
0
3
2
1
2
0
1
7
0
1
图6-4  采用最佳页面置换算法时的置换图
2．先进先出页面置换算法
先进先出（first in first out， FIFO）页面置换算法是最早出现的页面置换算法。该算法总
是会淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。该算法实现简
单，只要把进程已调入内存的页面按先后次序链接成一个队列，并设置一个指针（称为替换指
针），使它总是指向最老的页面。但该算法与进程实际运行的规律不相适应，因为在进程中，
有些页面（如含有全局变量、常用函数、例程等的页面）会经常被访问，而FIFO 页面置换算法
并不能保证这些页面不被淘汰。
这里，我们仍用介绍最佳页面置换算法时所讲的例子，但采用FIFO页面置换算法进行页面
置换（见图6-5）。当进程第一次访问页面2 时，将把页面7换出，因为它是最先被调入内存的；
在第一次访问页面3时，又将把页面0换出，因为它在现有的2, 0, 1三个页面中是最老的页。从图
6-5中可以看出，采用FIFO页面置换算法时进行了12次页面置换，比最佳页面置换算法正好多  
一倍。
7
0
1
2
0
3
0
4
2
3
0
3
2
1
2
0
1
7
0
1
7
0
1
2
0
1
2
3
1
2
3
0
4
3
0
4
2
0
4
2
3
0
2
3
0
1
3
0
1
2
7
1
2
7
0
2
7
0
1
7
0
7
图6-5  采用FIFO页面置换算法时的置换图

--- Page 204 ---
183
第
6章 
虚拟存储器
6.3.2 最近最久未使用页面置换算法和最少使用页面置换算法
1．最近最久未使用页面置换算法介绍
FIFO页面置换算法的性能之所以较差，是因为它所依据的条件是各个页面调入内存的时
间，但是页面调入的先后顺序其实并不能反映页面的使用情况。最近最久未使用（least recently 
used，LRU）页面置换算法，是根据页面调入内存后的使用情况来做决策的。由于无法预测各
页面将来的使用情况，只能将“最近的过去”作为“最近的将来”的近似，因此，LRU页面置
换算法会选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录
一个页面自上次被访问以来所经历的时间 t。当须淘汰一个页面时，选择现有页面中 t值最大的
（即最近最久未使用的）页面予以淘汰。
利用LRU页面置换算法对6.3.1小节中所讲例子进行页面置换的结果如图6-6所示。当进程第
一次对页面2进行访问时，由于页面7 是最近最久未被访问的，故将它置换出去。当进程第一次
对页面3进行访问时，第1 页成为最近最久未使用的页，故将它换出。从图6-6中可以看出，前5
个时间的图像与采用最佳页面置换算法时的相同，但这并非是必然的结果，因为最佳页面置换
算法是从“向后看”的观点出发的，即它依据的是以后各页的使用情况；而LRU页面置换算法
则是“向前看”的，即其会根据各页以前的使用情况来判断，而页面过去和未来的走向之间并
无必然的联系。
7
7
7
0
7
0
1
1
0
7
1
0
2
2
0
1
2
0
3
4
0
3
4
0
2
0
3
2
4
3
2
1
3
2
0
1
2
0
3
0
4
2
3
0
3
2
1
2
0
1
7
0
1
图6-6  采用LRU页面置换算法时的置换图
2．LRU 页面置换算法的硬件支持
LRU页面置换算法虽然是一种比较好的算法，但要求系统提供较多的硬件支持。为了了解
一个进程在内存中的各个页面各有多少时间未被进程访问，以及如何快速地知道哪一页是最近
最久未使用的页面，须有以下两类硬件之一的支持。
（1）寄存器。
为了记录某进程在内存中各页的使用情况，须为内存中的每个页面配置一个移位寄存器。
该寄存器可表示为：
R=Rn-1Rn-2Rn-3 … R2R1R0。
当进程访问某物理块时，要将相应寄存器的Rn-1位置成1。此时，定时信号将每隔一定的时间
（如100ms）就使寄存器右移一位。如果把n位寄存器的数看作一个整数，那么，具有最小数值的寄
存器所对应的页面，就是最近最久未使用的页面。图6-7所示为某进程在内存中具有8个页面，且为
每个页面配置一个8位寄存器时的LRU访问情况。这里，把内存中的8个页面的序号分别定为1～8。
从图6-7中可以看出，第3个内存页面的R值最小，当发生缺页时，首先会将它置换出去。
（2）栈。
可利用一个特殊的栈，保存当前使用的各个页面的页面号。每当进程访问某页面时，便将
该页面的页面号从栈中移出，并压入栈顶。因此，栈顶始终是最新被访问页面的页面号，而栈
底则是最近最久未使用页面的页面号。假定现有一进程，它分到了五个物理块，所访问的页面
的页面号序列如下所示：
4 ，7 ，0 ，7 ，1 ，0 ，1 ，2 ，1 ，2 ，6

--- Page 205 ---
184
计算机操作系统 （慕课版）
页面
R7
1
2
3
4
5
6
7
8
0
1
0
0
1
0
0
0
1
0
0
1
1
0
0
1
0
1
0
1
0
1
0
1
1
0
0
0
1
0
0
0
0
1
0
1
0
1
0
1
0
1
1
0
1
0
1
1
1
0
0
1
1
1
1
0
0
0
0
1
0
1
1
1
R6
R5
R4
R3
R2
R1
R0
图6-7  某进程具有8个页面时的LRU访问情况
在前三次访问时，系统会依次将4 、7、0放入栈中，栈底是4 ，栈顶是0；第四次是访问第7
页，会使栈顶变为7 。在第八次访问页面2 后，该进程的五个物理块都已装满，在第九次和第十
次访问时，未发生缺页。在第十一次访问页面6 时发生了缺页，此时页面4 是最近最久未被访问
的页，故将它置换出去。随着进程的访问，栈中页面号的变化情况如图6-8所示。
4 7 0 7 1 0 1 2 1 2 6
6
2
1
0
7
2
1
0
7
4
2
1
0
7
4
1
0
7
4
1
7
0
4
7
0
4
0
7
4
7
44
0
1
7
4
1
2
0
7
4
图6-8  用栈保存当前使用页面时栈的变化情况
3．最少使用页面置换算法
在采用最少使用（least frequently used， LFU）页面置换算法时，应为内存中的每个页面
设置一个移位寄存器，用来记录该页面被访问的频率。该页面置换算法会将在最近时期使用最
少的页面作为淘汰页。由于存储器具有较高的访问速度，如每次访问用时100ns，则在1ms的时
间内可能对某页面连续访问成千上万次，因此，直接利用计数器来记录某页面被访问的次数是
不现实的，只能采用较大的时间间隔来记录对存储器某页面的访问。 LFU页面置换算法采用了
移位寄存器方式。每次访问某页面时，便将该移位寄存器的最高位置1 ，再每隔一定时间（如
100ms）右移一次。这样，在最近一段时间内使用最少的页面将是 ∑Ri最小的页面。LFU页面置
换算法的页面访问图，与LRU页面置换算法的页面访问图完全相同；或者说，利用这样一套硬
件既可实现LRU页面置换算法，又可实现LFU页面置换算法。应该指出，LFU页面置换算法并不
能真正反映页面的使用情况，因为在每一时间间隔内，只是用寄存器的一位来记录页面的使用
情况，所以在该时间间隔内，对某页访问1次和访问1 000次是完全等效的。
6.3.3 Clock 页面置换算法
虽然LRU页面置换算法是一种较好的算法，但由于它要求有较多的硬件支持，其实现所需
的成本较高，故在实际应用中大多采用LRU页面置换算法的近似算法。Clock页面置换算法就是
用得较多的一种LRU页面置换算法的近似算法。
1．简单的 Clock 页面置换算法
当利用简单的Clock页面置换算法时，只要为每页设置一个访问位，再将内存中的所有页面
都通过链接指针链接成一个循环队列即可。当某页被访问时，其访问位被置1 。Clock页面置换

--- Page 206 ---
185
第
6章 
虚拟存储器
算法在选择一页进行淘汰时，只要检查页的访问位。如果是0 ，就选择该页换出；如果是1 ，则
重新将它置为0，暂不换出，给予该页第二次驻留内存的机会，再按照FIFO页面置换算法检查下
一个页面。当检查到队列中的最后一个页面时，若其访问位仍为1 ，则再返回队首去检查第一个
页面。图6-9所示为简单Clock页面置换算法的流程和示例。由于该算法循环检查各页面的使用
情况，故称之为Clock页面置换算法。但因该算法只有一个访问位，只能用它表示该页是否已经
使用过，而置换时是将未使用过的页面换出，故又将该算法称为最近未用（ not recently used，
NRU）页面置换算法或二次机会页面置换算法。
入口
返回
是
否
将该页面的
访问位置为“0”
令查寻指针前进一步，
以指向下一个表目
选择该页面并将其换出
页面访问位=0？
块号
0
1
2
3
4
5
6
7
4
2
5
1
0
1
0
1
页号
访问位
指针
替换
指针
图6-9  简单Clock页面置换算法的流程和示例
2．改进型 Clock 页面置换算法
在将一个页面换出时，如果该页已被修改过，则须将该页重新写回到磁盘上；但如果该页
未被修改过，则不必将其重新写回磁盘。换言之，对于修改过的页面，在换出时所付出的开销
比未修改过的页面的大，或者说置换代价大。在改进型Clock页面置换算法中，除须考虑页面的
使用情况外，还须再增加一个需要考虑的因素——置换代价。这样，选择页面换出时，既要是
未使用过的页面，又要是未被修改过的页面，将同时满足这两个条件的页面作为首选淘汰的页
面。由访问位A和修改位M可以组合成下面4种类型的页面。
第1类（A=0，M=0）：表示该页最近既未被访问，又未被修改，是最佳淘汰页。
第2类（A=0，M=1）：表示该页最近未被访问，但已被修改，并不是很好的淘汰页。
第3类（A=1，M=0）：表示该页最近已被访问，但未被修改，该页有可能再被访问。
第4类（A=1，M=1）：表示该页最近已被访问且被修改，该页有可能再被访问。
内存中的每个页都必定是这四类页面之一。在进行页面置换时，可采用与简单Clock页面置
换算法类似的改进型Clock页面置换算法，它们的差别在于该算法须同时检查访问位与修改位，
以确定该页是4类页面中的哪一类。其执行过程可分成以下3步。
（1）从指针所指示的当前位置开始，扫描循环队列，寻找A=0且 M=0的第一类页面，将所
遇到的第一个此类页面作为所选中的淘汰页。在第一次扫描期间不改变访问位A。
（2）如果第一步失败，即查找一轮后未遇到第一类页面，则开始第二轮扫描，寻找A=0且
M=1的第二类页面，并将所遇到的第一个此类页面作为淘汰页。在第二轮扫描期间，将所有扫
描过的页面的访问位都置0。
（3）如果第二步也失败，亦即未找到第二类页面，则将指针返回到开始的位置，并将所有
的访问位复0。然后重复第一步，即寻找A=0且 M=0的第一类页面，如果仍失败，则必要时再重
复第二步，寻找A=0且M=1的第二类页面，此时一定能找到可被淘汰的页。
改进型Clock页面置换算法与简单Clock页面置换算法相比，可减少磁盘的I/O操作次数。但为
了找到一个可置换的页，可能需要经过几轮扫描。换言之，实现该算法本身开销将有所增加。

--- Page 207 ---
186
计算机操作系统 （慕课版）
6.3.4 页面缓冲算法
在请求分页系统中，由于进程在运行时经常会发生页面换入/ 换出的情况，所以一个十分明
显的事实是，页面换入/ 换出所付出的开销将对系统性能产生重大影响。在此，我们首先对影响
页面换入/换出效率的若干因素进行分析。
1．影响页面换入 / 换出效率的若干因素
影响页面换入/换出效率的因素有很多，其中包括：对页面进行置换的算法，将已修改页面
写回磁盘的频率，以及将磁盘内容读入内存的频率。
（1）页面置换算法 。影响页面换入/ 换出效率最重要的因素，无疑是页面置换算法。因为
一个好的页面置换算法，可使进程在运行过程中具有较低的缺页率，从而可以减少页面换入/ 换
出的开销。正因如此，才会有许多学者去研究页面置换算法，相应地也就出现了大量的页面置
换算法，在前文中已对主要的页面置换算法做了介绍。
（2）写回磁盘的频率 。对于已经被修改过的页面，在将其换出时，应当写回磁盘。如果
采取每当有一个页面要被换出时，就将它写回磁盘的策略，则意味着每换出一个页面就需要启
动一次磁盘。但如果在系统中已建立了一个已修改换出页面链表，则针对每个要被换出的页面
（已修改），系统可暂不把它们写回磁盘，而是将它们挂在已修改换出页面链表上，仅当被换
出页面数目达到一定值（如64）时，再将它们一起写回到磁盘上，这样就显著地减少了磁盘I/O
的操作次数，或者说，减少了已修改页面换出的开销。
（3）读入内存的频率。在设置了已修改换出页面链表后，在该链表上就暂时有了一批装有
数据的页面，如果有进程在这批数据还未写回磁盘时需要再次访问这些页面，则无须从磁盘上
调入，而可直接从已修改换出页面链表中获取，这样不仅可以降低将页面从磁盘读入内存的频
率，而且可以减少页面换入的开销。或者说，只须花费很小的开销，便可使这些页面又回到该
进程的驻留集中。
2．页面缓冲算法
页面缓冲算法（page buffering algorithm， PBA）就是采用上述思想，在原页面置换算
法的基础上增设已修改页面链表，保存已修改且需要被换出的页面，等被换出的页面数目达
到一定值时，再一起换出至磁盘，以达到减少页面换出开销的目的。页面缓冲算法的主要特
点是：①显著地降低了页面换入/ 换出的频率，使磁盘I/O的操作次数大为减少，因而减小了
页面换入/ 换出的开销；②正是由于换入/ 换出的开销大幅度减小，其采用一种较简单的置换
策略（如FIFO页面置换算法）时不需要特殊硬件的支持，实现起来非常简单。页面缓冲算
法已在不少系统中被采用，下面介绍V AX/VMS系统中所使用的页面缓冲算法。在该系统的
内存分配策略中采用了可变分配局部置换方式，系统为每个进程分配一定数目的物理块，系
统自己保留一部分空闲物理块。为了能显著地降低页面换入/ 换出的频率，在内存中设置了
以下两个链表。
（1）空闲页面链表 。实际上空闲页面链表是一个空闲物理块链表，这些系统掌握的空
闲物理块用于分配给频繁发生缺页的进程，以降低这些进程的缺页率。当这些进程需要读入
一个页面时，它们便可利用空闲物理块链表中的第一个物理块来装入该页。当有一个未被修
改的页面要换出时，实际上并不将它换出到磁盘，而是将它所在的物理块挂在空闲链表的末
尾。应当注意，这些挂在空闲链表中的、未被修改的页面中是有数据的，如果以后某进程需
要这些页面中的数据，则可从空闲链表上将它们取下，这免除了从磁盘读入数据的操作，减

--- Page 208 ---
187
第
6章 
虚拟存储器
少了页面换入的开销。
（2）修改页面链表。修改页面链表是由已修改的页面所形成的链表。设置该链表的目的是
减少已修改页面换出的次数。当进程需要将一个已修改的页面换出时，系统并不会立即把它换
出到磁盘上，而是会将它所在的物理块挂在修改页面链表的末尾。这样做的目的是降低将已修
改页面写回磁盘的频率，进而降低将磁盘内容读入内存的频率。
6.3.5 请求分页系统的内存有效访问时间
与基本分页存储管理方式不同，在请求分页管理方式中，内存的有效访问时间不仅要考虑
访问页表和访问实际物理地址数据的时间，还要考虑缺页中断的处理时间。这样，在具有快表
机制的请求分页管理方式中，就会存在下面3 种方式的内存访问操作，它们所对应的有效访问时
间的计算公式也有所不同。
（1）被访问页在内存中，且其对应的页表项在快表中。
显然，此时不存在缺页中断情况，内存的有效访问时间分为查找快表时间和访问实际物理
地址时间，即有：
EAT=λ+t，
上式中，λ为查找快表所需要的时间，t 为访问一次内存所需要的时间。
（2）被访问页在内存中，且其对应的页表项不在快表中。
显然，此时也不存在缺页中断情况，但需要访问内存两次，一次读取页表，另一次读取数
据；另外还需要更新快表。因此，这种情况下内存的有效访问时间可分为查找快表时间、查找
页表时间、修改快表时间和访问实际物理地址时间，即有：
EAT=λ+t+λ+t =2×（λ+t）。
（3）被访问页不在内存中。
因为当被访问页不在内存中时，需要进行缺页中断处理，所以在这种情况下，内存的有效
访问时间可分为查找快表时间、查找页表时间、处理缺页中断时间、更新快表时间和访问实际
物理地址时间。假设缺页中断处理时间为ε，则有：
EAT=λ+t+ε+λ+t=ε+2×（λ+t）。
针对上述3种情况的讨论，没有考虑快表的命中率和缺页率等因素。加入这两个因素后，内
存的有效访问时间计算公式变为：
EAT=λ+а×t+（1–а）×[t+f×（ε+λ+t）+（1-f）×（λ+t）]，
上式中，а表示命中率，f 表示缺页率。 如果不考虑命中率而仅考虑缺页率， 即上式中的λ=0 且
а=0，则 有 ：
EAT=t+f×（ε+t）+（1-f）×t。
6.4 “抖动”与工作集
由于请求分页式虚拟存储器系统的性能优越，在正常运行的情况下，它能有效减少内部碎
片，提高处理机的利用率和系统吞吐量，故是目前最常用的一种系统。但如果在系统中运行的
进程太多，进程在运行中频繁地发生缺页情况，则其会对系统的性能产生很大影响，故还需要
对请求分页系统的性能做简单的分析。

--- Page 209 ---
188
计算机操作系统 （慕课版）
6.4.1 多道程序度与“抖动”
1．多道程序度与处理机的利用率
由于虚拟存储器系统能从逻辑上扩大内存，这时，只要装入一个进程的部分程序和数
据，进程便可开始运行，故人们希望在系统中能运行更多的进程，即增加多道程序度（道
数）以提高处理机的利用率。但处理机实际的利用率却如图6-10中的实线所示，其中横轴表示
进程数量，纵轴表示相应的处理机利用率。在横轴的开始部分，随着进程数量的增加，处理
机的利用率急剧增加；但当到达 N1时，其增速就明显减慢了；当到达 Nmax时，处理机的利用率
达到最大，以后先开始缓慢下降，当到达 N2时，若再继续增加进程数，利用率将会加速下降而
趋于0，如图6-10中的 N3点。之所以会发生在后面阶段利用率趋于0 的情况，是因为在系统中已
发生了“抖动”。
处理机利用率
进程数量
抖动
CPU饱和度
N1
O
Nmax N2 N3
L/S
100%
图6-10  处理机利用率与进程数量之间的关系
2．产生“抖动”的原因
产生“抖动”的根本原因是，同时在系统中运行的进程太多，导致分配给每个进程的物理
块太少，不能满足进程正常运行的基本要求，致使每个进程在运行时会频繁地出现缺页，必须
请求系统将所缺之页调入内存。这会使得在系统中排队等待页面换入/ 换出的进程数量增加。显
然，对磁盘的有效访问时间也会随之急剧增加，造成每个进程的大部分时间都用于页面的换入/
换出，而几乎不能再去做任何有效的工作，从而导致发生处理机的利用率急剧下降而趋于0 的情
况。我们称此时的进程处于“抖动”状态。
“抖动”是在进程运行中出现的严重问题，必须采取相应的措施来解决它。为此，有不少
学者对它进行了深入研究，并提出了许多非常有效的解决方法。由于“抖动”的发生与系统为
进程分配物理块的多少有关，因此有人提出了关于进程“工作集”的概念。
6.4.2 工作集
1．工作集的基本概念
进程发生缺页率的时间间隔与进程所获得的物理块数有关。图6-11所示为缺页率与物理块
数之间的关系。从图6-11中可以看出，缺页率随着所分配物理块数的增加而明显减小，当物理
块数超过某个数目时，再为进程增加一个物理块，则其对缺页率的改善不会很明显。可见，此
时已无必要再为它分配更多的物理块。当为某进程所分配的物理块数低于某个数目时，每减少

--- Page 210 ---
189
第
6章 
虚拟存储器
一个物理块对缺页率的影响都会十分明显，此时又应为该进程分配更多的物理块。为了能清楚
地说明形成图6-11所示曲线的原因，还须先介绍“工作集”的概念。
缺页率
物理块数n
下限
上限
O
图6-11  缺页率与物理块数之间的关系
关于工作集的理论是1968年由布兰农 ·邓宁提出并推广的。他认为，基于程序运行时的局
部性原理，可以得知程序在运行期间对页面的访问是不均匀的，在一段时间内仅局限于较少的
页面，而在另一段时间内又可能会局限于对另一些较少的页面进行访问。这些页面被称为活跃
页面。如果能够预知程序在某段时间间隔内要访问哪些页面，并将它们调入内存，则将大大降
低缺页率，从而可以显著提高处理机的利用率。
2．工作集的定义
所谓工作集，是指在某段时间间隔Δ中进程实际要访问页面的集合。布兰农·邓宁指出，虽
然程序只需要少量的几页在内存中便可运行，但为了较少地产生缺页，应使程序的全部工作集
装入内存中。然而我们无法事先预知程序在不同时刻将访问哪些页面，故仍只有像页面置换算
法那样，将程序在过去某段时间内的行为作为程序在将来某段时间内行为的近似。具体来说，
是把某进程在时间t的工作集记为w（t, Δ），其中的变量Δ称为工作集的“窗口尺寸”（windows 
size）。图6-12所示为某进程访问页面的序列和窗口大小分别为3, 4, 5时的工作集。由此可将工
作集定义为，进程在时间间隔（t-Δ, t）中引用页面的集合。
窗口大小
访问页面序列
24 24
15   24
18   15   24
23   18   15
24   23   18
17   24   23
18   17   24
15   17   18
24   15   17
18   24   17
—
—
—
—
—
—
24
15   24
18   15   24
23   18   15   24
—
17   24   23   18
—
15   17   18   24
—
—
—
—
—
—
—
—
24
15   24
18   15   24
23   18   15   24
—
17   24   23   18   15
—
—
—
—
—
—
—
—
—
—
15
18
23
24
17
18
24
18
17
17
15
24
17
24
18
3 4 5
（a）序列                             （b）工作集
图6-12  某进程访问页面的序列和窗口大小分别为3, 4, 5时的工作集
工作集w（t, Δ）是二元函数，即在不同时间t的工作集大小不同，所含的页面数也不同，与
窗口尺寸Δ有关。工作集大小是窗口尺寸Δ的非降函数（non-decreasing function），从图6-12中也

--- Page 211 ---
190
计算机操作系统 （慕课版）
可看出这一点，即：
w （t，Δ）
 w （t，Δ+1）。
6.4.3 “抖动”的预防方法
为了保证系统具有较大的吞吐量，必须防止“抖动”的发生。目前已有许多防止“抖动”
发生的方法，这些方法几乎都是采用调节多道程序度来控制“抖动”发生的。下面介绍几种较
常用的预防“抖动”发生的方法。
1．采取局部置换策略
在页面分配和置换策略中，如果采取的是可变分配方式，则为了预防发生“抖动”，可
采取局部置换策略。根据这种策略，当某进程发生缺页时，只能在分配给它的内存空间内进
行置换，而不允许从其他进程的内存空间中去获得新的物理块。这样，即使该进程发生了“抖
动”，也不会对其他进程产生影响，于是可把该进程“抖动”所造成的影响限制在较小的范围
内。该方法虽然简单易行，但效果不是很好，因为在某进程发生“抖动”后，它还会长期地处
在磁盘I/O的等待队列中，使队列的长度增加，这会延长其他进程缺页中断的处理时间，也就是
会延长其他进程对磁盘的访问时间。
2．把工作集算法融入处理机调度中
当调度程序发现处理机的利用率低下时，它将试图从外存调一个新作业进入内存，以改善
处理机的利用率。如果在调度中融入了工作集算法，则在调度程序从外存调入作业之前，必须
先检查每个进程在内存中的驻留页面是否足够多。如果都已足够多，则此时便可从外存调入新
的作业，而不会因新作业的调入而导致缺页率的增加；如果有些进程的内存页面不足，则应首
先为那些缺页率居高的作业增加新的物理块，此时将不再调入新作业。
3．利用“L=S”准则调节缺页率
1980年，布兰农·邓宁提出了“L=S”准则以调节多道程序度，其中 L是缺页之间的平均时 
间，S是平均缺页服务时间，即用于置换一个页面所需的时间。如果 L远比S大，则说明很少发生
缺页，磁盘的能力尚未得到充分利用；如果 L比S小，则说明频繁发生缺页，缺页的速度已超过
磁盘的处理能力。只有当 L与S接近时，磁盘和处理机才都可达到它们最大的利用率。理论和实
践都已证明，利用“L=S”准则，对于调节缺页率是十分有效的。
4．选择暂停的进程
当多道程序度偏高且已影响到了处理机的利用率时，为了防止发生“抖动”，系统必须
减少多道程序的数量。此时，应基于某种原则选择暂停某些当前活动的进程，将它们调出到磁
盘上，以便腾出内存空间并将其分配给缺页率偏高的进程。系统通常会采取与调度程序一致的
策略，即首先选择暂停优先级最低的进程，若需要，则再选择暂停优先级较低的进程。当内存
还显拥挤时，还可进一步选择暂停一个并不十分重要但却较大的进程（以便释放出较多的物理
块）或者剩余执行时间最多的进程等。
请思考请求分页与交换的区别和联系。
思考题

--- Page 212 ---
191
第
6章 
虚拟存储器
6.5 请求分段存储管理方式
在分页基础上建立的请求分页式虚拟存储器系统，是以页面为单位进行换入/ 换出的。而
在分段基础上所建立的请求分段式虚拟存储器系统，则是以分段为单位进行换入/ 换出的。它们
在实现原理以及所需要的硬件支持上都是十分相似的。在请求分段系统中，程序运行之前只要
先调入少数几个分段（不必调入所有分段），便可启动运行。当所访问的段不在内存中时，可
请求OS将所缺的段调入内存。像请求分页式虚拟存储器系统一样，为实现请求分段存储管理方
式，同样需要一定的硬件支持和相应的软件。
6.5.1 请求分段中的硬件支持
为了实现请求分段存储管理，应在系统中配置多种硬件机构，以支持快速完成请求分段功
能。与请求分页系统相似，在请求分段系统中所需的硬件支持有：请求段表机制，缺段中断机
构，以及地址变换机构。
1．请求段表机制
在请求分段存储管理中所需的主要数据结构是请求段表。该段表中除了具有请求分页机制
中所具有的访问字段A、修改位M、存在位P和外存地址这4个字段外，还增加了存取方式和增补
位这2个字段。这些字段供程序在换入/换出时参考。下面所示为请求段表的段表项。
段名 段长 段的起始地址 存取方式 访问字段A 修改位M 存在位P 增补位 外存地址
在段表项中，除了段名（号）、段长、段在内存中的起始地址外，还增加了以下字段。
（1）存取方式。由于在应用程序中的段是信息的逻辑单位，可根据该信息的属性对它实施
保护，故在段表中增加了存取方式字段。如果该字段为两位，则存取属性可以是只执行、只读
或允许读/写。
（2）访问字段A。其含义与请求分页的相应字段相同，用于记录该段被访问的频繁程度。
其可供页面置换算法在选择换出页面时参考。
（3）修改位M。用于表示该段在进入内存后是否已被修改过，供置换段时参考。
（4）存在位P。用于表示该段是否已调入内存，供程序访问时参考。
（5）增补位。增补位是请求分段存储管理中所特有的字段，用于表示该段在运行过程中是
否做过动态增长。
（6）外存地址。用于表示该段在外存中的起始地址，即起始盘块号。
2．缺段中断机构
在请求分段系统中，采用的是请求调段策略。每当发现运行进程所要访问的段尚未调入内
存时，便由缺段中断机构产生一个缺段中断信号，进入OS后，由缺段中断处理程序将所需的段
调入内存。与缺页中断机构类似，缺段中断机构同样需要在一条指令的执行期间产生和处理中
断，同时，在一条指令执行期间也可能会产生多次缺段中断。但是，由于分段是信息的逻辑单
位，因此不可能出现一条指令被分割在两个分段中以及一组信息被分割在两个分段中的情况。
缺段中断的处理过程如图6-13所示。由于段不是定长的，因此对缺段中断的处理要比对缺页中
断的处理复杂。

--- Page 213 ---
192
计算机操作系统 （慕课版）
虚段S不在内存中
阻塞请求进程
从外存读入虚段S
修改段表及内存空区链
唤醒请求进程
返回
内存中是否
有合适的空区?
内存中所有空区
之和≥S?
拼接空区，以形成
一个合适的空区
淘汰一个或几个实段，
以形成一个合适的空区
是
是
否
否
图6-13  请求分段系统中的缺段中断处理过程
3．地址变换机构
请求分段系统中的地址变换机构，是在分段系统地址变换机构的基础上形成的。因为被访问
的段并非全在内存中，所以在进行地址变换时，若发现所要访问的段不在内存中，则必须先将所
缺的段调入内存，并修改段表，然后才能利用段表进行地址变换。为此，在地址变换机构中又增
加了某些功能，如缺段中断的请求与处理等。图6-14所示为请求分段系统的地址变换过程。
访问[s][w]
访问[A]
是否符合存取方式？
虚段S是否在内存中？
是
是
是
否
否
否
分段越界
中断处理
分段保护
中断处理
缺段
中断处理
w≤段长？
修改访问字段，如写访问，置修改位=1
形成访问内存地址（A）=（内存起始地址s）+（位移量w）
图6-14  请求分段系统的地址变换过程
6.5.2 分段的共享与保护
在5.6节中曾介绍过分段存储管理方式的优点：便于实现分段的共享与保护。此外，也扼要
地介绍过实现分段共享的方法。本小节将进一步介绍为了实现分段共享，还应配置相应的数据
结构——共享段表，并对表中的共享段进行操作。
1．共享段表
为了实现分段共享，可在系统中配置一张共享段表，所有共享段都在共享段表中占有一表
项。在表项的上面记录了共享段的段名（号）、段长、内存起始地址、状态（存在）位、外存

--- Page 214 ---
193
第
6章 
虚拟存储器
起始地址以及共享进程计数count等信息。接下去记录了共享此分段的每个进程的情况。共享段
表如图6-15所示，其中部分项的说明如下。
共享段表
段名
段长
内存起始地址
外存起始地址
状态位
状态
进程名
进程号
共享进程记数count
…
…
…
…
…
存取控制
段号
…
图6-15  共享段表
（1）共享进程计数count 。非共享段仅为一个进程所需要。当进程不再需要该段时，可立
即释放该段，并由系统回收该段所占用的空间。而共享段是为多个进程所需要的，为记录有多
少进程正在共享该分段，须设置共享进程计数count。当某进程不再需要而释放它后，系统并不
会立即回收该段所占的内存区，而是会检查count 是否为0。若不是0，则表示还有进程需要它，
仅当所有共享该段的进程全都不再需要它（count为0）时，系统才会回收该段所占的内存区。
（2）存取控制。对于一个共享段，其应为不同的进程赋予不同的存取权限。例如，对于主
进程，通常会允许它读和写；而对于其他进程，则可能只允许它们读或执行。
（3）段号。对于一个共享段，在不同的进程中其可以具有不同的段号。每个进程均可用自
己进程的段号去访问该共享段。
2．共享段的分配与回收
（1）共享段的分配。由于共享段是供多个进程所共享的，因此，共享段的内存分配方法与
非共享段的内存分配方法有所不同。在为共享段分配内存时，对于第一个请求使用该共享段的进
程，系统会为该共享段分配一物理区，再把共享段调入该区，同时将该区的起始地址填入请求进
程的段表的相应项中，还须在共享段表中增加一表项，填写请求使用该共享段的进程名、段号和
存取控制字段等有关数据，把count置为1。当又有其他进程需要调用该共享段时，由于该共享段
已被调入内存，故此时无须再为该共享段分配内存，而只要在调用进程的段表中增加一表项，填
写该共享段的物理地址即可。在共享段的段表中增加一个表项，填上调用进程的进程名、该共享
段在本进程中的段号、存取控制字段等，再执行count=count+1操作，以表明有两个进程共享该共
享段。以后，凡有进程需要访问该共享段，都按上述方式在共享段的段表中增加一个表项。
（2）共享段的回收。当共享此段的某进程不再需要该段时，应将该段释放，包括撤销在该
进程段表中共享段所对应的表项，并执行count=count -1操作。若结果为0，则须由系统回收该共
享段的物理内存，并取消共享段表中该段所对应的表项，表明此时已没有进程使用该段；否则
（减1后结果不为0），只取消调用者进程在共享段表中的有关记录。
3．分段保护
在分段系统中，由于每个分段在逻辑上都是相对独立的，因而比较容易实现信息保护。目
前，通常会采用以下几种措施来确保信息的安全。
（1）越界检查。越界检查是利用地址变换机构来完成的。为此，在地址变换机构中设置了
段表寄存器，用于存放段表起始地址和段表长度信息。在进行地址变换时，首先将逻辑地址空
间的段号与段表长度进行比较，如果段号大于或等于段表长度，则发出地址越界中断信号。此
外，还须在段表中为每个段设置段长字段；在进行地址变换时，还要检查段内地址是否大于或

--- Page 215 ---
194
计算机操作系统 （慕课版）
等于段长，若是，则产生地址越界中断信号，从而保证了每个进程只能在自己的地址空间运行。
（2）存取控制检查 。存取控制检查是以段为基本单位进行的。为此，在段表的每个表项
中，都设置了一个“存取控制”字段，用于规定对该段的访问方式。通常的访问方式有：①只
读，即只允许进程对该段中的程序或数据进行读访问；②只执行，即只允许进程调用该段去执
行，但不允许读该段的内容，更不允许对该段的内容执行写操作；③读/ 写，即允许进程对该段
进行读/写访问。对于共享段，存取控制显得尤为重要，因此应为不同的进程赋予不同的读/ 写
权限。这时，既要保证信息的安全性，又要满足运行需要。例如，对于一个企业的财务账目，
应该只允许会计人员对其进行读或写，允许领导及有关人员去读。而对于一般人员，则既不准
读，更不准写。值得一提的是，这里所介绍的存取控制检查是基于硬件实现的，它能较好地保
证信息的安全，因为攻击者很难对存取控制字段进行修改。
（3）环保护机构。这是一种功能较完善的保护机制。该机制规定：低编号的环具有高优先  
权。OS核心处于0 号环内，某些重要的实用程序和OS服务占居中间环，而一般的应用程序则被
安排在外环上。在环系统中，程序的访问和调用应遵循以下规则：①一个程序可以调用驻留在
相同环或较高特权环（内环）中的服务；②一个程序可以访问驻留在相同环或较低特权环（外
环）中的数据。图6-16所示为环保护机构中程序调用与数据访问的关系。
环0
调用 返回
调用 访问
访问返回
（a）程序调用 （b）数据访问
环0
环1
环2
环1
环2
图6-16  环保护机构中程序调用与数据访问的关系
6.6 虚拟存储器实现实例
本节将分别讨论在Windows XP和Linux系统中如何实现虚拟存储器。
6.6.1 实例 1 ： 在 Windows XP 系统中实现虚拟存储器
Windows XP系统采用请求页面调度以及簇（clustering）来实现虚拟存储器。簇在处理缺页
中断时，不但会调入不在内存中的页（出错页），还会调入出错页周围的页。在创建一个进程
时，系统会为该新进程分配工作集的最小值和最大值。工作集的最小值是进程在内存中时所保
证有的页面数的最小值。如果有足够多的内存可用，那么进程就可分配更多的页面，直至达到
其工作集的最大值。对于大部分应用程序，工作集的（页面数的）最小值和最大值是50和 345 
（在有些环境下，进程允许页面数超过其工作集的最大值）。
另外，虚拟存储器管理器会维护一个空闲帧的链表，与该链表相关联的一个阈值，可用
于表示是否有足够多的可用内存。如果一个进程的页面数低于其工作集的最大值且出现缺页情
况，那么虚拟存储器管理器就可以从该空闲链表上分配帧。如果一个进程的页面数已达到其工
作集的最大值且出现缺页情况，那么虚拟存储器管理器就会采用局部置换方式来选择置换页。
当空闲内存的量低于其阈值时，虚拟存储器管理器就会采用自动工作集进行修整，以使该
值在其阈值之上。自动工作集的修整方式为：计算分配给进程的内存物理块数，如果进程所分

--- Page 216 ---
195
第
6章 
虚拟存储器
配的物理块数大于其工作集的最小值，那么虚拟存储器管理器就会从中删除物理块，直到进程
的页面数等于其工作集的最小值。一旦有了足够多的空闲内存，具有工作集的最小值页面数的
进程就会从空闲块中分配物理块。
用于确定从哪个工作集中删除页的算法与OS所运行的处理机的类型有关。对于单处理机
80x86系统，Windows XP使用了6.3.3小节所介绍的改进型Clock页面置换算法。对于Alpha系统
和多处理机80x86系统，清除引用位需要使其他处理机的转译后备缓冲器（translation lookaside 
buffer，TLB）内容失效。为了避免这种开销，Windows XP使用了6.3.1小节所介绍的FIFO页面置
换算法的一个变种。
6.6.2 实例 2 ： 在 Linux 系统中实现虚拟存储器
Linux系统采用虚拟存储器管理技术，使得每个进程都有各自互不干涉的地址空间。以32位
为例，该空间是块大小为4GB的线性虚拟空间，用户所看到和接触到的都是该虚拟地址，而无
法看到实际的物理内存地址。
在Linux系统中，4GB的进程地址空间被人为地分为两个部分：用户空间与内核空间。用户
空间占据0～3GB（0xC0000000），内核空间占据3GB ～4GB。用户进程通常情况下只能访问用
户空间的虚拟地址，而不能访问内核空间的虚拟地址。用户进程只有在进行系统调用（代表用
户进程在内核态执行）等时，才可以访问到内核空间。用户空间对应进程，因此每当进行进程
切换时，用户空间就会跟着变化；而内核空间是由内核负责映射的，它并不会跟着进程改变，
换言之，它是固定的。内核空间地址有自己对应的页表，而用户进程则各自有不同的页表。
Linux系统中用户空间的管理策略，请参见5.7节的内容。Linux系统的内核空间主要有两
种内存分配算法，即伙伴（buddy）和slab分配，两者可结合使用。buddy提供了2 的幂大小内
存块的分配方法，具有数组特性，简单高效；缺点是存在内部碎片。slab提供了小对象的内存
分配方法，其实际上是一个多级缓存列表，最小的分配单位称为一个slab（一个或者多个连续  
页），其被分配给多个对象共用。
Linux系统中虚拟存储器的具体管理示意如图6-17所示，图中的虚框表示Linux系统中的虚拟
存储器子系统，其除了可管理用户空间的MMU外，还包含面向内核内存管理的zoned buddy分配
器和slab分配器。
通用C库
（glibc）
内核
子系统
slab
分配器 物理
内存
磁盘
驱动 磁盘
虚拟存储器子系统
kswapd
MMU
zoned
buddy
分配器
bdflush
图6-17  Linux系统中虚拟存储器的具体管理示意

--- Page 217 ---
196
计算机操作系统 （慕课版）
在虚拟存储器管理子系统中， kswapd 是一个后台 daemon 进程，负责对系统内存做定时检
查，一般是 1s一次。如果发现没有足够的空闲页面，就进行页回收操作，将不再使用的页面
换出。如果要换出的页面脏（被修改过）了，则还需要将这个页面写回到磁盘或者交换分区
swap中。
bdflush也是一个后台daemon进程，负责周期性地检查脏缓冲（即磁盘缓冲），并将其写回
磁盘。不过在Linux 2.6版本之后，pdflush就取代了bdflush，前者的优势在于：可以使多个线程
并发，而bdflush只能支持单线程运行，这就保证了不会在回写繁忙时阻塞；另外，bdflush的操
作对象是缓冲，而pdflush是基于页面的，显然pdflush的效率要更高。
6.7 本章小结
用户期望能够执行逻辑地址空间大于物理地址空间的进程。虚拟存储器是一种技术，能够
将较大的逻辑地址空间映射到较小的物理内存上。虚拟存储器允许运行极大的进程，提高了多
道程序度与处理机利用率。虚拟存储器的实现通常采用请求分页存储管理方式和请求分段存储
管理方式；由于页的大小相同、管理方便，请求分页存储管理更加常用。
本章在介绍虚拟存储器的基本概念、实现原理的基础上，详细介绍了请求分页存储管理方
式，包括缺页中断、页面置换算法、系统性能分析、“抖动”和工作集等，并简要介绍了请求
分段系统的实现。围绕页面置换算法，本章详细介绍了最佳页面置换算法、FIFO页面置换算
法、LRU页面置换算法、LFU页面置换算法、Clock页面置换算法和改进型Clock页面置换算法等
的基本原理与具体实现。
习题6（含考研真题）
一、简答题
1．常规存储器管理方式具有哪两大特征？它们对系统性能有何影响？
2．什么是虚拟存储器？如何实现分页式虚拟存储器？
3．“整体对换从逻辑上也扩充了内存，因此也实现了虚拟存储器的功能”这种说法是否正
确？请说明理由。
4．在请求分页系统中，为什么说在一条指令执行期间可能产生多次缺页中断？
5．试比较缺页中断与一般的中断，它们之间有何明显区别？
6．试说明在请求分页系统中页面的调入过程。
7．（考研真题） 简述在具有快表的请求分页系统中，将逻辑地址变换为物理地址的完整  
过程。
8．何谓固定分配局部置换和可变分配全局置换的内存分配策略？
9．实现LRU页面置换算法所需要的硬件支持是什么？
10．什么是“抖动”？产生“抖动”的原因是什么？
11．何谓工作集？它是基于什么原理确定的？
12．为了实现请求分段存储管理，应在系统中增加配置哪些硬件机构？

--- Page 218 ---
197
第
6章 
虚拟存储器
二、计算题
13．（考研真题） 某虚拟存储器的用户空间共有 32个页面，每页 1KB，内存16KB 。假定
某时刻系统为用户的第0 、1、2、3页分配的物理块号为5 、10、4、7，而该用户作业的长度为6
页，试将十六进制的逻辑地址0A5C、103C、1A5C变换成物理地址。
14．某请求调页系统，页表保存在寄存器中。若一个被替换的页未被修改过，则处理一个
缺页中断需要8ms；若被替换的页已被修改过，则处理一个缺页中断需要20ms。内存存取时间
为1µs，访问页表的时间可忽略不计。假定70%被替换的页被修改过，为保证有效存取时间不超
过2µs，可接受的最大缺页率是多少？
15．（考研真题）某分页式虚拟存储系统，用于页面交换的磁盘的平均访问及传输时间是
20ms，页表保存在内存中，访问时间为1µs，即每引用一次指令或数据，就需要访问内存2 次。
为改善性能，可以增设一个联想寄存器，若页表项在联想寄存器中，则只要访问1 次内存。假设
80%的访问对应的页表项在联想寄存器中，剩下的20%中，10%的访问（即总数的2%）会产生
缺页。请计算有效访问时间。
16．假定某OS存储器采用分页存储管理方式，一个进程在快表中的页表项如表6-1所示，在
内存中的页表项如表6-2所示。
表6 -1　快表中的页表项
页号 页帧号
0 f1
1 f2
2 f3
3 f4
表6 -2　内存中的页表项
页号 页帧号
4 f5
5 f6
6 f7
7 f8
8 f9
9 f10
注：只列出不在快表中的页表项。
假定该进程长度为320B，每页32B。现有逻辑地址101 204 576 （八进制），若上述逻辑地址
能变换成物理地址，则说明变换的过程，并指出具体的物理地址；若不能变换，则说明其原因。
17．有一个矩阵int A[l00, 100]以行优先方式进行存储。计算机采用虚拟存储系统，物理内
存共有3页，其中1页用来存放程序，其余2 页用来存放数据。假设程序已在内存中占了1 页，其
余2页空闲。若每页可存放200个整数，则程序1 、程序2执行的过程中各会发生多少次缺页？每
页只能存放100个整数时，会发生多少次缺页？以上结果说明了什么问题？
   程 序 1 ：     程 序 2 ：
   for(i=0; i<100; i++)    for(j=0; j<100; j++) 
                  for(j=0; j<100; j++)        for(i=0; i<100; i++)
                          A[i, j]=0;                 A[i, j]=0;

--- Page 219 ---
198
计算机操作系统 （慕课版）
三、综合应用题
18．（考研真题）有一个请求分页式虚拟存储器系统，分配给某进程3个物理块，开始时内
存中预装入第1, 2, 3个页面，该进程的页面访问序列为1, 2, 4, 2, 6, 2, 1, 5, 6, 1。
（1）若采用最佳页面置换算法，则访问过程发生的缺页率为多少？
（2）若采用LRU页面置换算法，则访问过程中的缺页率为多少？
19．进程已分配到4 个块，如表6-3所示（编号为十进制，从0 开始）。当进程访问第4 页
时，产生缺页中断，请分别用FIFO页面置换算法和LRU页面置换算法决定缺页中断处理程序选
择换出的页面。
表6 -3 页表
块号 页号 装入时间 最近访问时间 访问位 修改位
2 0 60 161 0 1
1 1 130 160 0 0
0 2 26 162 1 0
3 3 20 163 1 1
20．某系统有4 个页，某个进程的页面使用情况如表6-4所示，问采用FIFO、 LRU、简单
Clock和改进型Clock页面置换算法，分别会置换哪一页？
表6 -4 页面使用情况
页号 装入时间 上次引用时间 R M
0 126 279 0 0
1 230 260 1 0
2 120 272 1 1
3 160 280 1 1
其中，R是读标志位，M是修改位。
21．（考研真题）在请求分页存储管理系统中，假设某进程的页表内容如表6-5所示。
表6 -5 某进程的页表内容
页号 页框号 有效位（存在位）
0 101H 1
1 — 0
2 254H 1
页面大小为4KB，一次内存的访问时间是100ns，一次TLB的访问时间是10ns，处理一次缺
页的平均时间是10
8
ns（已含更新TLB和页表的时间），进程的驻留集大小固定为2，采用LRU页
面置换算法和局部淘汰策略。假设：①TLB初始为空；②地址变换时先访问TLB，若TLB未命
中，则再访问页表（忽略访问页表之后的TLB更新时间）；③有效位为0 表示页面不在内存中，
产生缺页中断，缺页中断处理后，返回到产生缺页中断的指令处重新执行。设有虚地址访问序
列2362H、1565H、25A5H，请问：
（1）依次访问上述3个虚地址，各需要多少时间？给出计算过程。
（2）基于上述访问序列，虚地址1565H的物理地址是多少？请说明理由。

--- Page 220 ---
输入/输出系统
