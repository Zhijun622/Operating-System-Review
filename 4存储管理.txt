--- Page 1 ---
第4章  存储管理
存储器是计算机系统中的重要组成部分，功能是保存指
令和数据，它的发展方向是高速、大容量和小体积。
计算机系统内的存储器由于采用材质、制作工艺等方面
的不同，存在在具有不同特点的存储器。
任何一种存储器，都无法同时从速度与容量两方面，满足用户
的需求。
它们组成了一个速度由快到慢，容量由小到大的存储体系。

--- Page 2 ---
寄存器
高速缓存
主存
磁盘缓存
磁盘
可移动存储介质
C P U 寄存器
主存
辅存
11/10/2025 2
速
度
容
量
小
大低
高
4.1  概述
图4-1  计算机系统存储层次示意 
4.1.1  多级存储器结构
由操作系统协调这些存储器的使用
1、易失性
2、CPU可直接访问
1、非易失性
2、CPU不可直接访问

--- Page 3 ---
关于主存（内存）的基本概念
CPU按地址对内存进行访
问
1、bit,byte,word
2、物理地址：将（物理）
内存以字节为单位进行划
分，为每一个字节从0开始
编号，字节的编号称为字
节的物理地址。
3、所有物理地址的集合称
为物理地址空间
内存的逻辑结构(4G内存)：
    0
    1
    2
    3
    4
4G-1

--- Page 4 ---
4.1.2程序的工作过程
                   0                               0 
                                   n
                                   0
                                                            m+n-1
                                   m
#include stdio.h
main()
{
...
y = x+5
printf('%d',y)
......
} 
1、源程序test.c
2、本质上是CPU不
认得，人容易理解
的字符串
3、符号地址想，
x,y
0101001 0101
1010101 0001
.......
0000111 1101 
1、目标程序*.obj
2、CPU理解，人不
理解的二进制指令
3、相对地址(以字
节为单位从0编址)
compile
0101001 0101
1010101 0001
.......
0000111 1101
1101011 0101
1010100 0100
.......
10000001 
1001
 
1101011 0101
1010100 0100
.......
10000001 1001 
stdio.onj
main.obj
link
1、可装载程序*.exe
2、CPU理解，人不理
解的二进制指令
3、相对地址(以字节为
单位从0编址)
4、作业的逻辑地址空
间
物理地址  内存
0000
0
0000
1
0000
2
.
.
.
0100
0
01FF
F
主
子1
子2
load

--- Page 5 ---
5
4.1.3地址转换
在多道程序设计环境下，用户无法事先约定各自占用内
存的哪个区域，也不知道自己的程序会放在内存的什
么位置，所以逻辑地址从0开始编。
程序地址如果不反映其真实的存储位置，就不可能得到
正确的执行。
把作业地址空间中使用的逻辑地址，变换成为物理内存
空间中的物理地址的过程又称地址映射或地址重定位
根据地址重定位的时机分为静态重定位和动态重定位

--- Page 6 ---
6
动态重定位：
动态重定位在指令执行过程中，每次访问内存
前动态地进行地址转换。
静态重定位:当用户程序被装入内存时，一次性
实现逻辑地址到物理地址的转换，以后不再转换

--- Page 7 ---
7
静态重定位
 当用户程序被装入内存时，一次性实现逻辑地址到物
理地址的转换，以后不再转换
   12345
Load  R1,500
 0
100
500
…..
    12345
Load R1,5100
 
    5500
    5000
   5100
0
动态

--- Page 8 ---
8
动态重定位
  在程序运行过程中要访问数据时再进行地址变换。由
地址变换机构进行的地址变换，硬件上需要重定位寄
存器的支持。
静态

--- Page 9 ---
9
4.1.4存储管理程序的功能
1. 内存的描述与组织
   描述内存的基本单元（关注内存哪些方面的特点）
  多个单元如何组织（表（数组）还是链）
       
2、基于1，确定分配算法和回收算法
当用户需要内存时,系统为之分配相应的存储空间；不需要时，及时
回收，以供其它用户使用
3、地址转换（重定位）
把逻辑地址转换为相应的物理地址的过程

--- Page 10 ---
10
4.存储保护
为多个程序共享内存提供保障，使在内存中的各道程序，
只能访问它自己的区域，避免各道程序间相互干扰，特
别是当一道程序发生错误时，不致于影响其他程序的运
行
5.存储扩充
用户在编制程序时，不应该受内存容量限制，所以要采
用一定技术来“扩充”内存的容量，使用户得到比实际
内存容量大的多的内存空间。
 
其中1,2,3,4是基本功能，5是扩展功能

--- Page 11 ---
4.2连续分配方式
 连续分配方式，是指为一个用户程序分
配一个连续的内存空间。
 包括
 固定分区分配
 可变分区分配
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 12 ---
12
4.2.1  固定分区存储管理
1. 基本思想
 主存事先由OS将物理内存用
户区分成若干个连续区域
（分区），各分区的大小可
以相等，也可以不相等。
 每个分区最多给一个作业使
用，
 分区大小和个数固定。
 
操作系统
分区 1
分区 2
分区  3

--- Page 13 ---
13
4.2.1  固定分区存储管理
2、内存的描述和组织
2.1分区的描述（结构体变量）：大小、起始地址、状态，编
号
2.2 分区的组织
由于分区的个数固定，适合采用数组来讲多个分组组织在一
起
分区表（结构体数组）：记录存储分区情况及存储区使用状
况的信息

--- Page 14 ---
分区
号
大小 起始位置 状态
1 8K 312K 0
2 32K 320K 0
3 32K 352K 0
4 128K 384K 0
5 512K 512K 0
OS     312K
312K
320K
352K
384K
512K
8K
32K
32K
128K
512K
分区表
物
理
内
存
的
分
布
1M-1
0

--- Page 15 ---
3.内存分配与回收算法
分区
号
pid
大小
size
起始位置
address
状态
status
1 8K 312K 0
2 32K 320K 0
3 32K 352K 0
4 128K 384K 0
5 512K 512K 0
进程A:6K
进程B:25K
进程C:36K
进程D:520K
fenpei(usize)
{for i = 1 to n
  if p[i].status = 0 
&&p.size >usize
  {p[i].status = 1
  return i
  }
if i > n 
   printf('无法分配')
}
OS312K
320K
352K
384K
512K
进程A（6K）
进程B（25K）
进程C（36K）
huishou(pid)
{
p[pid].status = 0
}
0
1
1
1
内碎片：分区内部无法使用的部分

--- Page 16 ---
4.地址映射与保护
 地址映射公式
   PA = LA + P[i].address
地址保护：
P[i].address <=PA<=P[i].address+P[i].size
何时执行？由谁执行？如何实现？
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 17 ---
5、总结
 优点：
 1、实现简单（数据结构和算法）
   2、可以支持多道程序
 缺点：
 1、存在内碎片（内存利用率不高）
 2、并发度受限（分区的个数）
 3、可装入作业大小受限（最大分区大小）

--- Page 18 ---
18
4.2.2  可变分区存储管理
1.基本思想
固定分区存储管理内存利用率为什么不高？
          如何彻底消除内碎片？
           什么时候进行分区的划分？
 可变分区存储管理 
OS在作业进入内存时从物理内存中（存在多个空闲分区）
选择一个合适的分区（比作业大的分区）进行切割：
  1、size= usize,分配给作业
  2、size= p.size- usize,编入空闲分区集合，留待下一次分配
 
内碎片！
根据作业大小“量体裁衣”
作业装入内存时划分
空闲分区
p.size 留待下次分配
p.size-usize
job
usize
分配
usize
分区的个数、分区的大小都是可变的，故称“可变分区存储管理”

--- Page 19 ---
19
4.2.2  可变分区存储管理
2、内存的描述和组织
2.1分区的描述（结构体变量）：大小、起始地址、状态，编号
2.2 分区的组织
由于分区的个数不固定，适合采用链表来将多个分组组织在一起
由于链表的查找长度与链表长度有关，为了加快链表查找速度，
将分区按照状态分成两个链表
1、作业链：由所有已经分配给作业的分区组成
2、空闲分区链：由内存中所有空闲分区组成
分区的描述信息中不需要状态和编号，但需要添加链接指针（单链、
双链）
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 20 ---
20
分区链的例子 
假设某一时刻物理内存的分布如右图所示，
试构建作业链和空闲分区链。
 
内存
OS
42K
作业B
20K
作业C
15K
作业D
30K
0K
35K
111K
77K
91K
151K
136K
226K
12K
77K
111k
25K
111K
151k
75K
151K
^
42K
35K
91K
20K
91K
136K
15K
136K
226K
30K
226K
^
作业链
空闲分区链

--- Page 21 ---
思考：为了进行内存的分配，空闲分区连是唯一的吗
 空闲分区链如上，如果有一个大小为10K的作
业要进入内存，分哪一个空闲分区？
 不同的分配算法会选择不同的分区进行分配！
多选一，调度的思想！ 调度算法如何体现？
调度对象的排队原则！

--- Page 22 ---
22
4.2.2  可变分区存储管理
可变分区存储管理的 （空闲分区队列的排队原则）：
1) 首次适应算法：空闲分区队列按分区起始地址升序排列。分
配时选择所有何时分区中起始地址最小的分区进行分配。
2) 循环首次适应算法：也叫下次适应算法。队列排队与首次适应
算法相同。但是分配时会从上次找到的分区的下一个分区开始查
找。
3) 最佳适应算法：空闲分区队列按分区大小升序排列。分配时选
择所有何时分区中大小最小的分区进行分配。
4) 最坏适应算法：空闲分区队列按分区大小降序排列。分配时选
择所有何时分区中大小最大的分区进行分配。

--- Page 23 ---
23
4.2.2  可变分区存储管理
3、分配算法和回收算法
3.1分配算法
每次有作业进入内存时，检索空闲分区队列，对找到的第一个满
足条件的分区（尺寸比作业尺寸大的），进行切割：一份与作
业等大的分配给作业，剩余的部分按照放置策略，移动到正确
的位置。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 24 ---
24
放 置 策 略 
存
OS
42K
作业B
20K
作业C
15K
作业D
30K
0K
35K
111K
77K
91K
151K
136K
226K
42K
35K
91K
20K
91K
136K
15K
136K
226K
30K
226K
^
42K
35K
^
20K
91K
226K
20K
91K
136K
42K
35K
226K
15K
136K
91K
15K
136K
^
30K
226K
35K
30K
226K
91K
首次适应算法
最佳适应算法
最坏适应算法

--- Page 25 ---
25
大小为13K的作业E进入内存 
存
OS
42K
作业B
20K
作业C
15K
作业D
30K
0K
35K
111K
77K
91K
151K
136K
226K
42K
35K
91K
20K
91K
136K
15K
136K
226K
30K
226K
^
42K
35K
^
20K
91K
226K
20K
91K
136K
42K
35K
226K
15K
136K
91K
15K
136K
^
30K
226K
35K
30K
226K
91K
首次适应算法
最佳适应算法
最坏适应算法
作业E 10K
作业 E 13K
29K
29K
48K

--- Page 26 ---
26
大小为13K的作业E进入内存 
存
OS
42K
作业B
20K
作业C
15K
作业D
30K
0K
35K
111K
77K
91K
151K
136K
226K
42K
35K
91K
20K
91K
136K
15K
136K
226K
30K
226K
^
42K
35K
^
20K
91K
226K
20K
91K
136K
42K
35K
226K
15K
136K
91K
15K
136K
^
30K
226K
35K
30K
226K
91K
首次适应算法
最佳适应算法
最坏适应算法
作业E 10K
作业 E 13K
2K
2K
149K

--- Page 27 ---
27
大小为13K的作业E进入内存 
存
OS
42K
作业B
20K
作业C
15K
作业D
30K
0K
35K
111K
77K
91K
151K
136K
226K
42K
35K
91K
20K
91K
136K
15K
136K
226K
30K
226K
^
42K
35K
^
20K
91K
226K
20K
91K
136K
42K
35K
226K
15K
136K
91K
15K
136K
^
30K
226K
35K
30K
226K
91K
首次适应算法
最佳适应算法
最坏适应算法
作业E 10K
作业 E 13K
29K
29K
48K

--- Page 28 ---
从头开始查表
检索完否？
m.size＞u.size?
m.size－u.size≤size?
从该分区中划出
u.size大小的分区
将该分区分配给请求者修
改有关数据结构
返回
返回
继续检索下一个表项
将该分区从链中移出
Y
N
N
Y
Y
N
m.size?
u.size?
size?
具体如
何修改？

--- Page 29 ---
29
4.2.2  可变分区存储管理
3、分配算法和回收算法
3.2回收算法
作业完成后，将作业占据的分区收回，按照放置策略插入空闲分
区队列中恰当的位置。
但是！要注意回收分区H与空闲分区F相邻的情况下的分区合并问
题。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 30 ---
30K
作业
作业A
作业
20K
11/10/2025 30
（1） （2）
30K
作业A
作业
20K
作业
（3）
作业
30K
作业
作业A
20K
（4）
作业
30K
作业A
20K
作业
回
收
内
存
的
四
种
情
况
50K
大小50K
50K
50K
H与任何F不相邻 H是F的下邻
H是F的上邻 H是F1的下邻，是F2的上邻
H
F
F2
F1
F
F
H
H
H
F
判断？
处理？
判断：
F.address+F.size = H.address
处理：
F.size= F.size+H.size
判断：
H.address+H.size = 
F.address
判断：
F1.address+F1.size = H.address
H.address+H.size = F.address
处理：F.address =H.address
F.size= F.size+H.size
处理：
F1.size= F1.size+H.size+F2.size
delete(F2)
处理：
insertt(H)

--- Page 31 ---
31
4.2.2  可变分区存储管理
4、地址映射
PA = LA +P.address
5、地址保护
  PA  ε [P.address,P.address+P.size]
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
P.address和P.size这两个数据存放在哪里？ PCB中
每次进行地址映射时都访问内存，程序执行速度
腰斩！
为了加快地址映射的速度，系统设置一对寄存器：
基址寄存器和限长寄存器，用于记录当前进程所在分区的起
始地址和分区大小

--- Page 32 ---
特殊现象（碎片）
 碎片：由于各作业请求和释放内存的结果，
会导致内存中经常出现①大量②分散的③小
空闲区。内存中这种容量太小，无法被利用
的小分区称为碎片。
 碎片分为分区内碎片和分区外碎片，他们都
会造成内存利用率不高

--- Page 33 ---
碎片例子
怎么破？
拼接！
（紧凑）
1、代价大
2、不彻底

--- Page 34 ---
回答：最佳适应算法和最坏适应算法
是否名副其实？
最佳（best fit）：
1、以最快的速度产生碎片
2、对于大作业，找到合适分区的速度最慢
最坏（worst fit）:正好相反

--- Page 35 ---
总结：
优点
 解决了内碎片问题（利用率有
所提高）
 并发度不受限
 作业大小不再受限于某个具体
的值（最大分区），受物理内
存的限制
缺点
 实现复杂（数据结构，分
配时（4中放置策略）回
收时4中邻接关系的判断
与处理）
 有外碎片现象，内存利用
率不够高！
 需要额外的硬件支持（基
址、限长寄存器）

--- Page 36 ---
讨论：为了解决碎片问题，os拼过哪些命？
 1、事后型。对于已经出现的碎片，采用
拼接的方法。（代价大，效果差）
 2、事先型。 在碎片出现前。
 2.1分配时，设置阈值size.
 2.2回收时，考虑回收分区与空闲分区的
邻接关系，及时合并分区。
怎么破？


--- Page 37 ---
解决问题的思路（参照死锁现象）
1、表现是什么样的？
2、后果如何？
3、产生现象的原因？
4、从原因着手找出切入点，寻求解决的思路和
办法  
碎片现象的解决之道
多个分散的小分区，无法利用
内存利用率低
大小不一的作业都要求连续
的物理内存
作业大小控制不了，但是作业一定要连续吗？
离散分配的思想！

--- Page 38 ---
38
4.3  分页存储管理
为了彻底解决碎片问题，使得每一片
碎片都可以得到充分利用，产生了离散分配的思想。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
将连续的作业剪成多个部分，分别装入物理内存中多个不连
续的区域。
45K
10K
30K
5K

--- Page 39 ---
39
4.3  分页存储管理
4.3.1 分页存储管理的基本思想
1. 将物理内存分成大小相等的部分（块block，物理块），块的
大小是2nB.例如256B,512B,1KB,2KB,4KB等。内存的分配和回
收都以块为单位进行。
2. 将作业分成大小相等的部分（逻辑页，page）
3. page size = block size
4. 一个逻辑页面恰好装入一个物理块中
这样一来，物理内存中所有的空块都可以利用上。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 40 ---
40
4.3  分页存储管理
4.3.2内存的描述与组织
作业装入内存时，只care一件事：此块空否。
由于PM的大小为2mB,块的大小为2nB,则整个物理内存可以分成
2m-n个块.
内存分配和回收以块为单位，则在分页存储管理中，可以对物理
内存进行二次抽象。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
真实的物理内存：
以字节为单位编址，
为每个字节进行编
号，从0 编到2m-1
分块后的物理内存：
以块为单位编址，
为每个块进行编号
从0 编到2m-n-1
抽象

--- Page 41 ---
41
4.3  分页存储管理
所以对于内存的描述，只需要两个信息：
块号（表达的物理地址的范围）和状态（未分配/已分配）
对于确定的物理内存和确定的物理块大小，整个物理内存能够分
割成的物理块的个数是确定的。
组织方式：数组。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充


--- Page 42 ---
42
  分页的例子
假设块的大小为￥4KB,则前
面例子中大小为45KB的作
业可以划成
(jobsize/blocksize + 1)个
page
45 / 4 +1 = 12
作业的大小是随机的，不可
能总是能够分成整数个
page，所以最后一个页面
往往不能装满，存在页内
碎片
45K


--- Page 43 ---
43
4.3  分页存储管理
4.3.3 内存的分配与回收
由于内存采用了类似于分区表的方式来表示，则内存的分配算法
和回收算法及其简单，类似于固定分区存储管理的算法。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
fenpei()
{for i = 1 to n
  if p[i].status = 0 
  {p[i].status = 1
  return i
  }
if i > n 
   printf('无法分配')
}
huishou(bid)
{
p[bid].status = 0
}

--- Page 44 ---
44
4.3  分页存储管理
4.3.4 地址映射
回顾：连续分配方式下，地址映射的公式，硬件支持情况
PA = LA +P.address
P.address                 基址寄存器
P.size                        限长寄存器
离散分配方式下，地址映射的关键问题是什么？
进程PCB中用于存放“程序和数据在内存中的地址”如何表示？
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 45 ---
45
4.3  分页存储管理
4.3.4 地址映射
必须有一张对照表（页表），记录
一个作业的每一个页面分别装入到
内存中的哪一个物理块中。
每一个进入内存的进程都有
一张页表。页表的地址存于
进程的PCB中。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
p b
0 256
1 260
2 n
3 262
4 261
5 ...
6 m
7 p
8 1023
9 ...
10 ...
11 ...

--- Page 46 ---
46
4.3  分页存储管理
4.3.4 地址映射
0号页面的LA逻辑地址的
范围[0...4095]
则LA为35的地址对应的
物理地址为
256*4096 +35
256号块的PA地址范围是
[256*4096,256*4096+4095]
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
p b
0 256
1 260
2 n
3 262
4 261
5 ...
6 m
7 p
8 1023
9 ...
10 ...
11 ...
LA=5000时，PA = ?

--- Page 47 ---
47
4.3  分页存储管理
4.3.4 分页存储管理的地址映射过程：
（1）根据页面大小判断LA所在逻辑页面的页号p和页内偏移d
若给定一个逻辑地址空间中的地址为A，页面大小为pagesize，
则:
        页号P=INT[A/pagesize]
        页内地址d=[A] MOD pagesize
    例如：系统页面大小为4KB，设A=5000B，则:
         P=INT[5000/4096] =1
        d=[5000] MOD 4096 = 904
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 48 ---
48
4.3  分页存储管理
4.3.4 分页存储管理的地址映射过程：
（1）根据页面大小判断LA所在逻辑页面的页号p和页内偏移d
A = 5000B  pagesize = 4KB 则p=1，d=904
（2）根据（1）得到的页号p,查页表
得到块号b = 260
(3)计算物理地址PA
由于页内偏移d = 块内偏移d
则PA = 260*4096+904 
= 1065864B
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
p b
0 256
1 260
2 n
3 262
4 261
5 ...
6 m
7 p
8 1023
9 ...
10 ...
11 ...

--- Page 49 ---
49
4.3  分页存储管理
4.3.4 地址映射性能分析
（1）根据页面大小判断LA所在逻辑页面的页号p和页内偏移d
A = 5000B  pagesize = 4KB 则p=1，d=904
（2）根据（1）得到的页号p,查页表
得到块号b = 260
(3)计算物理地址PA
由于页内偏移d = 块内偏移d
则PA = 260*4096+904 
= 1065864B
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
p b
0 256
1 260
2 n
3 262
4 261
5 ...
6 m
7 p
8 1023
9 ...
10 ...
11 ...
除法！
乘法！
读内存！

--- Page 50 ---
50
4.3  分页存储管理
4.3.4 存在的问题
1、地址映射的第（1）利用除法求p和d,第（3）步利用乘法计算
PA.CPU执行乘法和除法十分耗时！
但CPU十分擅长做位操作！
逻辑地址（虚地址）32bit的结构：
pagesize = 4KB = 212B
 011位为位移量(页内地址)，即每页的大小为4KB
 12 31位为页号，地址空间最多允许有1M页
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
p b
0 256
1 260
2 n
3 262
4 261
5 ...
6 m
7 p
8 1023
9 ...
10 ...
11 ...
位移量d页号P
31                          12 11                           0

--- Page 51 ---
将CPU做乘除法的动作转换为做位操作的办法，可以节约大量
CPU时间！
为了进一步减少CPU的工作量，专门设置硬件来完成位操作。
地址分页机构
作用：
（1）根据页面大小将逻辑地址拆分成p和d
(2)将物理块号b和块内偏移d拼接成物理地址
位移量d页号P
31                          12 11                           0
位移量d块号b
31                          12 11                           0

--- Page 52 ---
52
4.3  分页存储管理
4.3.4 存在的问题
2、地址映射的第（2）步，需要读进程的PCB获得当前进程的页表在内存中
的地址。（额外多读一次内存，进程执行速度腰斩），再读页表根据页号
获得块号（又多读一次内存，进程执行速度再次腰斩）。
根据可变分区存储管理中加快地址映射的方法，将当前进程的页表地址B和页
表长度L(max(p))用一个寄存器（页表寄存器PTR）存放.将读内存PCB的时
间减少至读寄存器的时间。（解决第一次多读内存的问题PCB）
如何解决第二次读内存中页表的问题？
思路相似但并不完全一样。
why?
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
寄存器稀少而金贵！页表内容多

--- Page 53 ---
寄存器
高速缓存
主存
磁盘缓存
磁盘
可移动存储介质
C P U 寄存器
主存
辅存

--- Page 54 ---
解决第二次额外读内存查页表问题的方法
 在内存和CPU之间引入一级存储器cache(高速
缓存)，用于存放并发进程的       页表。（因
为高速缓存也有限！）
用于存放并发进程部分页表的高速存储器称为
“快页表”，简称快表
部分

--- Page 55 ---
页式地址变换举例（无快表机制）
     作业2地址空间中，设100号单元处有如下指令：    mov  
r1,[2500]。当这条指令执行时，如何进行正确的地址变换。
pagesize= 1KB=210B
mov  r1 ,
[2500]
123
0
1
2
作业2地址空间
            2500            → 2*1024   +   452 
                      p=2       w=452
0000100111000100        000010     0111000100

--- Page 56 ---
•     页式地址变换过程（无快表）        
      000111 0111000100
15               10   9                              0
页号P 页内位移W
页表寄存器
mov  r1 ,
[2500]
123
0
1
2
作业2地址空间
+
0 2
1 4
2 7
页表
             000010 0111000100
15               10   9                              0
页号P 页内位移W
2500 0
1KB
主存
2KB
3KB
4KB
5KB
6KB
7KB
8KB
9KB
10KB1
os
os
mov r1 , [2500]
123
第1页
7*1024+452
=7620
地址分页机构

--- Page 57 ---
•     页式地址变换的步骤（无快表）
map(A)
  (1)地址分页机构把CPU给出的逻辑地址A分为两部分：页
号p和页内地址d；
(2)将逻辑页号p与页表寄存器的页表长度内容比较，>则为
越界（地址保护！），返回；
(3)根据页表寄存器的页表地址得到页表在内存的首地址，
并根据逻辑页号p在页表中找到对应的物理块号b；
(4)由地址分页机构把物理块号b与逻辑地址中的页内地址d
合并成为物理地址PA,返回PA。

--- Page 58 ---
•     页式地址变换的步骤（有快表）
map(A)
  (1)地址分页机构把CPU给出的逻辑地址A分为两部分：页
号p和页内地址d；
(2)将逻辑页号p与页表寄存器的页表长度内容比较，>则为
越界（地址保护！），返回；
(3)根据页表寄存器的页表地址得到页表在内存的首地址，
并根据逻辑页号p在页表中找到对应的物理块号b；
（3'）根据逻辑页号查快表，得到对应的物理块号b
(4)由地址分页机构把物理块号b与逻辑地址中的页内地址d
合并成为物理地址PA,返回PA。
一定要注意，（3）和（3'）同时进行！

--- Page 59 ---
11/10/2025
页表长度页表始址
页表寄存器
页内地址页号(3)
逻辑地址L
db
<
+
越界中断
b
1
块号页号
页表
具有快表的分页系统的地址变换机构：
b
块号页号
快表
输
入
寄
存
器

--- Page 60 ---
内存的有效访问时间（Effective Access Time）
•（根据逻辑地址读出该地址的值的时间）


--- Page 61 ---
61
例
如果查找快表花费的时间是50ns，访问内
存的时间是750ns，
页号在快表：存取时间为50+750=800ns
页号在慢表：存取时间为750+750=1500ns
命中率为90%   存取时间为0.9*800+0.1*1500=870ns
命中率为97%   存取时间为0.97*800+0.03*1500=821ns
时间延迟
命中率为90%   （870-750）/750=16%
命中率为97%  （821-750）/750=9.5%

--- Page 62 ---
4.3.5 两级和多级页表
         现代计算机系统都支持非常大的逻辑地
址空间(232264)，页表本身就非常大，需占
用较大的地址空间，一个物理块可能装不下。
例如：一个具有32位逻辑地址空间的分页系统，规定页面
大小为4KB即212B，则每个进程页表的页表项可达1M个，
若每个页表项占用4个字节，则需要4M连续的物理内存
存放页表（？）。一个物理块只能容纳256个页表项。
为了将整个页表离散地装入内存，只能将页表分页，从
而形成二级页表甚至多级页表。
62


--- Page 63 ---
…
…
…
0
1
2
3
4
5
6
7
114
115
1468
内存空间
…
6
4
1
第0页页表
0
1
2
…
255
115
114
第1页页表
0
1
2
…
255
1468
第n页页表
0
1
2
…
255
0
1
2
n
外部页表
两级分页结构

--- Page 64 ---
总结
优点： 缺点：
1、地址映射复杂，需要
的支持较多（页表、地
址分页机构、页表寄存
器、快表）
2、对任何一个逻辑地址，
存在两次访问内存的问
题，即使引入快表也有
延迟

--- Page 65 ---
思考：分页存储管理的内存利用率还有没
有榨取的空间？
考虑如下场景：6道C语言编写的程序，都包含了stdio.h头文
件。则程序经过编辑、编译、链接后形成可装载模块，分页
后装入物理内存的物理块中。


--- Page 66 ---
在这种情况下，即使整个物理内存全部装满，
一个空块都没有，能否说明内存利用率高？
显然，不能！
因为内存虽然装满了，但是共同的内容（比如
例子中的stdio.h）重复装入了多次(6次)。
如果只装一次，多个程序共享，内存利用率可
进一步提高！

--- Page 67 ---
在分页存储管理方式下，能否实现信息共
享？
理想很丰满，现实很骨感！
为啥？

--- Page 68 ---


--- Page 69 ---
因为多作业进行分页的时候，机械地按照页面大小对作
业的逻辑地址空间进行分割，完全不考虑作业的逻辑结
构。
在这种机械分割的情况下，一条指令甚至一个操作数都
有可能在分割的时候跨页面。
一个公共模块在不同的作业中被分割的情况各不一样。
很难保证恰好在模块边缘分割且恰好占整数个页面。
理论上可以共享，实践操作几乎没有可能

--- Page 70 ---
共享！
共享
！
共享！

--- Page 71 ---
4.4分段存储管理
为了进一步提高离散分配方式（分页）的内存利用率，避免将
同样的内容（共同的模块）装入多次，在对作业进行分割的时
候，换一种方式。
如何灵活切割？
充分考虑作业的逻辑结构，将逻辑上相关的内容分在一起，布
线管的内容分开。这样就可以将多个程序中共有的模块只装入
一次，多个程序在运行过程中共享。从而达到提高内存利用率
的目的。
机械切割（分页） 灵活切割（分段）

--- Page 72 ---


--- Page 73 ---
73
段的基本概念 
1. 段
 段是一组逻辑信息的集合。（C语言中的一个模块，甚
至一个函数，汇编语言中的一个段（数据段、代码段、堆栈段））
 每个段都有自己的名字和长度，通常编译后
用一个段号来代替段名，
 每个段都从0开始编址，并采用一段连续的
地址空间，段的长度由相应的逻辑信息的长
度决定（各不相同）。
 

--- Page 74 ---
4.4.1分段存储管理的基本思想
1、将作业按照其逻辑结构分成若干个
段。
2、每一个段进入内存后占据一片连续的物理内存，同一作
业内部的不的段之间可以不连续。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
请问：
1、分段存储管理是连续分配还是离散分配？
2、根据经验（可变分区、分页存储管理）推测：
• 物理内存如何划分？
• 物理内存的描述、组织、分配、回收更类似那种存
储管理方式？
• 前面的“碎片”现象，“两次访问内存”现象会不会产生？

--- Page 75 ---
分析：
1、具有”段内连续，段间离散“的特征。（属于离散分配）
所以离散分配方式下的问题有：
• 一定需要类似于分页存储管理中“页表”的数据结构来记
录一个连续的作业在内存中的离散分布情况
• 一定存在离散分配的“多次访问内存”的现象
2、由于“段内连续”，而段的大小各不相同，无法对物理
内存进行类似分页中的标准化分割。所以
• 物理内存是以分区为单位进行分配和回收的。（内存的
描述、组织、分配、回收与可变分区存储管理一模一样）
• 物理内存中一定会产生（外）碎片

--- Page 76 ---
76
逻辑作业分段的例子
主程序
M
子程序
X
子程序
X
数组
A
工作区
B
0
K
0
P
0
L
0
N
0
S
段号 段长 存取控制 段始址
0 K 3200
1 P 1500
2 L 6000
3 N 8000
4 S 5000
段表 1500
3200
5000
6000
8000
P
K
S
L
N
内存
分段系统中的逻辑地址由段号s和段内地址d组成。

--- Page 77 ---
分
段
系
统
中
共
享editor的
示
意
图
进程1
editor
data1
进程2
editor
data2
段表
段长 基址
4K 20K
2K 40K
段表
段长 基址
4K 20K
2K 50K
主存
0
…
20
editor
…
40
data1
…
50
data2分段系统的一个突出优点是易于实现段的共享，
允许若干个进程共享一个或多个分段，且对段的
保护十分简单易行。
可重入代码(纯代码):是一个允许多个进程同时访问的
代码.纯代码不允许任何进程对其修改

--- Page 78 ---
4.4.2分段存储管理的地址映射
由于分段存储管理属于离散分配方式，
其地址映射类似于分页存储管理。
需要操作系统提供的支持包括。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
分页存储管理 分段存储管理
地址维度 一维地址A 二维（s,d）
数据 页表 段表
硬件支持 地址分页机构 无
页表寄存器 段表寄存器
快页表 快段表

--- Page 79 ---
79
4.4.2     分段地址转换过程
LACPU 段号s  段内位移d
>
+
段表长度ts    段表始址ta
段表寄存器STCR
Y
地址越界(段号S)
 段长    段始址
                
                
    ss           L
+
PA
  内存
    段表s ta
>
越界中断(段内偏移d)
思考：
段
长
ts
max(s)

--- Page 80 ---
分段存储管理总结
优点：
1、支持共享，提
高内存利用率
2、支持动态链接，
作业不必全部装入
内存
缺点：
1、有外碎片
2、存在两次访问内
存的问题
3、实现复杂（与可
变分区类似）

--- Page 81 ---
4.5段页式存储管理
正是由于分段存储管理兼具了连续分配和离散分配的缺
点，所以很少有操作系统采用纯粹的分段存储管理。
有没有什么办法，既保留分段的优点（共享，动态链
接），又没有分段的缺点（碎片，实现复杂）？
在分段的基础上（共享，动态链接），对段进行分页
（无外碎片（但是会产生少量内碎片），实现简单）！
段页式存储管理！

--- Page 82 ---
4.5.1段页式存储管理的基本思想
1、物理内存分块，（内存以块为
单位进行分配与回收，内存的描述
与组织，分配与回收算法，与分页
存储管理一模一样）
2、作业分段（逻辑地址二维，支
持共享和动态链接）
3、段内分页（解决碎片问题）
4、页大小 = 块大小
5、一页装入一块
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
段号S       段内地址W
页号p 页内地址d

--- Page 83 ---
4.5.2段页式存储管理的地址映射
由于分段存储管理属于离散分配方式，
其地址映射类似于分页存储管理。
需要操作系统提供的支持包括。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
分页存储管理 分段存储管理 段页式
地址维度 一维地址A 二维（s,d） 二维（s,d）
数据 页表 段表 段页表
硬件支持 地址分页机构 无 地址分页机构
页表寄存器 段表寄存器 段页表寄存器
快页表 快段表 快段页表

--- Page 84 ---
段表起始地址
段表控制寄存器
段表
段表长度
状态段号
0
1
2
3
4
1
1
1
0
1
页表长度
…
…
…
…
…
页表起始地址
…
…
…
…
…
状态
…
…
…
…
…
状态页号
0
1
2
3
4
1
1
1
0
1
外存存储块号
页表
状态页号
0
1
2
3
4
1
1
1
0
1
外存存储块号
操作系统
段页表的例子

--- Page 85 ---
85
页表    页表
首址  长度
S ，(   p d )
 B'          L' 
+
B 逻辑
地址
段表地址寄存器
L
段表长度寄存器 页内地址段号   页号
比较
段号0
S 物理
地址
段表
若S≥L,则地
址越界
比较 若p≥ L',则
地址越界
 b
页号0   页架号
p
页表
+
 b d
页架号   页内地址
4.5.3  地址转换(无快表)
地
址
分
页
机
构

--- Page 86 ---
思考：
在段页式存储管理的地址映射过程中，为了读出某个逻
辑地址中的数据，需要访问几次内存？
3次！
1、读段表
2、读页表
3、根据PA读物理内存
怎么破？ 快表！

--- Page 87 ---
87
 段号    页号      页架号
页表    页表
首址  长度
S ，(   p d )
 B'          L' 
+
B 逻辑
地址
段表地址寄存器
L
段表长度寄存器 页内地址段号   页号
比较
段号0
S 物理
地址
段表
若S≥L,则地
址越界
图：引入快表后段页式存储管理的地址转换
快表
S        p           p'
比较 若p≥ L',则
地址越界
 p'
页号0   页架号
p
页表
+
 p' d
页架号   页内地址
4.5.2  地址转换过程（有快表）
地
址
分
页
机
构

--- Page 88 ---
总结：
优点
 共享
 动态链接
 不存在碎片
缺点
 三次访问内存
 需要的硬件支持
多
 更多页内碎片
（与分页比较）

--- Page 89 ---
小结
至此，讲述了两大类5种存储管理的方式：
1、连续分配方式
1.1固定分区
1.2可变分）
2、离散分配
2.1分页
2.2分段
2.3段页式
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
地址映射简单，存在碎片问题
地址映射复杂，需要的硬件支持较多，
存在多次访问内存问题
没有考虑“内存扩充”的问题，意味着能够进入内存执
行的作业受物理内存大小限制

--- Page 90 ---
4.6 虚拟存储器
前面讲述的5种存储管理方式称为“实存管理”。
特点：
1、全部装入
2、常驻内存。（直到作业完成才从内存撤出）
并发作业能够使用的内存尺寸受物理内存大小限制，不能超
越。
当作业大小超过为内存大小时，作业无法装入并运行。
思考：是否必须全部装入？是否必须常驻内存？

--- Page 91 ---
虚拟存储器：操作系统通过一定的技术手段，将内存和
辅存这物理上的两级存储器，改造成逻辑上的一级存储
器，向用户提供了比物理内存和作业的逻辑地址空间大
得多的“虚拟存储器”。
可见，虚拟存储器由操作系统实现了对物理内存的扩充，
解除了物理内存容量对作业尺寸上限的限制，给用户编
程带来了极大地方便。

--- Page 92 ---
4.6.1 Virtual Memory 三要素
1. 理论基础
2. 技术手段
3. 物质基础1、理论基础：程序的局部性原理。
早在1968年，Denning.P就曾指出：程序在执行时将呈
现出局部性规律。
程序在执行过程中的一个较短时期内，所执行的指令地
址和指令的操作数地址，分别局限于一定区域。
 局部性主要表现：
 时间局部性：是指一段指令在某一时间段内会被
反复执行。
 空间局部性：是指一旦某一个存储单元被访问，
那么它附近的单元也将很快被访问。
程序具有循环结构
程序具有顺序结构
分
支
结
构
会
破
坏
局
部
性

--- Page 93 ---
4.6.1 Virtual Memory 三要素
1. 理论基础
2. 技术手段
3. 物质基础2、技术手段：对换
既然程序的执行具有局部性，意味着程序不需要全部装入，只
装入一部分就可以开始运行。
但是！因为只装入了一部分就开始运行，随着程序的推进，PC
指令计数器指向的指令在不断变化。一定会在某个时刻，出现
下一时刻要用到的信息（指令或操作数）不在内存！                  
称发生了内存缺失。       
由OS将缺失的信息从辅存装入内存。随着并发进程不停地发生
内存缺失，OS不断将缺失的信息装入内存。内存很快装满。装
满之后有发生内存缺失，
OS按照一定策略，挑选部分已经装入内存的信息，将这些信息
从内存扔出，存到辅存。
怎么办？
在哪里？
怎么办？

--- Page 94 ---
4.6.1 Virtual Memory 三要素
1. 理论基础
2. 技术手段
3. 物质基础1、理论基础：程序的局部性原理。
早在1968年，Denning.P就曾指出：程序在执行时将呈
现出局部性规律。
程序在执行过程中的一个较短时期内，所执行的指令地
址和指令的操作数地址，分别局限于一定区域。
 局部性主要表现：
 时间局部性：是指一段指令在某一时间段内会被
反复执行。
 空间局部性：是指一旦某一个存储单元被访问，
那么它附近的单元也将很快被访问。
程序具有循环结构
程序具有顺序结构
分
支
结
构
会
破
坏
局
部
性

--- Page 95 ---
 
物理上：两级速度差异巨大的存储器
逻辑上：一级存储器，速度介于二者之间，容量巨大 
辅存
内存换入
换出
VM到底多大？由谁决定VM的大小？

--- Page 96 ---
4.6.1 Virtual Memory 三要素
1. 理论基础
2. 技术手段
3. 物质基础
3、物质基础
一定容量的内存+相当容量的辅存

--- Page 97 ---
4.6.2 实现VM要解决的问题
1、物理内存的分配策略
在支持虚拟存储器的环境下，程序只装入部分即开始运行。
则在进程的生存周期中，进程分得的物理内存<进程的大小。
究竟如何分配物理内存？
有两种策略：
 固定分配：进程生存周期中分得的物理内存数量不变。
（固定数量，按比例分配）
 可变分配：进程生存周期中分得的物理内存数量会发生变
化（当进程频繁发生内存缺失时，增加数量，否则，减少，
保持所有进程具有差不多的内存缺失频率。）

--- Page 98 ---
4.6.2 实现VM要解决的问题
2、调入策略
决定何时调入进程所需的信息。
预调：在进程发生内存缺失前，OS按照一定的算法预测哪
些信息会被访问，在访问这些信息前预先将其调入内存。
请调：直到进程已经发生了内存缺失，向OS提出调入请求。
OS收到进程请求后，从辅存中将所缺的信息调入内存。
你认为哪种策略比较靠谱？效果较好？

--- Page 99 ---
4.6.2 实现VM要解决的问题
3、置换策略
当内存已经装满了，仍有进程发生了内存缺失时，必须进行
一次置换（先将内存中的选中信息换出，腾出一定的内存空
间，再从辅存将需要的信息换入内存。）
置换策略决定在哪一个范围内进行置换。
 局部置换。在进程内部进行置换。（谁发生内存缺失，就
将谁的信息换出去）
 全局置换：在整个物理内存范围内进行置换。
你们认为那种策略比较好？为什么？

--- Page 100 ---
4.7 请求分页存储管理
4.7.1基本思想
 PM分块
 作业分页
 页大小=块大小
 一页装入一块
 只装入部分即可运行。
运行过程中发生内存缺失时，称为发生了“缺页”。由操作系统
从辅存将所缺的页面调入内存。当内存（调度策略决定）满时
依然缺页，操作系统根据调度算法选择确定的页面换出到辅存
后在调入页面。
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充

--- Page 101 ---
4.7 请求分页存储管理
4.7.2内存的组织和描述，内存的分配与回收
4.7.3地址映射
1、内存的描述与组织
2、内存的分配与回收
3、地址映射
4、地址保护
5、地址扩充
与基本分页存储管理一模一样
基本分页 请求分页
页表（页号、块号） 扩展的页表
页表寄存器（页表始址，
页表长度）
√
地址分页机构 √
快表 √
缺页中断处理机构

--- Page 102 ---
 为保证进程能正常运行最少需要多少物理块。
           从理论上讲，进程只要获得一个物理块就可以运行。但是进程正常
运行所需的最少物理块数与计算机的硬件结构（指令系统）有关，取决于
指令的格式、功能和寻址方式。由于分页是系统的行为，可能会出现下面
的情景：（指令跨页，操作数跨页）
         由此可见，系统应保证任一条
指令执行时，其所涉及的虚拟地址
所在的页都应在内存中。这个页数
就是进程所需要的最小块数，若系
统为进程所分配的物理块数少于此
值时，进程将无法运行。 
1
2
3
4
5
6
涉
及6次
缺
页
中
断
的
指
令
copy A B
数据A：
数据B：
能够在内存中拼接出一条完整的指令

--- Page 103 ---
    在请求分页系统中，每当所要访问的页面不在内存时，便
产生一缺页中断，请求OS将所缺之页调入内存
    缺页中断又是一种特殊的中断，它与一般的中断相比，
有着明显的区别，主要表现在下面三个方面：
(1) 在指令执行期间产生和处理中断信号
　(2) 一条指令在执行期间，可能产生多次缺页中断。
普通中断 缺页中断
中断发生时
机
一条指令结束，由
中断扫描机构扫描
指令执行期间，立刻响应
返回断点 下一条指令 当前指令
发生频率 一次 一条指令执行期间多次中断

--- Page 104 ---
3
页号 块号 状态 辅存地址 访问位 修改位
部分装入，哪些页
面装入，哪些未装
入？
未装入的页面，存
在辅存中什么地方？
需要从内存换出一
页时，选择哪一页
换出，为淘汰算法
提供淘汰的依据？ 对于确定要淘汰出
局的页面，如何淘
汰？直接覆盖还是
先写回辅存再覆盖？

--- Page 105 ---
缺页中断处理
保留 CPU 现场
从外存中找到缺页
内存满否？
选择一页换出
该页被修改否？
将该页写回外存
OS 命令 CPU 从外存读缺页
启动 I/O 硬件
将一页从外存换入内存
修改页表
否
是
是
否
页表项在快表中？
CPU 检索快表
访问页表
否
页在内存？
修改访问位和修改位
形成物理地址
地址变换结束
否
页号＞页表长度?
开始
程序请求访问一页
产生缺页中
断请求调页
修改快表
是
越界中断
是
是
4、
请
求
分
页
存
储
管
理
地
址
映
射
过
程
一维逻辑地址
地址分页机构
页表寄存器
地址保护
页表状态位
将页表项装入
快表
不一定修改修
改位，一定修
改访问位
地址分页机构
缺页中断响应
硬件完成
程序换道
页表中的辅存
地址
置换策略
置换算法
访问位
修改位
块号、状态、辅
存地址

--- Page 106 ---
4.8 页面置换算法
页面置换算法的好坏直接影响虚拟存储器的有效访问时间。
如果页面置换算法选择不当，会造成系统“抖动”（颠簸）
在虚存中，页面在内存与外存之间频繁调度，以至于调度页面
所需时间比进程实际运行的时间还多，此时系统效率急剧下降，
甚至导致系统崩溃。
基本概念：
1、页面走向。程序执行过程中对页面的访问顺序。
2、命中：要访问的页面在内存
3、命中率 = 命中次数/总访问页面数
3、缺页率 = 1 - 命中率

--- Page 107 ---
107
4.8.1 最佳置换算法 
        最佳置换算法是由Belady于1966年提出的一种理论
上的算法。 其所选择的被淘汰页面，将是①以后永不使
用的， 或许是②在最长(未来)时间内不再被访问的页面。
采用最佳置换算法，通常可保证获得最低的缺页率。 
思考：为什么这种算法是理论上的算法？可否用于实际
的页面置换？

--- Page 108 ---
108
    假定系统为某进程分配了三个物理块， 并考虑有以下的页面号引
用串（页面走向）：
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1      
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
最佳置换算法（OPT）例
从该页面走向你能得到什么结论？
程序对页面的访问时不均匀
的！局部性原理存在

--- Page 109 ---
2. 先进先出(FIFO)页面置换算法
该算法的思想是：假设程序总是顺序执行的，那么
先进入主存的页先退出主存，最早调入主存的页，其不再
被使用的可能性比最近调入主存的页要大。所以总是选择
作业中在主存驻留时间最长（即最老）的一页淘汰。

--- Page 110 ---
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
缺页15次，总访问次数20次，缺页率15/20＝75％，命中率25%
页面置换12次，置换率12/20=60%
先进先出置换算法（FIFO）
例
        

--- Page 111 ---
111
4.8.3 最近最久未使用(LRU)置换算法 
1. LRU(Least Recently Used)置换算法的描述 
算法的思想是：由于程序的执行具有局部性，
可以用程序最近一段时间（页面进入内存以来）的页
面访问历史情况来预测将来页面的访问情况。当需要
置换一页时，选择在最近一段时间内最久不用的页予
以淘汰（借鉴最佳置换算法部分思想）。

--- Page 112 ---
发生置换
的时刻

--- Page 113 ---
7
缺
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
7
0
缺
7
0
1
缺
2
0
1
换
2
0
1
中
2
0
3
换
2
0
3
中
4
0
3
换
4
0
2
换
4
3
2
换
 换
0
3
2
中
0
3
2
中
1
3
2
换
1
3
2
中
1
0
2
换
1
0
2
中
1
0
换
1
0
7
中
 中
最近最久未使用置换算法（LRU）例

--- Page 114 ---
 
LRU的实现：
1、记时法：系统为每一页面增设一个记时器。
每当一个页面被访问时，当时的绝对时钟内容被
拷贝到对应的记时器中，这样系统记录了内存所
有页面最后一次被访问的时间。淘汰页面时，选
取记时器中值最小的页面淘汰。

--- Page 115 ---
 堆栈法：用一个栈保留页号。每当访问一个页
面时，就把它从栈中取出放在栈顶上。这样一
来，栈顶总是放最新被访问页面的页面号，而
栈底放着最近最久未使用的页面号。由于要从
栈的中间移走一项，所以要用具有头尾指针的
双向链连起来。
注意：不是通常意义上的栈 

--- Page 116 ---
116
2) 栈 
7 0 1 2 0 3 0 4 2
2
1
0
0
2
1
3
0
2
0
3
2
4
0
37
0
7
1
0
7
2
4
0
用栈保存当前使用页面时栈的变化情况
每当进程访问某页面时，便将该页面的页面号从
栈中移出，将它压入栈顶

--- Page 117 ---
           【例】假定系统为某进程分配了3个物理块，
页面访问序列为：5、0、1、2、0、3、0、4、2、3、
0、3、2、1、2、0、1、5、0、1。采用最近最久未使
用置换算法，计算缺页中断次数和缺页中断率。            
解：页面置换过程如下表所示：
页面访问序列 5 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 5 0 1
1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 5 0 1
0 0 1 2 0 3 0 4 2 3 0 3 2 1 2 0 1 5 0
5 5 5 0 1 2 2 3 0 4 2 2 0 3 3 1 2 0 1 5
+ + + + - + - + + + + - - + - + - + - -
缺页中断次数=12
缺页中断率=12/20=60% 

--- Page 118 ---
4.8.4  Clock置换算法 
1. 简单的Clock置换算法 : 
每页设置一位访问位(1,0)，内存中的所有页链接成一个
循环队列,淘汰页面过程:
循环检查各页面的使用情况，访问位为“0”，选择该页
淘汰；访问位为“1”，置为“0”，查询指针前进一步。最
后回到队首
循环检查各页面使用情况--clock 算法.又称为“最近未
使用”置换算法（NRU）
入口
查寻指针前进一步，指向
下一个表目
页面访问位＝ 0?
选择该页面淘汰
是
返回
置页面访
问位＝“ 0”
否
块号 页号 访问位 指针
0
1
2 4 0
3
4 2 1
5
6 5 0
7 1 1
替换
指针

--- Page 119 ---
11/10/2025
119
  
 P a g e 9 
use=1
Page19
Use=1
Page1
Use=1
Page45
Use=1
Page191
Use=1
Page556
Use=0
Page13
Use=0Page67
Use=1
Page33
Use=1
Page222
Use=0
下一个页指针
n 0
1
2
3
4
56
7
8
一个页替换前的缓冲区状态
P a g e 9 
use=1
Page19
Use=1
Page1
Use=1
Page45
Use=0
Page191
Use=0
Page727
Use=1
Page13
Use=0Page67
Use=1
Page33
Use=1
Page222
Use=0
n 0
1
2
3
4
56
7
8
下一页替换后的缓冲区状态
下一个页指针

--- Page 120 ---
11/10/2025 辽东学院信息技术学院 120
2. 改进型Clock置换算法 
       由访问位A和修改位M可以组合成下面四种类型的页面：
       1类(A=0, M=0): 表示该页最近既未被访问， 又未被修改， 是
最佳淘汰页。
       2类(A=0, M=1)： 表示该页最近未被访问， 但已被修改， 并不
是很好的淘汰页。
       3类(A=1, M=0)： 最近已被访问， 但未被修改， 该页有可能再
被访问。
       4类(A=1, M=1): 最近已被访问且被修改， 该页可能再被访问。 

--- Page 121 ---
11/10/2025 辽东学院信息技术学院 121
  访问位A，修改位M共同表示
  一个页面的状态
  四种状态：00  01  10  11
  三轮扫描：
第一轮：淘汰00页面，未找到，下一步；
第二轮：淘汰01页面，非01页面-A位复位
为“0”，
反复执行 第一轮和第二轮 


--- Page 122 ---
11/10/2025 辽东学院信息技术学院 122
 选择到当前时间为止被访问次数最少的页面被置
换；
 每页设置访问计数器，每当页面被访问时，该页
面的访问计数器加1；
 发生缺页中断时，淘汰计数值最小的页面，并将
所有计数清零；

--- Page 123 ---
11/10/2025 辽东学院信息技术学院 123
       它是对FIFO算法的发展，通过被置换页面的缓冲，
有机会找回刚被置换的页面；
 被置换页面的选择和处理：用FIFO算法选择被置
换页，把被置换的页面放入两个链表之一。
• 如果页面未被修改，就将其归入到空闲页面链
表的末尾
• 否则将其归入到已修改页面链表。

--- Page 124 ---
        需要调入新的物理页面时，将新页面内容读入
到空闲页面链表的第一项所指的页面，然后将第一
项删除（从空闲链表摘下）。
        空闲页面和已修改页面，仍停留在内存中一段
时间，如果这些页面被再次访问，只需较小开销，
而被访问的页面可以返还作为进程的内存页。
        当已修改页面达到一定数目后，再将它们一起
调出到外存，然后将它们归入空闲页面链表，这样
能大大减少I/O操作的次数。


--- Page 125 ---
belady现象 
             Belady异常现象：一般而言，分配给进程的物
理块越多，运行时的缺页次数应该越少。但是
Belady在1969年发现了一个反例，使用FIFO算法时，
四个物理块时的缺页次数比三个物理块时的多，这
种反常的现象称为Belady异常。如下面两表所示，
一个进程有5个页面，页面访问序列如下：
Belady异常现象（3个物理块的FIFO现象）  
页面访问序列 0 1 2 3 0 1 4 0 1 2 3 4 
0 1 2 3 0 1 4 4 4 2 3 3 
 0 1 2 3 0 1 1 1 4 2 2 
  0 1 2 3 0 0 0 1 4 4 
九次缺页 
+ + + + + + + - - + + - 
 

--- Page 126 ---
belady现象 
              Belady异常现象（4个物理块的FIFO现象） 
 页面访问序列 0 1 2 3 0 1 4 0 1 2 3 4 
0 1 2 3 3 3 4 0 1 2 3 4 
 0 1 2 2 2 3 4 0 1 2 3 
  0 1 1 1 2 3 4 0 1 2 
   0 0 0 1 2 3 4 0 1 
十次缺页 
+ + + + - - + + + + + + 
 
由表中可见，3个物理块时缺页次数是9次，缺页中断
率为9/12=75%；而4个物理块时的缺页次数是10次，
缺页中断率为10/12≈83.3%。

--- Page 127 ---


